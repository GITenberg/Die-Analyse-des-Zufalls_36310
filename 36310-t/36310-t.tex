% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
%                                                                         %
% The Project Gutenberg EBook of Die Analyse des Zufalls, by              %
% H. E. (Heinrich Emil) Timerding                                         %
%                                                                         %
% This eBook is for the use of anyone anywhere at no cost and with        %
% almost no restrictions whatsoever.  You may copy it, give it away or    %
% re-use it under the terms of the Project Gutenberg License included     %
% with this eBook or online at www.gutenberg.net                          %
%                                                                         %
%                                                                         %
% Title: Die Analyse des Zufalls                                          %
%                                                                         %
% Author: H. E. (Heinrich Emil) Timerding                                 %
%                                                                         %
% Release Date: June 6, 2011 [EBook #36310]                               %
%                                                                         %
% Language: German                                                        %
%                                                                         %
% Character set encoding: ISO-8859-1                                      %
%                                                                         %
% *** START OF THIS PROJECT GUTENBERG EBOOK DIE ANALYSE DES ZUFALLS ***   %
%                                                                         %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %

\def\ebook{36310}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                  %%
%% Packages and substitutions:                                      %%
%%                                                                  %%
%% book:     Required.                                              %%
%% inputenc: Standard DP encoding. Required.                        %%
%% fontenc:  Enables German hyphenation. Required.                  %%
%% babel:    German language Hyphenation. Required.                 %%
%%                                                                  %%
%% amsmath:  AMS mathematics enhancements. Required.                %%
%% amssymb:  Additional mathematical symbols. Required.             %%
%% mathrsfs: Math script font. Required.                            %%
%%                                                                  %%
%% ifthen:   Logical conditionals. Required.                        %%
%% alltt:    Fixed-width font environment. Required.                %%
%% indentfirst: Indent first word of each sectional unit. Optional. %%
%%                                                                  %%
%% makeidx:  Indexing. Required.                                    %%
%% multicol: Multi-column formatting for index. Required.           %%
%%                                                                  %%
%% array:    Array enhancements. Required.                          %%
%% longtable: Multi-page tables. Required.                          %%
%% multirow: Multi-row table entries. Required.                     %%
%%                                                                  %%
%% soul:     Gesperrt text. Optional.                               %%
%% footmisc: Extended footnote capabilities. Required.              %%
%%                                                                  %%
%% graphicx: Graphics inclusion. Required.                          %%
%% caption:  Caption enhancements. Required.                        %%
%%                                                                  %%
%% calc:     Infix arithmetic. Required.                            %%
%%                                                                  %%
%% fancyhdr: Enhanced running headers and footers. Required.        %%
%%                                                                  %%
%% geometry: Enhanced page layout package. Required.                %%
%% hyperref: Hypertext embellishments for pdf output. Required.     %%
%%                                                                  %%
%% Compilation Flags:                                               %%
%%                                                                  %%
%%   The following behavior may be controlled by boolean flags.     %%
%%                                                                  %%
%%   ForPrinting (false by default):                                %%
%%   Compile a screen-optimized PDF file. Set to true for print-    %%
%%   optimized file (two-sided layout, black hyperlinks).           %%
%%                                                                  %%
%% Summary of log file:                                             %%
%%   Four harmless overfull hboxes, six harmless underfull hboxes.  %%
%%                                                                  %%
%%                                                                  %%
%% PDF pages: 245                                                   %%
%%                                                                  %%
%% Compile History:                                                 %%
%%                                                                  %%
%% May 2011 (adhere). Compiled with pdflatex:                       %%
%%         [pdfeTeX, Version 3.141592-1.40.3 (Web2C 7.5.6)]         %%
%%                                                                  %%
%%    pdflatex x2                                                   %%
%%    makeindex                                                     %%
%%    pdflatex x2                                                   %%
%%                                                                  %%
%%                                                                  %%
%% June 2011: pglatex.                                              %%
%%   Compile this project with:                                     %%
%%   pdflatex 36310-t.tex ..... TWO times                           %%
%%   makeindex 36310-t.idx                                          %%
%%   pdflatex 36310-t.tex ..... TWO times                           %%
%%                                                                  %%
%%   pdfTeXk, Version 3.141592-1.40.3 (Web2C 7.5.6)                 %%
%%                                                                  %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\listfiles
\documentclass[12pt,leqno]{book}[2005/09/16]
\usepackage[latin1]{inputenc}[2006/05/05]
\usepackage[T1]{fontenc}
\usepackage[greek,ngerman]{babel}[2005/11/23]

\usepackage{amsmath}[2000/07/18]
\usepackage{amssymb}[2002/01/22]
\usepackage{mathrsfs}[1996/01/01]

\usepackage{ifthen}[2001/05/26]  %% Logical conditionals
\usepackage{alltt}[1997/06/16]

\IfFileExists{indentfirst.sty}{%
  \usepackage{indentfirst}[1995/11/23]
}{}

\usepackage{makeidx}[2000/03/29]
\usepackage{multicol}[2006/05/18]

\usepackage{array}[2005/08/23]
\usepackage{longtable}[2004/02/01]
\usepackage{multirow}

\IfFileExists{soul.sty}{%
  \usepackage{soul}[2003/11/17]
  \sodef{\so}{}{0.15em}{0.5em plus 0.25em}{0.5em plus 0.25em}%
}{%
  %% else change gesperrt to italics, which are not used elsewhere
  \newcommand\so[1]{\textit{#1}}%
}

\usepackage[perpage]{footmisc}[2005/03/17]

\usepackage{graphicx}[2006/02/20]
\usepackage[font=small,justification=centerfirst,labelformat=empty]{caption}[2007/01/07]

\usepackage{calc}[2005/08/06]

\usepackage{fancyhdr}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Interlude:  Set up PRINTING (default) or SCREEN VIEWING %%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% ForPrinting=true (default)           false
% Asymmetric margins                   Symmetric margins
% Black hyperlinks                     Blue hyperlinks
% Start Preface, ToC, etc. recto       No blank verso pages
%
% Chapter-like ``Sections'' start both recto and verso in the scanned
% book. This behavior has been retained.
\newboolean{ForPrinting}

%% UNCOMMENT the next line for a PRINT-OPTIMIZED VERSION of the text %%
%\setboolean{ForPrinting}{true}

%% Initialize values to ForPrinting=false
\newcommand{\Margins}{hmarginratio=1:1}     % Symmetric margins
\newcommand{\HLinkColor}{blue}              % Hyperlink color
\newcommand{\PDFPageLayout}{SinglePage}
\newcommand{\TransNote}{Anmerkungen der Korrekturleser}
\newcommand{\TransNoteCommon}{%
  Ein Exemplar des Originals wurde dankenswerterweise von der Cornell
  University Library: Historical Mathematics Monographs Collection
  zur Verfügung gestellt.
  \bigskip

  Kleinere typographische Korrekturen und Änderungen der Formatierung
  wurden stillschweigend vorgenommen.
  \bigskip
}

\newcommand{\TransNoteText}{%
  \TransNoteCommon

  Diese PDF-Datei wurde für die Anzeige auf einem Bildschirm
  optimiert, kann bei Bedarf aber leicht für den Druck angepasst
  werden. Anweisungen dazu finden Sie am Anfang des
  LaTeX-Quelltextes.
}
%% Re-set if ForPrinting=true
\ifthenelse{\boolean{ForPrinting}}{%
  \renewcommand{\Margins}{hmarginratio=2:3} % Asymmetric margins
  \renewcommand{\HLinkColor}{black}         % Hyperlink color
  \renewcommand{\PDFPageLayout}{TwoPageRight}
  \renewcommand{\TransNote}{Transcriber's Note}
  \renewcommand{\TransNoteText}{%
    \TransNoteCommon

    Diese PDF-Datei wurde für den Druck optimiert, kann bei Bedarf
    aber leicht für den Bildschirm angepasst werden. Anweisungen dazu
    finden Sie am Anfang des LaTeX-Quelltextes.
  }
}{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%  End of PRINTING/SCREEN VIEWING code; back to packages  %%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\ifthenelse{\boolean{ForPrinting}}{%
  \setlength{\paperwidth}{8.5in}%
  \setlength{\paperheight}{11in}%
  \usepackage[body={5in,8in},\Margins]{geometry}[2002/07/08]
}{% else, if ForPrinting=false
  \setlength{\paperwidth}{4.75in}%
  \setlength{\paperheight}{7in}%
  \renewcommand{\cleardoublepage}{\clearpage}
  \raggedbottom
  \usepackage[body={4.5in,6in},\Margins,includeheadfoot]{geometry}[2002/07/08]
}

\providecommand{\ebook}{00000}    % Overridden during white-washing
\usepackage[pdftex,
  hyperref,
  hyperfootnotes=false,
  pdftitle={The Project Gutenberg eBook \#\ebook: Die Analyse des Zufalls},
  pdfauthor={H. E. Timerding},
  pdfkeywords={Andrew D. Hwang, Ralf Stephan, Joshua Hutchinson,
               Project Gutenberg Online Distributed Proofreading Team,
               Cornell University Library Historical Mathematical Monographs Collection},
  pdfstartview=Fit,    % default value
  pdfstartpage=1,      % default value
  pdfpagemode=UseNone, % default value
  bookmarks=true,      % default value
  linktocpage=false,   % default value
  pdfpagelayout=\PDFPageLayout,
  pdfdisplaydoctitle,
  pdfpagelabels=true,
  bookmarksopen=true,
  bookmarksopenlevel=1,
  colorlinks=true,
  linkcolor=\HLinkColor]{hyperref}[2007/02/07]

%%%% Fixed-width environment to format PG boilerplate %%%%
\newenvironment{PGtext}{%
\begin{alltt}
\fontsize{8.1}{9}\ttfamily\selectfont}%
{\end{alltt}}

%% Miscellaneous spacing parameters
\renewcommand{\headrulewidth}{0pt}
\setlength{\headheight}{15pt}

\setlength{\textfloatsep}{12pt plus 4pt}

\setlength{\emergencystretch}{1em}
\setlength{\parindent}{2em}
\newcommand{\Indent}{\hspace*{2em}}

\newlength{\TmpLen}

\newcommand{\DPnote}[1]{}
\newcommand{\DPtypo}[2]{#2}
\newcommand{\DPPageSep}[2]{\ignorespaces}

% Decorative rules:
\newcommand{\tb}[1][1.5cm]{\begin{center}\rule{#1}{0.5pt}\end{center}}
% End of chapter mark
\newcommand{\EndChap}{\pagebreak[0]\tb[3cm]\pagebreak[3]}

\newcommand{\aaO}{a.\;a.\;O.}
\renewcommand{\dh}{d.\;h.}
\newcommand{\zB}{z.\;B.}

\newcommand{\PadTxt}[3][c]{%
  \settowidth{\TmpLen}{\text{#2}}%
  \makebox[\TmpLen][#1]{#3}%
}
\newcommand{\Ditto}[1][Jahre]{\PadTxt{#1}{''}}

\newcommand{\DotBox}[2][3cm]{\parbox[l]{#1}{#2\dotfill}}

\setlength{\doublerulesep}{1pt}
\newcolumntype{T}{!{\setlength{\arrayrulewidth}{2pt}\!\vline\!}}
\newcommand{\thsize}{\footnotesize}% Table heading font size
\newcommand{\thsmall}{\scriptsize}

\newcommand{\ColSkip}{\smallskip}

\newcommand{\ColHead}[2]{%
  \multicolumn{1}{c}{%
    \settowidth{\TmpLen}{\thsize\text{#1}}%
    \parbox[c]{\TmpLen}{\thsize\ColSkip\centering#2\ColSkip}%
  }
}
% Set column heads followed by one or two normal-width \vlines
\newcommand{\ColHeadb}[2]{%
  \multicolumn{1}{c|}{%
    \settowidth{\TmpLen}{\thsize\text{#1}}%
    \parbox[c]{\TmpLen}{\thsize\ColSkip\centering#2\ColSkip}%
  }
}
\newcommand{\ColHeadbb}[2]{%
  \multicolumn{1}{c||}{%
    \settowidth{\TmpLen}{\thsize\text{#1}}%
    \parbox[c]{\TmpLen}{\thsize\ColSkip\centering#2\ColSkip}%
  }
}

% Same, but followed with a thick \vline
\newcommand{\ColHeadB}[2]{%
  \multicolumn{1}{cT}{%
    \settowidth{\TmpLen}{\thsize\text{#1}}%
    \parbox[c]{\TmpLen}{\thsize\ColSkip\centering#2\ColSkip}%
  }
}

\newcounter{FigNo}
\newcommand{\Input}[2][0.9\textwidth]{%
  \refstepcounter{FigNo}
  \phantomsection\label{fig:\theFigNo}
  \includegraphics[width=#1]{./images/#2.png}
}
\newcommand{\Fig}[1]{\hyperref[fig:#1]{Fig.~#1}}

% Equation numbers: anchors and links
\newcommand{\Tag}[1]{%
  \phantomsection\label{eqn:\theChapNo:#1}%
  \tag*{#1}
}

\newcommand{\Eqref}[1]{\hyperref[eqn:\theChapNo:#1]{#1}}

% Miscellaneous notational conveniences
\DeclareInputMath{183}{\cdot}
\newcommand{\Dash}{\text{---}}
\newcommand{\EnDash}{\text{--}}

\renewcommand{\rho}{\varrho}
\renewcommand{\phi}{\varphi}
\renewcommand{\epsilon}{\varepsilon}

\newcommand{\frakx}{\mathfrak{x}}
\newcommand{\frakM}{\mathfrak{M}}

\newcommand{\Int}{\displaystyle\int}%[** TN: Original uses {\int\limits}]
\newcommand{\Sum}{\mathop{\textstyle\sum}\limits}
\newcommand{\Prod}{\mathop{\textstyle\prod}\limits}

\DeclareMathOperator{\tang}{tang}

\newcommand{\Z}{\phantom{0}}

% Adjust footnote markers
\makeatletter
\renewcommand\@makefnmark%
  {\mbox{\,\upshape\@textsuperscript{\normalfont\@thefnmark})}}

\renewcommand\@makefntext[1]%
  {\noindent\makebox[2.4em][r]{\@makefnmark\;}#1}
\makeatother

\newcommand{\SetRunningHeads}[2][]{%
  \fancyhf{}
  \thispagestyle{empty}
  \ifthenelse{\equal{#1}{}}{%
    \fancyhead[C]{\small #2.}
  }{
    \fancyhead[CE]{\small #1.}
    \fancyhead[CO]{\small #2.}
  }
  \ifthenelse{\boolean{ForPrinting}}
             {\fancyhead[RO,LE]{\thepage}}
             {\fancyhead[R]{\thepage}}
}

\newcommand{\BookMark}[2]{%
  \phantomsection%
  \pdfbookmark[#1]{#2.}{#2}%
}

\newcommand{\LicenseInit}{%
  \cleardoublepage
  \BookMark{0}{Lizenz}
  \SetRunningHeads{Lizenz}
}

% Index formatting
\makeindex
\newcommand{\PrintIndex}{%
  \backmatter
  \BookMark{-1}{Namenverzeichnis und Lizenz}
  \BookMark{0}{Namenverzeichnis}
  \printindex
}
\newcommand{\f}[1]{\hyperpage{#1}\,{f.}}
\newcommand{\ff}[1]{\hyperpage{#1}\,{ff.}}
\newcommand{\uo}[1]{\hyperpage{#1}\,{u.o.}}

\makeatletter
\renewcommand{\@idxitem}{\par\hangindent 30\p@\global\let\idxbrk\nobreak}
\renewcommand{\indexspace}{\par\penalty-3000 \vskip 10pt plus5pt minus3pt\relax}

\renewenvironment{theindex}{%
  \setlength\columnseprule{0.5pt}\setlength\columnsep{18pt}%
  \cleardoublepage
  \phantomsection
  \label{index}
  \addtocontents{toc}{\protect\ToCLine{\protect\so{Namenverzeichnis}}{index}}
  \addtocontents{toc}{\protect\EndChap}
  \SetRunningHeads{Namenverzeichnis}
% ** N.B. font size
  \begin{multicols}{2}[%
    \subsection*{\centering\Large\textbf{Namenverzeichnis.}}%
    \subsubsection*{\centering\normalfont\footnotesize(Die Zahlen bedeuten die Seiten.)}%
    \small]
    \setlength\parindent{0pt}\setlength\parskip{0pt plus 0.3pt}%
    \thispagestyle{empty}\let\item\@idxitem\raggedright%
  }{%
  \end{multicols}\EndChap
}
\makeatother


% ToC formatting
\AtBeginDocument{\renewcommand{\contentsname}%
  {\protect\thispagestyle{empty}%
    \protect\centering\normalfont\Large\textbf{INHALT.}%
    \protect\BookMark{0}{Inhaltsverzeichnis}}}

\newcommand{\ToCBox}[1]{%
  \settowidth{\TmpLen}{Siebentes Kapitel: }%
  \makebox[\TmpLen][l]{#1:}%
}

\newcommand{\ToCLine}[3][]{%
  \ifthenelse{\equal{#3}{chapter:1}}{%
    \noindent\makebox[\textwidth][r]{\scriptsize Seite}\\%
  }{}%
  \settowidth{\TmpLen}{999}%
  \ifthenelse{\not\equal{#1}{}}{%
    \noindent\strut\parbox[b]{\textwidth-\TmpLen}{%
      \raggedright\hangindent10em\ToCBox{#1}#2\dotfill}%
  }{%
    \noindent\strut\parbox[b]{\textwidth-\TmpLen}{%
      \raggedright\hangindent10em#2\dotfill}%
  }%
  \makebox[\TmpLen][r]{\pageref{#3}}\\[4pt]%
}

\newcommand{\TitleBox}[3]{%
  \textbf{\Huge #1}
  \medskip

  \settowidth{\TmpLen}{\textbf{\Huge #1}}%
  \parbox[s]{\TmpLen}{\footnotesize #2}%
  \medskip

  {\footnotesize #3}%
}

\newcommand{\Signature}[2]{%
  \pagebreak[0]
  \noindent\parbox[t]{\textwidth}{\medskip\Indent#1\\[2\baselineskip]\null\hfill\textbf{#2}\Indent}%
  \pagebreak[3]
}

\newcommand{\Section}[2][]{%
  \thispagestyle{empty}
  \ifthenelse{\equal{#1}{}}{%
    \subsection*{\centering\Large #2}
  }{%
    \subsection*{\centering\normalsize\textbf{#1}}
    \subsubsection*{\centering\Large\textbf{#2}}
  }
  \tb[0.75cm]
}

\newcommand{\Vorwort}{%
  \cleardoublepage
  \BookMark{0}{Vorwort}
  \pagestyle{fancy}
  \SetRunningHeads{Vorwort}
  \vspace*{1cm}
  \Section{VORWORT.}
}

\newcounter{ChapNo}
\newcommand{\Chapter}[2]{%
  \cleardoublepage
  \phantomsection
  \refstepcounter{ChapNo}
  \label{chapter:\theChapNo}
  \pdfbookmark[0]{#1: #2.}{chapter:\theChapNo}
  \addtocontents{toc}{\protect\ToCLine[#1]{#2}{chapter:\theChapNo}}
  \SetRunningHeads[#1]{#2}
  \Section[#1.]{#2.}
}

%%%% Begin document %%%%
\begin{document}

\pagestyle{empty}
\pagenumbering{Alph}
\BookMark{-1}{Anfang}
%%%% PG BOILERPLATE %%%%
\BookMark{0}{PG Titelblatt}
\begin{center}
\begin{minipage}{\textwidth}
\small
\begin{PGtext}
The Project Gutenberg EBook of Die Analyse des Zufalls, by 
H. E. (Heinrich Emil) Timerding

This eBook is for the use of anyone anywhere at no cost and with
almost no restrictions whatsoever.  You may copy it, give it away or
re-use it under the terms of the Project Gutenberg License included
with this eBook or online at www.gutenberg.net


Title: Die Analyse des Zufalls

Author: H. E. (Heinrich Emil) Timerding

Release Date: June 6, 2011 [EBook #36310]

Language: German

Character set encoding: ISO-8859-1

*** START OF THIS PROJECT GUTENBERG EBOOK DIE ANALYSE DES ZUFALLS ***
\end{PGtext}
\end{minipage}
\end{center}
\clearpage
%%%% Credits %%%%
\begin{center}
\begin{minipage}{\textwidth}
\begin{PGtext}
Produced by Andrew D. Hwang, R. Stephan, Joshua Hutchinson,
and the Online Distributed Proofreading Team at
http://www.pgdp.net. (This ebook was produced using images
provided by the Cornell University Library Historical
Mathematics Monographs collection.)
\end{PGtext}
\end{minipage}
\end{center}
\vfill
\begin{minipage}{0.85\textwidth}
\small
\BookMark{0}{Anmerkungen zur Transkription}
\subsection*{\centering\normalfont\scshape%
\normalsize\MakeLowercase{\TransNote}}%
\raggedright
\TransNoteText
\end{minipage}
%%%%%%%%%%%%%%%%%%%%%%%%%%% FRONT MATTER %%%%%%%%%%%%%%%%%%%%%%%%%%
\DPPageSep{001}{}
%[Blank Page]
\DPPageSep{002}{}
%[Blank Page]
\DPPageSep{003}{}
%[** Library stamp]
\iffalse
Cornell University Library

BOUGHT WITH THE INCOME OF THE
SAGE ENDOWMENT FUND
THE GIFT OF
Henry W. Sage
1891
MATHEMATICS
\fi
\DPPageSep{004}{}
%[Blank Page]
\DPPageSep{005}{i}
\frontmatter
\pagenumbering{Roman}
%[Blank Page]
\DPPageSep{006}{ii}
%title page
\begin{center}
%[** TN: Hard-coded inter-word space to coax alignment of second argument]
\TitleBox{DIE\quad WISSENSCHAFT}
  {SAMMLUNG VON EINZELDARSTELLUNGEN AUS DEN GEBIETEN
  DER NATURWISSENSCHAFT UND DER TECHNIK}{BAND 56}
\vfill

\textbf{\Large H. E. TIMERDING}
\medskip

\tb
\bigskip

\textbf{\LARGE DIE ANALYSE DES ZUFALLS}
\vfill

\footnotesize
MIT 10 ABBILDUNGEN
\vfill
%[** publisher's device]
\includegraphics[width=3cm]{./images/006.png}
\vfill

\textbf{\large BRAUNSCHWEIG}
\medskip

DRUCK UND VERLAG VON FRIEDR. VIEWEG \&~SOHN
\medskip

\normalsize
1915
\end{center}
\clearpage
\DPPageSep{007}{iii}
%[** TN: Omit second title page]
\iffalse
DIE ANALYSE DES ZUFALLS

VON

H. E. TIMERDING

MIT 10 ABBILDUNGEN

BRAUNSCHWEIG

DRUCK UND VERLAG VON FRIEDR. VIEWEG \& SOHN

1915
\fi
\DPPageSep{008}{iv}
%copyright page
\null\vfill
\begin{center}
\hrule
\footnotesize
\bigskip
Alle Rechte, \\
namentlich das Recht der Übersetzung in fremde Sprachen, vorbehalten.
\tb

Copyright, 1915, by \so{Friedr}.\ \so{Vieweg} \&~\so{Sohn}, \\
Braunschweig, Germany.
\bigskip

\hrule
\end{center}
\vfill
\DPPageSep{009}{v}


\Vorwort

Das Problem des Zufalls ist an sich ein metaphysisches
Problem. Es ist es wenigstens, wenn wir Metaphysik als die
Theorie des Geschehens auffassen. Die Behandlung des Zufalls
scheint daher auch nur nach den alten metaphysischen
Methoden möglich, nämlich so, daß für das Geschehen in
der Welt eine innerliche Erklärung gesucht wird. Je nachdem,
wie diese Erklärung ausfällt, wird die Existenz des Zufalls
bejaht oder verneint werden. Auf diese Weise soll aber das
Problem des Zufalls hier nicht behandelt werden. Vielmehr
soll gerade die naturwissenschaftliche Methode auf dieses
Problem angewendet werden. Diese Methode hat im Gegensatz
zu der Metaphysik der alten Schulphilosophie das Bezeichnende,
daß sie über den Bereich der Erfahrung nicht hinausgeht.
Sie besteht zunächst darin, daß die Erscheinungen, die sich
unserer Erfahrung darbieten, sorgfältig beobachtet und geordnet
werden, indem wir verwandte Erscheinungen zusammenfassen,
das Gemeinsame an ihnen herausheben und,
wenn wir eine ständige Wiederkehr einer gewissen Gemeinsamkeit
beobachten, diese als eine Gesetzmäßigkeit in den
Erscheinungen aufzeichnen. Nach dieser Methode haben wir
versucht auch hier vorzugehen. Es handelt sich dann nur
darum, die Erscheinungen herauszugreifen, die wir als zufällige
bezeichnen, und das Gemeinsame an ihnen zu suchen.
Dieses Gemeinsame würde innerhalb der Grenzen der Beobachtung
das Wesen des Zufalls ausmachen.

Die naturwissenschaftliche Methode geht aber doch noch
weiter, indem sie sich ein bestimmtes Bild von den Vorgängen
zu machen sucht, die als von gleicher Art zusammengefaßt
werden. Dieses wird erreicht, indem man einen besonders
\DPPageSep{010}{vi}
einfachen oder übersichtlichen Vorgang unter den
zu einer Gruppe zusammengefaßten herausgreift oder indem
man zu den wirklich beobachteten noch einen erdichteten
Vorgang, ein schematisches Bild, das alle gemeinsamen Züge
der wirklich beobachteten Vorgänge zeigt, hinzufügt. Auf
der Herstellung solcher schematischer Bilder beruht wesentlich
die Anwendung der Mathematik auf Naturvorgänge.
Diese Anwendung der Mathematik bildet auch für uns den
Hauptzielpunkt. Deswegen sind wir auch hier auf die Herstellung
schematischer Bilder für die als zufällig bezeichneten
Vorgänge angewiesen. Auf ihnen baut sich die sogenannte
Wahrscheinlichkeitsrechnung auf, so wie sie sich
im Laufe der drei letzten Jahrhunderte entwickelt hat. Bei
dieser Entwickelung sind allerdings lange Zeit auch ontologische
Gesichtspunkte maßgebend gewesen, wenngleich
dies selten unumwunden eingeräumt wurde. Erst die um
die Mitte des vorigen Jahrhunderts (man kann sagen, mit
J.~F.~\so{Fries}' Versuch einer Kritik der Prinzipien der Wahrscheinlichkeitsrechnung,
\index{Fries@Fries, J. F.}%
Braunschweig~1842) einsetzende
Kritik hat nach und nach die ontologischen Bestandteile
als solche erkannt und nach Möglichkeit ausgeschieden.

Die Begriffe sind aber auch heute noch nicht so geklärt,
daß sie keiner weiteren Erörterung mehr bedürfen. Deswegen
schien es in der vorliegenden Darstellung geboten,
mit der größten Vorsicht vorzugehen und den begrifflichen
Erörterungen einen breiteren Raum zu gewähren. So sind,
rein äußerlich genommen, die mathematischen Entwickelungen
nur auf einen kleinen Teil des Buches beschränkt,
und hierin liegt vielleicht ein gewisser Vorzug, da auf diese
Weise auch der Leser, der in der Mathematik weniger zu
Hause ist, auf seine Rechnung kommen kann, wenn er nur
die wenigen Kapitel, welche die eigentlichen analytischen
Entwickelungen enthalten, überschlägt. Was das Buch an
\DPPageSep{011}{vii}
begrifflicher Klärung zu geben sucht, wird er auch so im
vollen Umfange finden. Über ein gewisses Maß hinaus ließen
sich leider die mathematischen Ableitungen nicht vereinfachen.
Ich habe sie auf das Notwendigste beschränkt und
mich bemüht, nur die gewöhnlichsten Elemente der höheren
Analysis als bekannt vorauszusetzen, und wenn jemand sich
die Mühe machen sollte, das, was er an analytischen Entwickelungen
hier findet, durch die Literatur hindurch zu verfolgen,
so wird er feststellen können, daß durch diese kurze
Zusammenfassung immerhin eine ziemliche Vereinfachung
erreicht ist. Es ist kaum möglich, ohne eigene ergänzende
Arbeit sich durch die unsäglich verwickelten und umfangreichen
Ableitungen hindurch zu winden, die an keiner
Stelle vereinigt sind und deren Resultate meist benutzt
werden, ohne auf die Ableitung selbst noch einmal einzugehen.
Dadurch geht aber die wirkliche Übersicht über den mathematischen
Gehalt dieser Theorie verloren, und eine solche
Übersicht auf möglichst knappem Raum zu geben, schien
nicht ohne Verdienst zu sein.

Es ist vielleicht gut, noch einmal zu wiederholen, daß
es sich hier nicht um eine Darstellung des Inhaltes der
Wahrscheinlichkeitsrechnung und auch nicht der Disziplin,
die wir seit \so{Fechners} grundlegendem Werke als Kollektivmaßlehre
bezeichnen, handelt, sondern daß wirklich nur die
Klärung eines bestimmten Begriffes die Aufgabe sein soll.
Hierbei schien es nötig, den rein kritischen Standpunkt
möglichst zu wahren, selbst wenn auf diese Weise die schließlich
gewonnenen Resultate in ihrer philosophischen Bedeutung
hinter den Erwartungen manches Lesers zurückbleiben.
Andererseits darf man doch behaupten, daß sich kaum
irgendwo eine Gelegenheit findet, in das Wesen der Dinge
durch exakte Methoden so tief einzudringen wie hier. Es
fragt sich nur, mit welcher Stufe der Erkenntnis man sich
\DPPageSep{012}{viii}
zufrieden geben will. Je kritischer ein Mensch gestimmt
ist, um so bescheidener und zurückhaltender wird er sein,
wenn er sich das Eindringen in die Ordnung der Natur zur
Aufgabe macht.

Bei den Grenzen, die dem Umfang der vorliegenden
Schrift gesteckt waren, ließ es sich nicht vermeiden, daß
manches nur skizzenhaft geblieben ist. Vielleicht liegt hierin
aber kein zu großer Fehler, da das Anregen zum eigenen
Nachdenken doch die Hauptaufgabe bleiben muß und die
sehr breit gehaltene Darstellung der meisten Untersuchungen
über die Grundlagen der Wahrscheinlichkeitsrechnung die
leitenden Gesichtspunkte manchmal mehr verhüllt als klar
hervortreten läßt. Die Literaturangaben, die ich mache,
sollen in keiner Weise Vollständigkeit beanspruchen, sie sollen
nur den Anschluß an die neueren literarischen Erscheinungen
auf dem behandelten Gebiete zu erreichen suchen.

Das Buch lag in der Handschrift vollendet vor, als der
Krieg ausbrach. Was wir seither mit tiefer Erschütterung
erfahren haben, hat uns eindringlicher als je "`des Zufalls
grausende Wunder"' vor Augen geführt, waltet er doch auch
in der todbringenden Wirkung der Geschosse. Die Theorie
des Zufalls, die wir hier entwickeln, hat in der Tat auf das
Schießwesen eine fruchtbare Anwendung gefunden. Ich
will nur auf die beiden Werke: \so{Sabudski-Eberhard},
\index{Sabudski-Eberhard}%
Die Wahrscheinlichkeitsrechnung, ihre Anwendung auf das
Schießen und auf die Theorie des Einschießens, Stuttgart~1906,
und \so{Kozak}, Theorie des Schießwesens auf Grundlage der
\index{Kozak}%
Wahrscheinlichkeitsrechnung und Fehlertheorie, Wien~1908,
verweisen.

\Signature{\so{Braunschweig}, im Februar 1915.}{H.~E. Timerding.}
\DPPageSep{013}{ix}

\tableofcontents
\iffalse
Seite

Erstes Kapitel:  Der Begriff des Zufalls ............  1

Zweites Kapitel: Die statistische Methode ........... 13

Drittes Kapitel: Stationäre Zahlenreihen ........... 21

Viertes Kapitel: Das "`Gesetz der großen Zahlen"' ....... 35

Fünftes Kapitel: Die Theorie der Glücksspiele ......... 50

Sechstes Kapitel: Die mathematische Analyse stationärer Reihen . 69

Siebentes Kapitel: Das Urnenschema .............. 91

Achtes Kapitel: Näherungsformeln .............. 105

Neuntes Kapitel: Die statistische Theorie des Zufalls ...... 134

Zehntes Kapitel: Die genetische Theorie des Zufalls ...... 154

Namenverzeichnis ..................... 168
\fi
\DPPageSep{014}{x}
%[Blank Page]
\DPPageSep{015}{1}
\mainmatter
\BookMark{-1}{Hauptteil}


\Chapter{Erstes Kapitel}{Der Begriff des Zufalls}

Was wir als Analyse des Zufalls bezeichnen, bedeutet nicht
den Versuch, in das innere Wesen der Zufallsereignisse an sich
einzudringen, es bedeutet vielmehr den Nachweis, daß auch
sie, wenn wir sie in ihrer Gesamtheit fassen, einer bestimmten
methodischen Behandlung fähig sind, und daß auch in diesen zunächst
jeder Gesetzmäßigkeit zu spotten scheinenden Ereignissen
eine gewisse Regelmäßigkeit erkennbar ist, wenn wir nicht das
einzelne Ereignis für sich, sondern den Einfluß aller gleich gearteten
Ereignisse auf das Weltgeschehen ins Auge fassen. Daß
das Wort Zufall den direkten Gegensatz zu Gesetzmäßigkeit bedeutet,
ist wohl die allgemeine Ansicht. Wir finden sie \zB~in
\so{John Stuart Mill}s Logik (Buch~III, Kap.~17) klar ausgesprochen,
\index{Mill@Mill, John Stuart|f}%
wo es heißt: "`Von Zufall wird gewöhnlich im direkten Gegensatz
zu Gesetz gesprochen. Was, so sagt man, keinem Gesetz zugeschrieben
werden kann, wird als zufällig angesehen. Es ist indessen
gewiß, daß alles, was geschieht, das Resultat eines Gesetzes
ist, \dh~die Wirkung von Ursachen, und aus einer Kenntnis des
Vorhandenseins dieser Ursachen heraus und ihren Gesetzen gemäß
vorausgesagt hätte werden können. Wenn wir eine bestimmte
Karte ziehen, ist dies eine Folge von ihrer Lage in dem Haufen.
Ihre Lage in dem Haufen war eine Folge von der Art, wie die
Karten gemischt wurden oder der Reihenfolge, in der sie bei dem
letzten Spiel ausgespielt wurden, und dies wieder Folgen früherer
Ursachen. In jedem Stadium wäre es, wenn wir eine genaue
Kenntnis der vorhandenen Ursachen besessen hätten, möglich gewesen,
die Wirkung vorauszusagen.

"`Ein zufällig eintretendes Ereignis läßt sich besser als ein
Zusammentreffen beschreiben, aus dem wir keine Regelmäßigkeit
schließen können, also als das Eintreten einer Erscheinung unter
\DPPageSep{016}{2}
bestimmten Umständen, ohne daß wir Grund haben zu schließen,
dieselbe Erscheinung würde unter diesen Umständen immer wieder
eintreten. Wenn wir näher zusehen, bedeutet dies aber, daß die
Aufzählung der Umstände nicht vollständig war. Was auch das
Ereignis sei, wenn alle Umstände sich wiederholen, würde sich
auch das Ereignis wiederholen, ja selbst dann, wenn nur die Umstände
sich wiederholen, auf welche das Ereignis immer folgt. Mit
den meisten der Umstände ist das Ereignis aber nicht beständig
verknüpft, ihre Verbindung mit ihm heißt dann zufällig. Zufällig
verknüpfte Ereignisse sind einzeln die Wirkungen von Ursachen
und deshalb von Gesetzen, aber von verschiedenen Ursachen und
solchen, die unter sich durch kein Gesetz verknüpft sind.

"`Es ist deshalb unrichtig zu sagen, daß ein Ereignis durch
Zufall herbeigeführt wird, aber wir können sagen, daß zwei oder
mehr Ereignisse durch Zufall verknüpft sind, daß sie nur durch
Zufall zusammen bestehen oder aufeinander folgen, \dh~daß sie
in keiner Weise ursächlich verknüpft sind, daß sie weder Ursache
und Wirkung noch Wirkungen derselben Ursache noch Wirkungen
unter sich gesetzmäßig verknüpfter Ursachen sind."'

Der Begriff erscheint hiermit zugleich in eine Form gebracht,
in der er sich mit der durchgängigen Gesetzmäßigkeit alles Naturgeschehens,
welche die moderne Wissenschaft annimmt, in Einklang
bringen läßt. Die Auffassung, die \so{John Stuart Mill} hier
befürwortet, findet sich schon früher bei \so{Schopenhauer} ausgesprochen,
\index{Schopenhauer}%
der in seinem Hauptwerk Die Welt als Wille und
Vorstellung (3.~Aufl.\ 1859, Bd.~1, S.~550) sagt: "`Das kontradiktorische
Gegenteil, \dh~die Verneinung der Notwendigkeit ist
die Zufälligkeit. Der Inhalt dieses Begriffes ist daher negativ,
nämlich weiter nichts als dieses: Mangel der durch den Satz vom
Grunde ausgedrückten Verbindung. Folglich ist auch das Zufällige
immer nur relativ: nämlich in bezug auf etwas, das nicht
sein Grund ist, ist es ein solches. Jedes Objekt, von welcher Art
es auch sei, \zB~jede Begebenheit in der wirklichen Welt, ist
allemal notwendig und zufällig zugleich: notwendig in der Beziehung
auf das eine, das ihre Ursache ist; zufällig in Beziehung
auf alles übrige. Denn ihre Berührung in Zeit und Raum mit
allem übrigen ist ein bloßes Zusammentreffen, ohne notwendige
Verbindung, daher auch die Wörter Zufall, \textgreek{sumbebhk'os}, contingens.
So wenig daher, wie ein absolut Notwendiges, ist ein absolut
\DPPageSep{017}{3}
Zufälliges denkbar. Denn dieses letztere wäre eben ein
Objekt, welches zu keinem anderen im Verhältnis der Folge zum
Grunde stände. Die Unvorstellbarkeit eines solchen ist aber
gerade der negativ ausgedrückte Inhalt des Satzes vom Grunde,
welcher also erst umgestoßen werden müßte, um ein absolut Zufälliges
zu denken: dieses selbst hätte aber alsdann auch alle Bedeutung
verloren, da der Begriff des Zufälligen solche nur in Beziehung
auf jenen Satz hat, und bedeutet, daß zwei Objekte nicht
im Verhältnis von Grund und Folge zueinander stehen. In der
Natur, sofern sie anschauliche Vorstellung ist, ist alles, was geschieht,
notwendig, denn es geht aus seiner Ursache hervor. Betrachten
wir aber dieses Einzelne in Beziehung auf das Übrige,
welches nicht seine Ursache ist, so erkennen wir es als zufällig;
dies ist aber schon eine abstrakte Reflexion."'

Diese "`abstrakte Reflexion"', die einerseits den Begriff des
Zufälligen auf alle Ereignisse ausdehnt, ihn aber anderseits rein
\so{relativ} wendet, indem immer nur ein Ereignis in bezug auf ein
anderes oder das räumliche oder zeitliche Zusammentreffen zweier
Ereignisse als zufällig bezeichnet werden kann, unterliegt aber
doch einigen Bedenken. Zunächst nämlich bedeutet der durchgängige
Zusammenhang alles Geschehens nicht, daß zu jedem Ereignis
ein anderes gefunden werden kann, das von jenem die
"`Ursache"' ist, während mit allen anderen Ereignissen kein solcher
Zusammenhang besteht, sondern die ursächliche Verknüpfung durchzieht
den Bereich aller Vorgänge in der Welt. Eine Abänderung
des Geschehens an irgend einer Stelle würde sich in ihren Folgen
über die ganze Welt ausbreiten. Es ist dies das Prinzip, das
\so{Kant} als Prinzip der Wechselwirkung in aller Schärfe formuliert
\index{Kant}%
hat. Nach diesem Prinzip würde ein Zufall im strengen Sinne
des Wortes auch dann unmöglich sein, wenn man den Begriff in
der angegebenen Weise nur relativ fassen will. Er läßt sich nur
so rechtfertigen, daß man durch das Zufallsurteil bloß das Fehlen
einer \so{engeren} kausalen Verknüpfung aussprechen will, ähnlich
wie man bei zwei Menschen sagt, sie seien nicht verwandt, auch
wenn sich, indem man weit genug in der Ahnenreihe zurückgeht,
eine genealogische Beziehung zwischen ihnen finden läßt.

Man könnte ferner den Einwand erheben, daß der Begriff
des Zufalls auf diese Weise viel enger gefaßt wird, wie es dem allgemeinen
Gebrauch des Wortes entspricht. Denn dieses soll hier
\DPPageSep{018}{4}
nur auf das Zusammentreffen zweier Ereignisse angewandt werden,
es wird aber ohne Zweifel auch von einem einzelnen Ereignis gebraucht.
Man kann sogar ohne weiteres die erste Bedeutung
unter der zweiten als besonderen Fall begreifen, indem man dann
eben das Zusammentreffen zweier bestimmter Geschehnisse als
das Zufallsereignis ansieht. Ein jedes Ereignis ist ja im Grunde
aus verschiedenen Momenten zusammengesetzt, die sich nur nicht
immer bequem trennen lassen, so daß es keine künstliche und
willkürliche Ausdeutung ist, wenn man auch \zB~den Witterungsumschlag
bei Mondwechsel als ein Ereignis ansieht.

Auf diese allgemeinere Fassung des Begriffes "`Ereignis"' als
eines beliebigen Ausschnittes aus dem Weltgeschehen läßt sich
allerdings die \so{Schopenhauer}sche Auffassung sofort übertragen.
Sie bedeutet, daß das Ereignis als zufällig bezeichnet wird, wenn in
ihm mehrere voneinander unabhängige Kausalreihen zusammenstoßen.
Ganz in diesem Sinne sagt auch \zB~\so{Cournot} (Exposition
\index{Cournot}%
de la théorie des chances et des probabilités, Paris 1843): "`L'idée
du hasard est celle du concours de causes indépendantes pour la
production d'un évènement déterminé."'

Die Frage bleibt aber: Wie sollen wir die zwei voneinander
unabhängigen Kausalreihen auffassen? Müssen wir nicht sagen,
wir nennen die Kausalreihen nur darum voneinander unabhängig,
weil wir ihren Zusammenhang in dem vorliegenden besonderen
Falle nicht erkennen können? Dann entspringt das Zufallsurteil
nur einer Unvollkommenheit unserer Erkenntnis, und in dieser
\so{subjektiven} Form sind die Zufallsurteile auch häufig aufgefaßt
worden.

Schon an der Schwelle der neueren Philosophie hat \so{Spinoza}
\index{Spinoza}%
aus dem allgemeinen Gesetz der Kausalität die Folgerung gezogen
(Ethik~I, Prop.~29): "`In der Natur gibt es nichts Zufälliges."' In
dem Scholion zu Prop.~33 sagt er weiter: "`Zufällig wird ein Ding
nur wegen unserer mangelhaften Erkenntnis genannt."' Danach
definiert er den Zufall: "`Ein Ding, von dem wir nicht wissen, ob
sein Wesen einen Widerspruch in sich schließt oder von dem wir
gewiß wissen, daß es keinen Widerspruch in sich schließt, ohne
aber über seine Existenz etwas Sicheres behaupten zu können,
weil die Ordnung der Ursachen uns verborgen ist, ein solches Ding
kann uns weder als notwendig noch als unmöglich erscheinen und
darum nennen wir es entweder zufällig oder möglich"' (möglich
\DPPageSep{019}{5}
offenbar, wenn seine Wirklichkeit unbekannt ist, zufällig, wenn
sein Vorhandensein feststeht). In ähnlichem Sinne sagt \so{Hume}
\index{Hume}%
(Philosophical Essays concerning human understanding): "`Obwohl
es nicht so etwas wie den Zufall in der Welt gibt, so hat doch
unsere Unbekanntschaft mit der wirklichen Ursache denselben
Einfluß auf die Erkenntnis und erzeugt eine solche Art von Glauben
oder Meinung, als ob es einen Zufall gäbe."'

Ob man so den Zufallsbegriff rein subjektiv faßt, indem man
ihn auf eine Unvollkommenheit unserer Erkenntnis zurückführt,
oder ob man ihm eine relative Bedeutung auch im objektiven Sinne
läßt, indem man nicht unsere mangelnde Einsicht in das Zustandekommen
des Ereignisses, sondern bei dem wirklichen Zustandekommen
eine gewisse Besonderheit, eine gewisse Unabhängigkeit
der verschiedenen Ursachen betont, immer hat der
Zufall als Gegenteil der Notwendigkeit an sich keine absolute
Bedeutung, solange man an dem Kausalitätsprinzip festhält, daß
jedes Geschehen in der Welt durch seine Ursachen mit Notwendigkeit
bestimmt ist.

Wenn wir aber den landläufigen Gebrauch des Wortes Zufall
ansehen, so ist noch immer nicht der eigentliche Kernpunkt
berührt. Was den Begriff des Zufalls nahelegt, ist nicht das
Fehlen einer Ursache, sondern das Mißverhältnis zwischen der
Ursache und der Wirkung, wenn wir sie nach ihrer Bedeutung
für uns selbst beurteilen. Wenn ein Spieler sein Hab und Gut auf
einen Wurf setzt, so wird es wenig für ihn ausmachen, daß der
Würfel nach bestimmten mechanischen Gesetzen seine Bewegung
ausführt, und daß so auch seine Endlage bestimmt ist. Die Einzelheiten
bei dem Vorgang des Würfelns sind so geringfügig und unkontrollierbar,
das Resultat aber ist so bestimmend für das Wohl
und Wehe des Spielers, daß die naturgesetzliche Notwendigkeit
beim Rollen des Würfels ganz außer Betracht bleibt. Das, was
wir im Leben Zufall nennen, bedeutet, wenn wir an dem naturwissenschaftlichen
Standpunkt festhalten, eine den menschlichen
Verhältnissen gegenüber empfundene krasse Ungleichwertigkeit
der Ursache und der Wirkung.

Gerade solche Ereignisse, wo ein ursächlicher Zusammenhang
durch die nach den Grundsätzen der exakten Wissenschaft geleitete
Erfahrung wohl angenommen werden kann, aber die Wirkung
eine unverhältnismäßig große ist, wie bei einer Feuersbrunst,
\DPPageSep{020}{6}
die ein vom Winde verwehter Funke hervorruft, geben jedoch
einen neuen Anlaß, den Zufall zu leugnen. Diese Leugnung beruht
auf einer Beseitigung der Erklärung alles Weltgeschehens
nach den Grundsätzen der kausalen Notwendigkeit und einer an
die Stelle dieser Erklärung tretenden Zwecksetzung in allen Vorkommnissen
des menschlichen und außermenschlichen Lebens, mit
anderen Worten, auf der Vertauschung des ätiologischen mit dem
teleologischen Standpunkt. Wenn wir dort von einer \so{Wirkung}
sprechen, reden wir hier von einer \so{Schickung}. Die Ereignisse des
Würfelspieles sind typisch zufällig, was das natürliche Zustandekommen
betrifft. Nach Möglichkeit sind alle Ursachen entfernt,
die auf das Eintreten eines bestimmten Wurfes hinwirken. Und
doch, wenn jemand an einem Tage durch fortgesetzte unglückliche
Würfe erhebliche Verluste erleidet, sagt er nicht: das war Zufall,
sondern: ich habe heute kein Glück. An Roulettetischen beobachten
die Spieler die Spielerfolge, bis sie selbst mitspielen. Sie
glauben dann zu finden, daß an einem Tage eine bestimmte Zahl
begünstigt sei und setzen auf diese. Eine solche Begünstigung
kann, wenn sie vorhanden ist, offenbar nicht auf denselben Grundsätzen
beruhen, auf denen wir die Naturwissenschaft aufbauen.
Es handelt sich nicht um einen physikalischen Einfluß (influxus
physicus), sondern eine metaphysische Wirkung (influxus metaphysicus).
Diese Auffassung wird uns in allen Fällen besonders
nahegelegt, wo es sich um Ereignisse handelt, die auf das Leben
der Menschen eine einschneidende Wirkung ausüben, und wo damit
das Mißverhältnis um so empfindlicher wird zwischen der Bedeutung
der Wirkung und der scheinbar sinnlosen Verkettung von
Umständen, welche diese Wirkung herbeigeführt haben. Wir
ersetzen dann die fehlende Ursache durch einen Grund, der sich
unserer Erkenntnis entzieht, den wir nur annehmen und als
Schicksal bezeichnen. Diesen Gedanken hat \zB~\so{Goethe}, dem
\index{Goethe}%
sonst die metaphysische Spekulation wenig lag, mit großer Liebe
gepflegt. Er sah das Walten des Schicksals auch da, wo es
scheinbar als Zufall auftritt. Was die Menschen so nennen, ist
eben Gott, der hier unmittelbar mit seiner Allmacht eintritt und
das Geringfügigste verherrlicht (vgl.\ \so{Siebeck}, Goethe als Denker,
\index{Siebeck}%
2.~Aufl.\ 1905, S.~143).

Dagegen äußerte schon \so{Spinoza} über diejenigen, welche alles
\index{Spinoza|f}%
Geschehen auf den Willen Gottes zurückführen (Ethik~I, Anhang):
\DPPageSep{021}{7}
"`Es darf nicht unerwähnt bleiben, daß Anhänger dieser Lehre, welche
im Angeben der \so{Zwecke} der Dinge ihren Scharfsinn zeigen wollen,
eine neue Art der Beweisführung aufgebracht haben, um diese ihre
Lehre glaublich zu machen. Sie führen diese nämlich nicht auf
die Unmöglichkeit, sondern auf die Unwissenheit zurück; was zeigt,
daß ihnen kein anderes Beweismittel für diese Lehre zu Gebote
stand. Wenn \zB~ein Stein von einem Dache auf den Kopf eines
Menschen fällt und ihn tötet, so beweisen sie, der erwähnten
Methode gemäß, daß der Stein gefallen sei, um den Menschen zu
töten, folgendermaßen: Wäre der Stein nicht zu eben diesem
Zwecke nach dem Willen Gottes heruntergefallen, wie mochten da
so viele Umstände (denn oft treffen viele zusammen) durch Zufall
zusammentreffen? Antwortet man, es sei so gekommen, weil der
Wind wehte, und weil der Mensch gerade dort vorbeiging, so
wenden sie dagegen ein: Weshalb hat der Wind gerade damals
geweht? Warum ist der Mensch gerade damals dort vorbeigegangen?
Erwidert man darauf: Der Wind fing damals zu wehen
an, weil das Meer tags zuvor, bei noch ruhigem Wetter, in Bewegung
kam, und der Mensch ging damals dort vorbei, weil er
von einem Freunde eingeladen war, so wenden sie --- da das
Fragen keine Grenzen hat --- abermals ein: Warum aber kam das
Meer in Bewegung? Warum war der Mensch damals eingeladen?
Und so werden sie nicht aufhören, fort und fort nach den Ursachen
der Ursachen zu fragen, bis man zum Willen Gottes seine
Zuflucht nimmt, \dh~zum Asyl der Unwissenheit."'

Der Kern des angewendeten Beweisganges wäre sonach der:
Wir können in dem Geschehen keinen nach menschlichen Begriffen
vernünftigen Sinn erkennen, wenn wir nicht annehmen, daß eine
bestimmte, allerdings uns verborgene Absichtlichkeit und Zweckmäßigkeit
in den Begebenheiten liegt, die unser Leben entscheidend
beeinflussen. Unter dem Einfluß der Naturwissenschaften sind
wir geneigt, einer solchen Auffassung wenigstens in ihrer Anwendung
auf die Vorgänge in der Natur jede Berechtigung abzusprechen,
vielmehr suchen wir diese Vorgänge nach anderen
Grundsätzen zu erfassen, die sich auf der Vorstellung eines naturnotwendigen
Geschehens, \dh~bestimmter stets wiederkehrender
Zusammenhänge aufbauen. \so{Kant} nennt einmal (Metaphysische
\index{Kant}%
Anfangsgründe der Naturwissenschaft, S.~99) den blinden Zufall
und das blinde Schicksal in der metaphysischen Weltwissenschaft
\DPPageSep{022}{8}
"`einen Schlagbaum für die herrschende Vernunft, damit entweder
Erdichtung ihre Stelle einnehme oder sie auf dem Polster dunkler
Qualitäten zur Ruhe gebettet werde"'.

Aber wo es sich wie hier und in jeder logischen Untersuchung
um die Ideenbildung an sich handelt, kann auch die für die ganze
Lebensauffassung bedeutsame Idee der Schicksalsbestimmung nicht
außer acht gelassen werden. Diese Idee verdankt ihren Ursprung
wesentlich dem Gefühl der Machtlosigkeit alles menschlichen Strebens
fremden Einwirkungen gegenüber, die im Gegensatz zu den planvollen
menschlichen Handlungen als sinnlos und unbegreiflich erscheinen.
Alles Ringen und Streben wird durch einen tückischen
Eingriff äußerer Umstände zunichte gemacht. In diesem Sinne
ist es völlig gleichgültig, ob der äußere Eingriff einem naturgesetzlichen
Geschehen oder einer regellosen Willkür entspringt.
Wenn wir in den Folgen des Zusammenstoßes zweier Eisenbahnzüge
die gesetzmäßige Wirkung der als lebendige Kraft bezeichneten
physikalischen Größe erkennen, so ist das ein geringer Trost für
die Verunglückten und ihre Angehörigen. In den gesetzmäßigen
Wirkungen der Natur spielt die Rücksichtnahme auf das menschliche
Wohl und Wehe keine Rolle. Der Mensch ist hineingestellt
in ein Spiel von Kräften, die sich mit dem Sinn seines Lebens von
vornherein nicht berühren.

Gerade weil die äußeren Einwirkungen auf das Leben des
Menschen so plötzlich und unerwartet kommen können, weil es so
schwer ist, in ihnen einen Sinn und einen Plan zu entdecken,
werden sie vom naiven Verstande als der Ausfluß einer der
menschlichen Zweckbestimmungen gegenüberstehenden, aber im
Vergleich zu ihr übermächtigen Entscheidung angesehen. Der landläufige
Begriff des Zufalls wird durch den Kausalbegriff im naturwissenschaftlichen
Sinne überhaupt nicht getroffen. Er bezieht sich
nur auf die Leugnung der Zweckbestimmung, entweder die unmittelbar
durch die menschliche Tätigkeit bedingte oder die in das
außermenschliche Geschehen nach Analogie der menschlichen Tätigkeit
hineingelegte. Zufall oder Schicksal, das ist meistens die Frage,
nicht Zufall oder Naturgesetz. So sind auch die Überlegungen,
die von rein menschlicher Seite her an die Glücksspiele angeknüpft
werden, nicht auf physische, sondern auf metaphysische Zusammenhänge
zu beziehen. Die Frage lautet nicht, ob die physikalischen
Vorgänge beim Glücksspiel, etwa beim Rollen der Roulettekugel,
\DPPageSep{023}{9}
auf einer physikalischen Gesetzmäßigkeit beruhen oder nicht,
sondern um was es sich handelt, ist, in den Resultaten des Spieles
eine bestimmte Schickung zu sehen, teils das Walten einer ausgleichenden
Gerechtigkeit, teils ein Bevorzugen bestimmter Glückskinder.
Vom naturwissenschaftlichen Standpunkt aus sind solche
Zusammenhänge, die außerhalb des physischen Geschehens liegen,
nicht zu verstehen. Damit sollen sie nicht von vornherein geleugnet
sein, sie müssen nur außer acht gelassen werden, wenn
man mit den Methoden der Naturwissenschaft operieren will.

In welchem Sinne nun auch das Wort Zufall verstanden wird,
ob wir es auf das physische Geschehen und sein Erfassen mit den
Methoden der modernen Naturwissenschaft, oder ob wir es auf die
aus der Beurteilung des Geschehens nach der Analogie der menschlichen
Handlungen entspringende metaphysische Auffassung beziehen
wollen, immer ist die Bedeutung die Leugnung eines bestimmten
Zusammenhanges. \so{Zufällig ist ein Ereignis, wenn
es nicht aus anderen Ereignissen oder bestimmten, als
gegeben angesehenen Prämissen nach festen Regeln oder
nach bestimmten Vernunftgründen gefolgert werden
kann.} Die physische und die metaphysische Seite vereinigen sich
in der Leugnung des Zufalls, die metaphysische, indem sie sagt:
alles entspringt einer festen Zweckbestimmung, die physische,
indem sie den Satz aufstellt: alle Ereignisse folgen aus anderen
nach gesetzmäßigen Zusammenhängen mit unbedingter Notwendigkeit.
Was aber Zufall und Notwendigkeit im physikalischen Sinne
betrifft, so ist zunächst zu sagen, daß in dieser Allgemeinheit
ausgesprochen der Satz "`Es gibt keinen Zufall"' wieder über die
Grenzen der Erfahrung hinausgeht, vielmehr eine Hypothese bedeutet.
Diese Hypothese hat keinen heuristischen Wert, sondern
dient nur zur Abklärung des Weltbildes.

Wenn nun auch in solchem dogmatischen Sinne der Zufall
geleugnet wird, sei es von einem ätiologischen oder einem teleologischen
Standpunkte aus, so bedeutet dies noch nichts gegen die
Verwendung des Wortes in einem einfachen pragmatischen Sinne.
Wenn wir sagen: "`Es ist ein Zufall, wenn sich bei wechselndem
Mond das Wetter ändert"', so verbinden wir damit einen bestimmten
Sinn, der weder der Zweckbestimmung in der Schöpfung noch der
durchgängigen Kausalität alles Geschehens widerspricht. Wir
meinen nämlich damit nur, daß unter den Momenten, die wir als
\DPPageSep{024}{10}
bestimmend für die Wetterlage ansehen müssen, der Mondwechsel
keine Stelle findet. Was in dem einzelnen Falle als bestimmend
für ein Ereignis oder, wenn man will, als dessen Ursache auftritt,
bedeutet doch immer eine bestimmte Gruppe von Erscheinungen,
und wir brauchen nicht den ganzen Weltenraum und die ganze
Ewigkeit zu durchforschen, um diese Ursachen für ein Ereignis
anzugeben. Im Gegenteil beruht jede naturwissenschaftliche Erkenntnis
darauf, daß wir bestimmte wenige Ereignisse als maßgebend
für das Eintreten eines anderen Ereignisses herausheben.
So finden wir als Ursachen für die Ausdehnung der Luft die
Steigerung der Temperatur oder die Verringerung des Druckes
und können einen bestimmten gesetzmäßigen Zusammenhang angeben,
der diese drei Größen verknüpft, so daß, wenn zwei davon
bekannt sind, die dritte sofort gefunden werden kann.

Eine solche Bestimmung des Erfolges aus gewissen, durch
Beobachtung zu ermittelnden Momenten ist aber \zB~nicht möglich,
wenn wir angeben sollen, auf welchem Felde der Scheibe beim
Roulettespiel die Kugel liegen bleiben wird. Darum haben wir
ein Recht, dieses Ereignis des Roulettespieles als ein zufälliges zu
bezeichnen, weil wir den schließlichen Erfolg nicht aus einer bestimmten
Gruppe von beobachtbaren Erscheinungen ableiten, \dh~als
eine regelmäßig eintretende Folge dieser Gruppe von Erscheinungen
erkennen können. Aus den beobachtbaren Ereignissen, die
in diesem Falle die Bedingungen des Spieles bilden (wohin neben
der sorgfältigen Anfertigung des zum Spiel dienenden Apparates
auch die genaue horizontale Aufstellung der Roulettescheibe und
ein genügender Impuls der Roulettekugel gehört) folgt nur, daß
die Kugel auf einem der Felder liegen bleiben muß, aber nicht,
auf welchem Felde. Demnach würde es, um ein Ereignis als zufällig
bezeichnen zu dürfen, genügen, wenn \so{alle erfahrungsmäßig
feststehenden Umstände, die bei einem Ereignis in
Betracht kommen, dieses Ereignis noch nicht bestimmen,
vielmehr es, wenn alle diese Umstände erfüllt sind, eintreten,
aber auch ausbleiben kann}.

So kommen wir auf einen engen Zusammenhang des Zufallsbegriffes
mit dem Begriffe der Möglichkeit. Denn als Möglichkeit
ist es anzusehen, wenn weder das Eintreten noch das Ausbleiben
eines Ereignisses als gewiß erscheint. Ein bloß mögliches Ereignis
kann eintreten, kann aber auch ausbleiben.
\DPPageSep{025}{11}

Wir müssen aber nach allem, was wir bis jetzt entwickelt
haben, sagen, ein Ereignis könne ebensogut eintreten wie ausbleiben,
wenn aus allen \so{beobachtbaren} Umständen, die bei diesem
Ereignisse in Betracht kommen, noch nicht geschlossen werden
kann, daß das Ereignis eintreten wird. Auf diese Weise vermeiden
wir sowohl jede metaphysische Färbung als auch eine rein subjektive
Fassung des Möglichkeitsbegriffes. Allerdings müssen wir
betonen, daß der Begriff der empirischen Bestimmbarkeit ein unsicherer
und schwankender ist. Was heute noch nicht bestimmbar
ist, kann es morgen werden. Umstände brauchen nicht unmittelbar
beobachtbar zu sein, damit wir ihnen einen bestimmten Charakter,
nämlich den gleichen Charakter, den wir an unmittelbar beobachtbaren
Umständen festgestellt haben, zuschreiben. Die Analogiebildung
spielt eine wesentliche Rolle in der naturwissenschaftlichen
Erkenntnis und ist nicht zu entbehren. Die Vorgänge im lebenden
Körper sind zum größten Teil unbestimmbar, aber wir zweifeln
nicht, daß sie von derselben Art sind wie andere Vorgänge, die
wir kennen. Unbestimmbar zu sein, bedeutet an sich keinen besonderen
und einheitlichen Charakter. Es tritt immer der Gedanke
hinzu, ob wir uns ein Bild machen können von Vorgängen, die,
wenn wir sie beobachten könnten, das Ereignis als aus ihnen
ableitbar erscheinen ließen. Beim Roulettespiel sind solche Vorgänge
nicht vorhanden, was geschieht, ist unmittelbar zu beobachten.
Die Kugel liegt offen auf der Scheibe und wird dadurch
in Bewegung gesetzt, daß die Scheibe selbst durch einen ihrer
Achse mitgeteilten Impuls in rasche Drehung versetzt wird. Wir
könnten allerdings aus der Stärke des Impulses, wenn sie uns genau
bekannt wäre, die Bewegung der Kugel und ihre Endlage nach
den Grundsätzen der Mechanik ableiten, aber die Entscheidung,
auf welchem Felde die Kugel liegen bleiben wird, hängt von solchen
geringen Differenzen des Impulses und von Fall zu Fall wechselnden
kleinen besonderen Vorgängen bei der Bewegung der Kugel
auf der rotierenden Scheibe ab, daß sie sich jeder Bestimmung
entzieht. Daher haben wir hier wirklich den Typus des zufälligen
Ereignisses vor uns.

Wir können nun andere Vorgänge bilden, die den beim
Roulettespiel vorliegenden gleichartig sind, dahin gehören die
Ziehungen der Lose bei den Lotterien oder die Ziehungen einer
Kugel aus einer Urne, die Kugeln von verschiedener Farbe gemischt
\DPPageSep{026}{12}
enthält, das Würfeln mit einem oder mehreren Würfeln und
dergleichen mehr. Solche Vorgänge sind es, auf denen wir die Glücksspiele
aufbauen. Wo diese Vorgänge nicht willkürlich zum Zweck
des Glücksspiels herbeigeführt werden, aber doch eine dem Glücksspiel
ähnliche Abmachung getroffen wird, spricht man bekanntlich
nicht von einem Spiel, sondern von einer Wette. Es liegt in der
Natur der Sache, daß eine Wette auch da vorliegen kann, wo
die hauptsächlichste Bedingung eines Glücksspieles, die vorherige
Unbestimmbarkeit des Erfolges, nicht erfüllt ist. In vielen Fällen
ist sie es aber, \zB~wenn bei einer Seefahrt auf die letzte Ziffer
in der Anzahl der an einem bestimmten Tage zurückgelegten Seemeilen
gewettet wird. Diese letzte Ziffer hängt in der Tat von
unbestimmbaren Einflüssen ab.

Fassen wir das allgemeine Ergebnis, zu dem wir vorläufig
gelangt sind, kurz zusammen, so ist es dieses, daß sich, auch wenn
wir von einer durchgängigen Kausalität alles Geschehens ausgehen,
gewisse Ereignisse herausheben, die wir als zufällige bezeichnen
dürfen. Ein wesentliches Merkmal dieser Ereignisse ist, daß wir
vorher nicht entscheiden können, ob sie eintreten werden oder
nicht, daß sie also vor ihrem Eintreten nur als möglich, aber auf
keine Weise als notwendig erscheinen. Es sind solche Ereignisse,
bei denen die uns mögliche ursächliche Bestimmung, selbst wenn
wir sie über die unmittelbare Erfahrung hinaus durch Analogiebildung
ergänzen, als nicht ausreichend befunden wird.
\EndChap
\DPPageSep{027}{13}


\Chapter{Zweites Kapitel}{Die statistische Methode}

Erscheint als das Bezeichnende der zufälligen Ereignisse zunächst
die Unmöglichkeit einer vollständigen kausalen Erklärung
und damit einer Voraussage ihres Eintretens, wenn alle beobachtbaren
Bedingungen des Ereignisses bekannt sind, so wird man
sagen, dann hat das Zufällige überhaupt den Charakter der Unerkennbarkeit.
Es lohnt nicht, weiter darüber zu reden. Und
doch erweisen sich die Zufallsereignisse als eine Quelle sehr weitgehender
Betrachtungen, selbst dann, wenn wir außerstande sind,
den Zusammenhang des Geschehens in ihnen vollständig zu durchschauen.

Diese Betrachtungen gehen davon aus, daß wir in den Zufallsereignissen
eine gewisse innere Gleichartigkeit zu erkennen
suchen. Das gibt uns die Möglichkeit, sie uns durch Analogiebildung
näher zu rücken. Wir greifen gewisse typische Ereignisse
unter ihnen heraus, bei denen die Gesamtheit der beobachtbaren
Bedingungen willkürlich geschaffen werden. Diese Ereignisse
sind die \so{Glücksspiele}. Wir schaffen uns so aus den Glücksspielen
ein Mittel, um die Besonderheit der Zufallsereignisse
allgemein zu beurteilen. Wir vergleichen die Zufallsereignisse mit
Glücksspielen, indem wir das Wort Vergleich aber nicht im poetischen
Sinne, sondern im Sinne der Zusammenstellung zahlmäßiger
Resultate verstehen.

Von vornherein erscheinen zwei Wege gangbar, um der
Eigenart des Zufälligen näher zu kommen. Entweder man sucht
sich einen Mechanismus des Geschehens zu denken, der im Resultat
mit den beobachteten Zufallsereignissen übereinstimmt, und überträgt
das innere Wesen dieses Mechanismus auf alle Zufallsereignisse.
Das wollen wir eine \so{genetische} Erklärung des Zufalls
nennen. Oder aber man stellt nur die Ereignisse zusammen, die
bei der statistischen Zählung gleiche Resultate liefern, ohne weiter
\DPPageSep{028}{14}
auf ihr Zustandekommen einzugehen. Man hält nur das im statistischen
Ergebnis Gleichartige nebeneinander und sieht mit
diesem Nebeneinanderhalten die Aufgabe als erledigt an. Dies
Verfahren wollen wir als die \so{statistische} Methode bezeichnen.

Auf den ersten Weg deutet W.~\so{Wundt} in seiner Logik
\index{Wundt, Wilh.|f}%
(1.~Bd., 5.~Abschn., 1.~Kap.,~3c) hin, der zunächst die Bedeutung
des Zufalls als einer Durchbrechung der Notwendigkeit des Geschehens
hervorhebt.

Er betont, daß es doch eine Auffassung gibt, die eine wissenschaftliche
Theorie des Zufälligen ermöglicht. Kurz gesagt ist
diese Auffassung die, daß wohl auch das Zufällige auf einer durchgängigen
Kausalität beruht, daß aber bei einem zufälligen Ereignis
die Ursachen wenigstens teilweise einen solchen besonderen
Charakter haben, daß sie sich unserer Beobachtung entziehen.
Von der wirklichen kausalen Entstehung des zufälligen Ereignisses
sind daher bestimmte Aussagen zu machen, und wir können
von einem objektiven Charakter der zufälligen Ereignisse sprechen,
ohne daß wir darum den Gedanken einer durchgängigen Kausalität
aufgeben.

Auf diese Weise scheint die Schwierigkeit völlig gehoben.
Wir finden eine Betrachtung, die den Grundsätzen der naturwissenschaftlichen
Forschung nicht widerspricht und die uns doch
die Möglichkeit gibt, den Begriff des Zufälligen auch in einer objektiven
Bedeutung zu erhalten. Damit scheint diese genetische
Betrachtung des Zufalls, die auf das wirkliche Zustandekommen
der als zufällig erscheinenden Ereignisse eingeht, ihre Bedeutung
und ihre Berechtigung zu erweisen. Es erhebt sich nur die Frage:
Wie können wir denn über solche Ursachen urteilen, die sich
unserer Beobachtung völlig entziehen? Nach \so{Wundts} Darstellung
handelt es sich dabei um eine Hypothese. Nehmen wir das
Vorhandensein solcher Ursachen an, so können wir nach den
Grundsätzen der Logik und der allgemeinen Erfahrung die wirklich
beobachteten Verhältnisse erschließen. Dies geht allerdings
nicht ohne eine ziemlich umständliche mathematische Entwickelung,
und \so{Wundts} Darstellung scheint nur eine Zusammenfassung
der Grundgedanken dieser von \so{Bessel} herrührenden Ableitung,
\index{Bessel@Bessel|f}%
die uns später noch beschäftigen wird, zu bedeuten.

Die \so{Bessel}sche Ableitung bezieht sich aber auf ganz besondere
Erscheinungen, nämlich die Abweichungen der bei der
\DPPageSep{029}{15}
Bestimmung einer physikalischen Größe gefundenen Zahlenwerte
voneinander. Der Begriff des Ereignisses scheint hier überhaupt
nicht zu passen, es handelt sich sozusagen nur um eine Begleiterscheinung
der wirklichen Ereignisse, nämlich der Beobachtungen.
Daher rührt es wohl auch, wenn \so{Wundt} äußert, der Zufall könne
niemals als selbständiges Phänomen, sondern immer nur als individuelle
Abänderung einer gesetzmäßig bestimmten Erscheinung
vorkommen. Diese Bedeutung würde den Geltungsbereich des
Zufälligen nun erheblich einschränken, denn es wäre ein solches
Zufallsereignis wie die Tötung eines Vorübergehenden durch einen
herabfallenden Ziegel oder die Tötung eines Soldaten durch den
Hufschlag eines Pferdes schwer in dieses Schema zu bringen.

Indes ist die \so{Bessel}sche Hypothese nicht auf die Erklärung
der Beobachtungsfehler bei physikalischen Messungen beschränkt,
sie läßt sich dem Grundgedanken nach in viel weiterem Umfange
anwenden. Die Hypothese ist im wesentlichen die, daß ein typisch
zufälliges Ereignis auf sehr vielen Einzelumständen beruhe, die
selbst von vornherein unbestimmt sind, daß das schließliche Endergebnis
nur die Frucht einer großen Anzahl vorausgehender Erscheinungen
sei, die alle voneinander unabhängig sind. Die Natur
des Zufallsereignisses wird dadurch aber immer noch viel enger
umgrenzt als früher, wo nur zwei voneinander unabhängige
Kausalreihen bestehen mußten, während jetzt sehr viele voneinander
unabhängige Umstände in dem Ereignis zusammenwirken
sollen.

Wir würden daher so den Bereich des Zufälligen von vornherein
enger bestimmen, als es gerechtfertigt erscheint. Wie gelangen
wir nun aber zu einer anderen, allgemeineren Methode, in
die Natur der zufälligen Ereignisse einzudringen? Zu dem Zwecke
müssen wir, wenn wir sagen, ein Zufallsereignis sei durch die feststellbaren
Ursachen nicht völlig bestimmt, uns fragen, was überhaupt
innerhalb der Grenzen der Erfahrung bedeutet, wenn wir
von Umständen sprechen, die in dem Verhältnis von Ursache und
Wirkung einen Erfolg bestimmen. Damit kann nur gemeint sein,
daß, wo wir diese Umstände zusammen beobachten, stets auch der
Erfolg zu beobachten ist. Nur an die tatsächliche Verbindung in
allen beobachteten Fällen ist gedacht. Wenn also, wie beim Zufallsereignis,
durch die feststellbaren Ursachen das Ereignis nicht
völlig bestimmt ist, so bedeutet das, daß in den Fällen, wo diese
\DPPageSep{030}{16}
Ursachen zusammen beobachtet sind, das Ereignis bisweilen eingetreten,
bisweilen aber auch ausgeblieben ist.

Wir können, um noch klarer zu sein, diese Feststellung in
zwei zerlegen. Die eine bedeutet, daß unter den in Betracht
kommenden Umständen, welche die Gesamtheit der beobachtbaren
Ursachen des Zufallsereignisses darstellen, dieses Ereignis wirklich
wenigstens einmal eingetreten ist. Die zweite Feststellung bedeutet,
daß das Ereignis unter den in Betracht kommenden Umständen
auch wenigstens einmal ausgeblieben ist. Quidquid existit contingenter,
aliquando non existit, ist ein alter Schulsatz. Das Feststellen
einer solchen einfachen Tatsache würde allerdings an sich
noch keine Statistik sein, die Statistik erscheint erst da, wo man
\so{zählt}, wie oft ein Ereignis eingetreten ist. Man wird nun sagen,
die Häufigkeit ist für die Tatsache der Möglichkeit, um die es sich
hier allein handelt, gänzlich bedeutungslos. Was einmal geschehen,
ist schon möglich. Wie oft es wieder geschieht, ist gleichgültig,
außer wenn es in allen in Betracht kommenden Fällen zu beobachten
ist. Dann würde sich die Möglichkeit in die Gewißheit
verwandeln.

Aber der Gedanke, daß in allen Fällen es gerade von Wert
ist, zu erfahren, wie oft verhältnismäßig unter den gegebenen
Umständen ein bestimmtes Ereignis eingetreten ist, bietet sich
von selbst dar.\ \so{Sigwart} formuliert diesen Gedanken in seiner
\index{Sigwart}%
Logik (Bd.~II, Tl.~III, S.~406) mit den Worten: "`In der statistischen
Zählung sind zwar die etwaigen individuellen Differenzen,
durch die jedes Ding einzig in seinen bestimmten Eigenschaften
sich von allen anderen unterscheidet, untergegangen, aber das
Einzelne hat doch noch insofern sein Recht gefunden, als es nicht
bloß als gleichgültiger Repräsentant eines allgemeinen Begriffes,
sondern in seiner numerischen Unterschiedenheit von allen anderen
beachtet ist."' Der hierdurch gemachte Fortschritt ist
durchaus dem zu vergleichen, den in der Naturwissenschaft der
Übergang von der bloßen Feststellung eines Zustandes zu seiner
zahlmäßigen Bestimmung bedeutet. Wenn ein Ereignis in $90$
von $100$ Fällen eingetreten ist, so werten wir die Möglichkeit
anders, als wenn wir es unter $100$ Fällen nur einmal beobachtet
haben.

Die Statistik, zu der wir so gelangen, betrifft statistische
Verhältniszahlen, \dh~es wird aufgezeichnet, wie oft unter bestimmten
\DPPageSep{031}{17}
Umständen, also in einer bestimmten Gruppe von Erscheinungen,
ein Ereignis eingetreten ist, wobei es sich zunächst
nur um die relative Häufigkeit, nicht aber um die absolute Anzahl
des Vorkommens handelt. Nun erhebt sich aber sofort die Frage,
die den Kernpunkt alles folgenden bildet: Nehmen wir an, wir
haben die relative Häufigkeit nicht bloß aus einer Serie von Beobachtungen
festgestellt, sondern wir haben mehrere Reihen von
Beobachtungen benutzt und aus jeder die relative Häufigkeit bestimmt.
Dann fragt es sich, ob wir ganz verschiedene Werte
der relativen Häufigkeit bei den einzelnen Bestimmungen zu erwarten
haben oder ob sich zwar nicht genau, aber doch angenähert
derselbe Wert bei den verschiedenen Bestimmungen ergeben
wird. In dem einen Falle erweisen sich die festgestellten
Werte der relativen Häufigkeit als gänzlich unbrauchbar zur
Charakterisierung des beobachteten Ereignisses im allgemeinen,
in dem anderen Falle dagegen können wir dem regelmäßig wiederkehrenden
Werte der relativen Häufigkeit eine bestimmte Bedeutung
für das Ereignis an sich zusprechen. Wir können es als
eine Eigentümlichkeit des Ereignisses ansehen, daß es mit dieser
relativen Häufigkeit auftritt, während sonst die relative Häufigkeit
nur eine Bedeutung innerhalb der räumlichen und zeitlichen
Begrenzung, der die beobachteten Fälle entsprechen, besitzt. Wenn
wir also etwa in regelmäßigen Zeitabschnitten die vorgekommenen
relativen Häufigkeiten notieren, so fragt es sich: nähern sich die
aufgezeichneten Verhältniszahlen alle einem bestimmten Werte
oder läßt sich in ihnen eine systematische Veränderung beobachten?
Es ist \zB~bekannt, daß die relative Häufigkeit der
Selbstmorde zunimmt, dagegen scheint es zweifelhaft, ob eine
ähnliche systematische Veränderung in dem Verhältnis der Anzahlen
von männlichen und weiblichen Selbstmördern zu beobachten ist.

Hierin liegt eine erste Scheidung der statistischen Verhältniszahlen
begründet. Je nachdem, ob wir in ihnen eine systematische
Veränderung beobachten oder nicht, werden wir von zufälligen
oder durch bestimmte Ursachen hervorgerufenen Schwankungen
sprechen. \so{Der Zufall würde so in der Statistik unmittelbar
zutage treten.}

Der große Vorzug, der in einer solchen statistischen Bestimmung
des Zufalls liegt, besteht darin, daß wir nicht mehr gezwungen
sind, auf die Einzelheiten beim Zustandekommen des
\DPPageSep{032}{18}
Ereignisses einzugehen, die in den meisten Fällen unserer Erkenntnis
verschlossen sind und nur aus mehr oder minder unbestimmten
Vermutungen heraus beurteilt werden, sondern vielmehr
uns an bestimmte Tatsachen halten können.

Nun ist aber klar, daß solche Schwankungen, die wir als zufällige
bezeichnen, nicht bloß bei statistischen Verhältniszahlen
auftreten können, sondern überhaupt, wo eine statistische Aufzeichnung
vorliegt. Wenn wir nämlich eine solche Reihe von
statistischen Zahlen uns vor Augen halten oder am besten sie in
einer Kurve oder Staffel graphisch darstellen, so beobachten wir
bald, daß neben systematischen Veränderungen auch ein regelloses
Hin- und Herschwanken auftritt. Ein solches Schwanken
werden wir wieder als zufällig bezeichnen. Allerdings ist es eine
besondere, vielleicht nicht immer lösbare Aufgabe, die zufälligen
Schwankungen richtig herauszuschälen. Unter der Voraussetzung,
daß dies gelingt, zeigt sich nun aber, daß das unbestimmte und
meistens auf bloßen Vermutungen beruhende Trennen der Ursachen
in systematische und zufällige ersetzt wird durch ein quantitativ
auf Grund gemessener oder gezählter Zahlenwerte ausführbares
Scheiden der systematischen und der zufälligen Veränderungen.
Wir können also der Methode der exakten Naturwissenschaft treu
bleiben, nur auf Grund bestimmter Messungen und bestimmter,
nach festen Regeln an diese Messungen geknüpfter Berechnungen
vorzugehen.

So werden wir darauf geführt, die Analyse statistischer
Tabellen nach bestimmten besonderen Gesichtspunkten als unsere
Aufgabe anzusehen. Hierbei erweist sich nicht einmal der Ursprung
der Tabelle aus einer statistischen Zählung als entscheidend,
vielmehr würden auch Tabellen, die auf Messungen einer
und derselben physikalischen Größe beruhen, möge diese Größe
nun veränderlich sein oder nicht, einer ganz analogen Analyse
zugänglich sein.

Bevor wir an diese Untersuchung gehen, scheint die Frage
gerechtfertigt, welche Resultate wir von ihr erwarten dürfen. Dadurch,
daß wir, statt auf das innerliche Zustandekommen der Zufallsereignisse
einzugehen, nur ihre äußerliche Verteilung ins Auge
fassen, geben wir, scheint es, die Hoffnung auf ein Eindringen
in das innere Wesen des Zufälligen auf. Über dieses Wesen
können wir ja keine Auskunft erhalten, wenn wir nichts anderes
\DPPageSep{033}{19}
aufzeichnen, als wie oft innerhalb einer gewissen Gruppe einzelner
Fälle das in Rede stehende Ereignis eingetreten und ausgeblieben
ist.

Der Ausweg ist eben der, daß wir in der Verteilung, die uns
die statistische Erhebung offenbart, doch in gewissem Sinne ein
Merkmal der Zufallsereignisse erkennen können. Es ergeben
sich gewisse Verteilungen, die typisch für die zufälligen Ereignisse
sind. Darin liegt, daß wir aus der übereinstimmenden Verteilung
auch auf eine innere Verwandtschaft der beobachteten Ereignisse
schließen. Ist dieser Schluß aber berechtigt? Das bleibt
unentschieden und muß unentschieden bleiben, weil wir in den
Mechanismus des Geschehens nicht eindringen können. Aber auch
in der bloßen Analogiebildung liegt eine gewisse Erklärung. Wir
machen uns eine Erscheinung schon begreiflich, wenn wir eine
andere Erscheinung finden, die sich in derselben Weise äußerlich
offenbart wie die erste. Alles Erklären ist im Grunde ein Vergleichen.
Der Vergleich kann im vorliegenden Falle einerseits so
geführt werden, daß wir nur die Erscheinungen zusammenfassen,
die eine gleiche oder verwandte Verteilung zeigen; andererseits
können wir aber auch gewisse typische Erscheinungen herausgreifen,
deren innerer Organismus uns leidlich klar erscheint und
nach ihnen die Erscheinungen mit verwandter Verteilung beurteilen.
Solche typische Erscheinungen sind die Glücksspiele.
Wir würden danach als zufällige Ereignisse solche zu bezeichnen
haben, bei deren statistischer Verfolgung sich dieselbe Verteilung
der Ergebnisse wie bei den reinen Zufallsspielen herausstellt. Für
die Glücksspiele kann man aber als zweckmäßig ein bestimmtes
Schema wählen, und dieses wird fast immer durch die Ziehungen
aus einer Urne, in der Kugeln von verschiedener Farbe gemischt
enthalten sind, gebildet. Die Beurteilung der Zufallsereignisse
nach diesem Urnenschema würde so das letzte Stadium der Untersuchung
sein. Welchen Wert man ihr beimessen will, bleibt in
gewisser Weise dem freien Belieben überlassen. Jedenfalls scheint
es kein anderes Verfahren zu geben, um in einwandfreier Weise
dem Charakter des Zufälligen nachzuspüren. Die Betrachtungen,
zu denen dieser Gedankengang führt, hat man für solid genug
zu halten, um darauf die Erforschung sowohl der Vorgänge in
den kleinsten Teilen der Materie als auch der Verteilung der
Himmelskörper im Weltenraum zu gründen.
\DPPageSep{034}{20}

Eines aber wird geltend gemacht werden und verdient sogleich
hervorgehoben zu werden. Indem man zur statistischen
Zählung übergeht, verschwindet das einzelne Ereignis und die
Betrachtung bezieht sich nur auf die statistische Gesamtheit. Die
gewählte Behandlungsweise setzt so voraus, daß es nicht das
einzelne Ereignis ist, worauf wir unser Interesse lenken, daß wir
vielmehr erst in der Gesamtheit der zusammengefaßten Ereignisse
den Gegenstand unserer Überlegung sehen. So ist in dem
angeführten physikalischen Beispiel nicht die Bewegung des einzelnen
Moleküls der Zielpunkt der Untersuchung, sondern wie
sich aus einer bestimmten Verteilung der Bewegungen aller einzelnen
Moleküle die beobachtbaren Eigenschaften und Zustände
des ganzen Körpers ergeben. In dem anderen Beispiele, das der
Astronomie angehört, handelt es sich nicht um die Lage des
einzelnen Fixsterns, sondern um die Verteilung aller Fixsterne
im Weltenraum. Ebenso ist bei den Untersuchungen über die
Erscheinungen in der menschlichen Gesellschaft, die auf zahlenmäßiger
Grundlage möglich sind, nicht das einzelne Individuum
der Gegenstand der Betrachtung, sondern eben die Gesamtmasse
der Bevölkerung. Das Wohl und Wehe des einzelnen verschwindet
und nur das Los der Allgemeinheit ist es, was in der Untersuchung
zutage tritt. Man kann es vermissen, daß so die Aufklärung
des einzelnen Zufallsereignisses an sich, die nur durch ein Eingehen
auf seine individuelle Besonderheit möglich ist, durch die
statistische Methode nicht gegeben wird. Man wird aber erkennen,
daß doch das wahre, kardinale Problem berührt wird. Denn dieses
Problem ist das, wie sich auf der Unbestimmbarkeit und anscheinenden
Regellosigkeit des einzelnen Falles eine Gesetzmäßigkeit
aufbaut und feste in Zahlen ausdrückbare Zusammenhänge
in der Gesamtheit ergeben. Gerade dies ist es ja auch, was selbst
nach aller möglichen Aufklärung unser tiefes Erstaunen hervorruft.
\EndChap
\DPPageSep{035}{21}


\Chapter{Drittes Kapitel}{Stationäre Zahlenreihen}

Wir wollen nun allgemein ausgehen von der Zusammenstellung
einer Reihe von Zahlenwerten, die man als eine \so{Tabelle}
bezeichnet. An einer Tabelle ist zu unterscheiden der Kopf, der
\so{Eingang} und der \so{Eintrag}. In dem \so{Kopf} der Tabelle wird
angegeben, was die in der Tabelle eingetragenen Zahlen allgemein
bedeuten. Der \so{Eingang} dagegen setzt die Bedeutung der einzelnen
Zahlen in der Tabelle fest. Damit also eine Reihe von
Zahlen sich in einer Tabelle anordnen läßt, ist es notwendig, daß
sie eine gemeinsame Bedeutung haben und die einzelne Zahl der
Reihe nur noch durch eine besondere Bestimmung festgelegt wird.
Diese besondere im Eingang der Tabelle stehende Bestimmung
kann verschiedener Art sein. Sie kann die in der Tabelle eingetragenen
Zahlen örtlich umgrenzen, wie wenn \zB~in einer
Statistik über Preußen bestimmte Zahlen für die einzelnen Provinzen
angegeben werden. Sie kann auch \zB, wenn es sich
um zahlmäßige Bestimmungen von Eigentümlichkeiten einzelner
Individuen handelt, die Namen dieser Individuen enthalten, oder
diese Namen durch laufende Nummern ergänzen oder ersetzen.
Eine solche Tabelle kann man allgemein als eine \so{Liste} bezeichnen.
Der Eingang kann aber auch selbst eine zahlmäßige Bestimmung
bedeuten. Sehr häufig bezeichnet er eine Zeit, entweder Zeitabschnitte,
\zB~Jahre, Monate oder Tage, oder bestimmte Zeitpunkte.

Der Eingang der Tabelle kann ferner eine reine Zahl sein.
Dann haben wir eine rein mathematische Tabelle vor uns, die
bestimmten Zahlenwerten wieder bestimmte Zahlenwerte zuordnet.
Sie legt das fest, was man im mathematischen Sinne als
eine \so{Funktion} bezeichnet. In ihr können unter anderem die
Resultate bestimmter Rechenoperationen zusammengestellt sein.
Dahin gehören \zB~die Logarithmentafeln. Wir wollen solche
Tabellen als \so{analytische} bezeichnen. Den analytischen Tabellen
stehen die \so{empirischen} gegenüber, die nicht bloß auf mathematischen
\DPPageSep{036}{22}
Rechnungen beruhen, sondern in denen ein bestimmtes
Erfahrungsmaterial niedergelegt ist, unter Umständen im Verein
mit Rechnungen, die an die empirisch ermittelten Zahlenwerte angeknüpft
werden. Wir haben bei diesen empirischen Tabellen
wieder zu unterscheiden, ob ihnen bestimmte \so{Messungen} oder
bloße \so{Zählungen} zugrunde liegen. Im ersten Falle können wir
von einer \so{Messungsreihe} sprechen, im zweiten Falle haben
wir eine \so{Zählungsreihe} oder eine eigentliche statistische Tabelle
vor uns. Um gleich ein Beispiel für beide Arten anzuführen,
können wir als Messungsreihe die Bestimmung der Körpergröße
eines Menschen in den verschiedenen Lebensaltern nehmen, als
Beispiel für eine Zählungsreihe eine sogenannte Sterbetafel, die
angibt, wieviel Menschen aus einer bestimmten Gruppe von Geborenen
in den verschiedenen Lebensaltern sterben. Der Eingang
der Tabelle ist in beiden Fällen dieselbe Zahl, nämlich das Lebensalter.
Der Eintrag ist in dem einen Falle eine Länge, also eine
gemessene Zahl, im anderen Falle eine durch Abzählung gewonnene
Zahl, nämlich eine Anzahl von Personen.

Die \so{Körpergrößen} beziehen sich auf Personen männlichen
Geschlechtes. Sie entsprechen nicht der Entwickelung eines bestimmten
Menschen, sondern sind Durchschnittszahlen, geben also
die Entwickelung eines "`Durchschnittsmenschen"' an. Der Gesamtgröße
ist die Beinlänge hinzugefügt und in einer dritten Spalte
gleich das Verhältnis der Gesamtgröße zur Beinlänge angegeben.
Man erkennt, daß dieses Verhältnis während des Wachstums des
Menschen abnimmt und sich einem bestimmten Endwert nähert,
den es aber schon vor der Vollendung des Wachstums erreicht.
\begin{center}
\begin{longtable}{c||c|c|c}
\multicolumn{4}{c}{%
  \so{Körpergröße männlicher Personen}\footnotemark.}\\
\hline\hline
\ColHeadbb{Jahre}{Alter\\ Jahre} &
\ColHeadb{Gesamtgröße}{Gesamtgröße \\ $m$} &
\ColHeadb{Beinlänge}{Beinlänge \\ $m$} &
\ColHead{\;Gesamtgröße\;}{$\dfrac{\text{Gesamtgröße}}{\text{Beinlänge}}$} \\
\hline
\hline
\endfirsthead
\hline\hline
\ColHeadbb{Jahre}{Alter\\ Jahre} &
\ColHeadb{Gesamtgröße}{Gesamtgröße \\ $m$} &
\ColHeadb{Beinlänge}{Beinlänge \\ $m$} &
\ColHead{\;Gesamtgröße\;}{$\dfrac{\text{Gesamtgröße}}{\text{Beinlänge}}$} \\
\hline
\hline
\endhead
%[** TN: 3rd column values retained, calculated 1st ÷ 2nd values indicated]
\Z0  & 0,500 & 0,160 & 3,13 \\
\Z1  & 0,698 & 0,241 & 2,90 \\
\Z2  & 0,791 & 0,288 & 2,75 \\
\Z3  & 0,864 & 0,328 & 2,64 \\ %[** 2,63]
\Z4  & 0,927 & 0,367 & 2,53 \\
\Z5  & 0,987 & 0,404 & 2,44 \\
\Z6  & 1,046 & 0,441 & 2,37 \\
\DPPageSep{037}{23}
%[** TN: Table head continues]
\Z7  & 1,104 & 0,478 & 2,31 \\
\Z8  & 1,162 & 0,514 & 2,26 \\
\Z9  & 1,218 & 0,550 & 2,21 \\
10 & 1,273 & 0,584 & 2,18 \\
11 & 1,325 & 0,616 & 2,15 \\
12 & 1,375 & 0,646 & 2,13 \\
13 & 1,423 & 0,674 & 2,11 \\
14 & 1,469 & 0,701 & 2,10 \\
15 & 1,513 & 0,723 & 2,09 \\
16 & 1,554 & 0,745 & 2,09 \\
17 & 1,594 & 0,766 & 2,09 \\ %[** 2,08]
18 & 1,630 & 0,782 & 2,09 \\ %[** 2,08]
19 & 1,655 & 0,794 & 2,09 \\ %[** 2,08]
20 & 1,669 & 0,802 & 2,09 \\ %[** 2,08]
25 & 1,682 & 0,806 & 2,09 \\
30 & 1,686 & 0,806 & 2,09 \\
40 & 1,686 & 0,805 & 2,09
\end{longtable}
\end{center}
\footnotetext{Vgl.\ \so{Quételet},\index{Quételet} Anthropométrie, Bruxelles 1871.}
\begin{figure}[hbt!]
  \centering
  \caption{Fig.~1.}
  \Input{037}
\end{figure}

Wir fügen dieser Tabelle sofort die graphische Darstellung
hinzu, die den Entwickelungsgang noch anschaulicher macht.
\DPPageSep{038}{24}

Die \so{Sterbetafel}, die wir als Beispiel für eine Zählungsreihe
anführen, gibt nicht etwa an, wie eine bestimmte Gruppe von
gleichzeitig Geborenen mit den Jahren sich gelichtet hat, sondern
sie enthält die Absterbeordnung, wie sie sich aus den Sterbefällen
einer bestimmten Epoche, wenn man diese nach dem Alter der
Gestorbenen gruppiert, ergibt. Das folgende ist in abgekürzter
Form die deutsche Sterbetafel für das Jahrzehnt 1901 bis~1910\footnote
  {Siehe Statistisches Jahrbuch für das Deutsche Reich~1913.}.
Die Anzahl der Geborenen ist gleich $100\,000$ gesetzt, neben den
Überlebenden stehen die während des folgenden Jahres Gestorbenen,
und daneben ist noch das Verhältnis der voranstehenden Zahlen
der beiden ersten Spalten, die sogenannte Sterbenswahrscheinlichkeit
für ein Jahr angegeben. Wir beschränken uns wieder auf
Personen männlichen Geschlechts.
\begin{center}
\begin{longtable}{r<{\quad}||*{2}{r<{\quad}|}r<{\qquad}}
\hline
\hline
\ColHeadbb{Jahre}{Alter\\Jahre} &
\ColHeadb{Überlebende}{Überlebende} &
\ColHeadb{eines Jahres}{Gestorbene\\während\\eines Jahres} &
\ColHead{Sterbenswahrschein-}{Sterbenswahrschein-\\lichkeit\\für ein Jahr}\\
\hline
\hline
\endhead
%[** TN: 3rd column values retained, calculated 2nd ÷ 1st values indicated]
  0 & 100\,000 & 20\,234  & 0,20\,234 \\
  1 &  79\,766 &  3\,181  & 0,03\,963 \\ %[**0,03 988]
  2 &  76\,585 &  1\,143  & 0,01\,492 \\
  3 &  75\,442 &     715  & 0,00\,947 \\ %[**0,00 948]
  4 &  74\,727 &     516  & 0,00\,691 \\
  5 &  74\,211 &     391  & 0,00\,528 \\ %[**0,00 527]
 10 &  72\,827 &     177  & 0,00\,244 \\ %[**0,00 243]
 15 &  72\,007 &     199  & 0,00\,277 \\ %[**0,00 276]
 20 &  70\,647 &     356  & 0,00\,504 \\
 25 &  68\,881 &     353  & 0,00\,513 \\
 30 &  67\,092 &     373  & 0,00\,556 \\
 35 &  65\,104 &     454  & 0,00\,697 \\
 40 &  62\,598 &     577  & 0,00\,922 \\
 45 &  59\,405 &     739  & 0,01\,244 \\
 50 &  55\,340 &     937  & 0,01\,693 \\
 55 &  50\,186 &  1\,183  & 0,02\,357 \\
 60 &  43\,807 &  1\,428  & 0,03\,260 \\
 65 &  36\,079 &  1\,698  & 0,04\,706 \\
 70 &  27\,136 &  1\,882  & 0,06\,936 \\ %[**0,06 935]
 75 &  17\,586 &  1\,871  & 0,10\,640 \\ %[**0,10 639]
 80 &   8\,987 &  1\,419  & 0,15\,787 \\ %[**0,15 789]
 85 &   3\,212 &     744  & 0,23\,160 \\ %[**0,23 163]
 90 &      683 &     219  & 0,32\,002 \\ %[**0,32 064]
 95 &       74 &      30  & 0,41\,399 \\ %[**0,40 541]
100 &        4 &       2  & 0,49\,668 \\ %[**0,5]
\end{longtable}
\end{center}
\DPPageSep{039}{25}

Man sieht, wie die Zahlenreihen in den verschiedenen Spalten
sich verhalten. Die Zahlen in der ersten Spalte nehmen natürlicherweise
beständig ab. Die Zahlen in der zweiten Spalte
nehmen zuerst ab, bis sie für das Alter von 12~Jahren ein Minimum
erreichen, dann nehmen sie zu, wenig ab, wieder zu und erreichen
für ein Alter von ungefähr 73~Jahren, das \so{Normalalter}, ein
Maximum, um dann bis zum Schluß abzunehmen (vgl.\ \Fig{2}).
\begin{figure}[hbt!]
  \centering
  \caption{Fig.~2. Anzahlen der in den verschiedenen Lebensaltern
    Gestorbenen auf $100\,000$ Geborene.}
  \Input{039}
\end{figure}
Die Zahlen der dritten Spalte nehmen zuerst ebenfalls ab und erreichen
ein Minimum mit den Zahlen der zweiten Spalte, dann
aber nehmen sie beständig und zwar zum Schluß sehr stark zu.

Je nach der \so{Art} des \so{Einganges} lassen sich die Tabellen in
zwei Arten scheiden. Bedeutet nämlich der Eingang eine Zahl
oder eine Zeit, so ergibt sich hiernach eine natürliche Ordnung,
nach der die Zahlen in der Tabelle entsprechend dem Eingang zu
nehmen sind. Dagegen kann es auch vorkommen, wie es bei einer
Liste oder bei einem Register häufig der Fall ist, daß die Reihenfolge,
in der man die Bezeichnungen des Einganges und damit
die Zahlen der Tabelle nimmt, völlig willkürlich bleibt. Wir
werden also immer unterscheiden können, ob eine Tabelle sich
ohne Verletzung einer natürlichen Ordnung umordnen läßt oder
\DPPageSep{040}{26}
nicht. Diese Unterscheidung fällt allerdings nicht ganz damit
zusammen, ob der Eingang nach einem natürlichen Prinzip geordnet
ist oder nicht. Dies zeigt ein Beispiel sofort. Im Falle
eines Geburtenregisters ist eine natürliche Ordnung nach dem
Zeitpunkt der Geburt vorhanden, aber wenn es sich um irgend
eine zahlmäßige Bestimmung handelt, die an die Geborenen
angeknüpft wird, \zB~die Lebensdauer, so kann man doch eine
Umordnung, etwa nach der Lebensdauer, vornehmen. Also ist
die Verletzung einer natürlichen Ordnung nicht notwendig dann
vorhanden, wenn der Eingang nach bestimmten Gesichtspunkten
geordnet ist. Dagegen wäre eine Umordnung \zB~bei einer
Logarithmentafel undenkbar. Dies liegt daran, daß zwischen dem
Eingang und dem Eintrag ein bestimmter gesetzmäßiger Zusammenhang
besteht: der Eintrag ist eine Funktion des Einganges,
und die Tabelle hat den Zweck, diese Funktion darzustellen. Beim
Geburtenregister ist aber nicht unmittelbar die Lebensdauer als
eine Funktion des Geburtsdatums anzusehen, die Tabelle stellt
also nicht eine bestimmte Funktion, sei es eine analytische oder
eine empirische, dar, und in diesem Fall ist die Umordnung
gestattet.

Wenn nun die Tabelle umgeordnet wird, so gelangt man
durch diese Umordnung immer dazu, einen funktionalen Zusammenhang
zu finden. Man geht zu dem Zweck von einer gewissen
natürlichen Umordnung der Tabelle aus. Diese \so{natürliche}
Umordnung ist die, bei der die Zahlenwerte der Tabelle
ihrer \so{Größe} nach aufeinander folgen. Man kann dann das ganze
Intervall, das die Zahlen erfüllen, in eine Anzahl gleiche Teile
teilen und angeben, wieviel Zahlen der Tabelle in jeden dieser
Teile fallen. Man unterwirft also sozusagen die Zahlenwerte der
Urreihe selbst einer Statistik, und das Resultat dieser Statistik
hat immer den Charakter einer funktionalen Abhängigkeit. Zu
jeder Größe der vorkommenden Zahlenwerte gehört ja eine bestimmte
Häufigkeit des Vorkommens. Die so abgeleitete Zahlenreihe
soll eine \so{Verteilungsreihe} heißen. Wir können auch
von einer \so{Verteilungsfunktion} sprechen, doch denkt man bei
dem Wort Funktion gewöhnlich an die gegenseitige Abhängigkeit
zweier kontinuierlich veränderlichen Zahlen, die ja nicht aus der
Tabelle selbst unmittelbar hervorgehen, sondern von der diese
nur den angenäherten Ausdruck bilden kann.
\DPPageSep{041}{27}

Es ist nun nicht eine allgemeine Erörterung der durch
Tabellen gegebenen Zahlenfolgen unsere Aufgabe, vielmehr handelt
es sich für uns darum, die Schwankungen herauszufinden, die wir
bei den in der Tabelle eingetragenen Zahlenwerten als zufällige
bezeichnen sollen.

Zu dem Zweck greifen wir eine besondere Art von Zahlenreihen
heraus, nämlich solche Reihen, bei denen wir keine systematische
Zu- oder Abnahme der eingetragenen Zahlenwerte beobachten
können, deren Werte vielmehr fortwährend zwischen
bestimmten Grenzen eingeschlossen bleiben. Solche Reihen von
Zahlen wollen wir als \so{stationäre} Zahlenreihen bezeichnen. Die
nächste Aufgabe wäre also die, genau anzugeben, wann eine Reihe
als stationär zu gelten hat. Hierfür läßt sich aber nicht eine
scharfe, allgemein gültige Definition geben, vielmehr kann man
nur Regeln anführen, die einen gewissen Anhalt für die Beurteilung
stationärer Reihen gewähren. Solche Regeln finden wir, indem
\DPtypo{wie}{wir} die Differenzen der in die Tabelle eingetragenen Zahlenwerte
bilden. Wir können dabei auf doppelte Weise vorgehen. Entweder
bilden wir die Differenzen von je zwei aufeinander folgenden
Tabellenwerten, oder wir bilden die Differenz eines Tabellenwertes
von allen anderen. Im ersten Falle erkennen wir, daß eine Reihe
stationär ist, daran, daß die Vorzeichen der Differenzen regellos
schwanken. Dies allein würde aber nicht ausreichen, denn wir
können uns eine Reihe denken, bei der positive und negative Differenzen
abwechseln und bei der doch ein beständiges Anwachsen der
eingetragenen Werte stattfindet, indem die positiven Differenzen
der Größe nach die negativen andauernd überwiegen. Deshalb
muß eine auf dem zweiten Fall der Differenzenbildung aufgebaute
Regel ergänzend hinzutreten. Diese zweite Regel sagt aus, daß
die Differenzen eines festen Wertes von allen anderen, der Reihe
nach genommenen Werten keine systematische Zu- oder Abnahme
erfahren dürfen, daß sie vielmehr selbst den Typus der regellosen
Schwankungen zeigen müssen. Allerdings muß es möglich sein,
daß diese Differenzen alle dasselbe Vorzeichen haben. Dies tritt
ein, wenn wir für den festen Wert den größten oder kleinsten
Wert der Reihe nehmen. Wollen wir positive \so{und} negative Differenzen
haben, so müssen wir einen Mittelwert zwischen diesen
beiden Extremwerten nehmen, im besonderen den Wert der Reihe,
unter dem höchstens ein Wert der Reihe mehr oder weniger liegt
\DPPageSep{042}{28}
als über ihm. Dann müssen die Vorzeichen der Differenzen
regellos wechseln, es dürfen nicht \zB~die positiven sich in einer
Gegend häufen, insbesondere indem sie nach einer bestimmten
Seite hin zunehmen. Diese einfachen Regeln reichen zu einer
vorläufigen Beurteilung, ob eine vorliegende Reihe als stationär
zu gelten hat, aus. Es wird aber gut sein, wenn wir zunächst
ein paar Beispiele für stationäre Reihen anführen.

Ein erstes wichtiges Beispiel solcher Reihen wird gegeben durch
eine Reihe von \so{Messungen derselben physikalischen Größe}.
Wenn die Messungen leidlich genau sind, weichen die erhaltenen
Werte verhältnismäßig wenig voneinander ab, um so weniger,
je genauer die Messungen waren. Bei physikalischen Größen
glauben wir an einen wahren Wert, dem die durch Messung gefundenen
Werte mehr oder weniger nahe kommen. Die Abweichung
von diesem wahren Wert bezeichnen wir dann als den
\so{Fehler} der Messung. Die Betrachtungsweise, der wir hier folgen,
geht jedoch auf die Bedeutung der Existenz des wahren Wertes,
die immer jenseits des Bereiches der eigentlichen Messungen liegt,
nicht weiter ein, vielmehr ist das einzig Gegebene für uns die
Messungsreihe selbst. Der als Resultat der einzelnen Messungen
niedergelegte Zahlenwert ist der zusammenfassende Ausdruck
eines bestimmten Vorganges, den wir eben als Messung bezeichnen
und bei dem gewöhnlich drei Momente: der der Messung zugrunde
liegende physikalische Tatbestand, die messende Person und das
Meßinstrument, zusammenwirken. Den physikalischen Tatbestand
setzen wir als unabhängig von der messenden oder beobachtenden
Person voraus. Nur unter dieser Voraussetzung ist es möglich,
von einem bestimmten, unabhängig von der Messung bestehenden
Zahlenwert, dem wahren Wert, zu sprechen und die Abweichung
von diesem wahren Wert, den begangenen Fehler, teils der Person
des Messenden, teils dem Meßinstrument zuzuschreiben. So tritt
auch in die sogenannte Fehlertheorie der Glaube an die von der
Wahrnehmung unabhängige Wirklichkeit einer uns umgebenden
Welt entscheidend hinein, und da dieser Glaube, weil er aus den
Sinneswahrnehmungen selbst nicht abgeleitet werden kann, notwendigerweise
metaphysischen Charakter hat, steht auch die so
aufgefaßte Fehlertheorie auf metaphysischem Boden, sie ist nur
transzendent zu begründen, unsere Betrachtungen dagegen sind
wesentlich immanenter Natur, sie bleiben ganz innerhalb der
\DPPageSep{043}{29}
Grenzen der Wahrnehmung, das einzig Gegebene sind für uns die
Beobachtungsresultate selbst, und es handelt sich nur um eine
bestimmte Analysierung dieser Resultate.

Hierdurch ist bedingt, daß wir die als Resultate verschiedener
Messungen derselben physikalischen Größe sich ergebenden Zahlen
nicht anders werten wie irgend eine andere stationäre Zahlenreihe,
bei der es ganz sicher ist, daß die einzelnen Zahlenwerte
sich nicht auf eine und dieselbe physikalische Größe beziehen. Als
ein erstes Beispiel für eine solche Zahlenreihe wollen wir die \so{mit
Roggen bebaute Bodenfläche in Mecklenburg-Schwerin}
während der einzelnen Jahre nehmen:
\begin{center}
\begin{tabular}{c||cTc||cTc||c}
\hline
\hline
\ColHeadbb{Jahr}{Jahr} &
\ColHeadB{Erntefläche}{Erntefläche\\qkm} &
\ColHeadbb{Jahr}{Jahr} &
\ColHeadB{Erntefläche}{Erntefläche\\qkm} &
\ColHeadbb{Jahr}{Jahr} &
\ColHead{Erntefläche}{Erntefläche\\qkm} \\
\hline
\hline
1880 & 1646 & 1889 & 1673 & 1898 & 1582 \\
1881 & 1647 & 1890 & 1673 & 1899 & 1568 \\
1882 & 1646 & 1891 & 1673 & 1900 & 1620 \\
1883 & 1673 & 1892 & 1625 & 1901 & 1661 \\
1884 & 1673 & 1893 & 1703 & 1902 & 1728 \\
1885 & 1673 & 1894 & 1701 & 1903 & 1612 \\
1886 & 1673 & 1895 & 1539 & 1904 & 1652 \\
1887 & 1673 & 1896 & 1618 & 1905 & 1678 \\
1888 & 1673 & 1897 & 1616 & 1906 & 1675 \\
\end{tabular}
\end{center}

Die Tabelle zeigt deutlich, daß wir es hier mit einer stationären
Zahlenreihe zu tun haben, denn die aufgezeichneten Zahlenwerte
bleiben zwischen den Grenzen 1539 und~1728, und es ist
kein merkliches Fortschreiten in der Reihe zu beobachten, vielmehr
gehören der größte und der kleinste Wert zwei mitten in
der Reihe, und zwar ziemlich dicht beieinander liegenden Jahren
(1893 und~1902) an. Es sind aber an diese Zahlenfolge noch
einige kritische Bemerkungen zu knüpfen. Die absolute Unveränderlichkeit
während der Jahre 1883 bis~1891 macht ganz den
Eindruck, als ob sie nicht auf wirklicher Beobachtung beruhte,
sondern dadurch entstanden wäre, daß einfach die Zahlen des
vorigen Jahres wieder hingesetzt wurden. Bei der Frage nach
der Entstehungsweise der Tabelle tritt hier also als wahrscheinlich
ein Grund auf, der von ganz anderer Art ist als die Ursache,
die eine wirkliche Veränderung oder Unveränderlichkeit in den
\DPPageSep{044}{30}
durch die Tabelle gegebenen realen Größen bedeutet. Er bedeutet
einen objektiven Fehler bei der Aufstellung der Tabelle. Derartige
Fehler sind bei statistischen Erhebungen notwendigerweise
mit in Rechnung zu ziehen, sie bilden den größten Übelstand der
Statistik, weil die Versuchung sehr groß ist, mühevollen Erhebungen
durch das Erdichten einer Zahl zu entgehen.

Zu den Zahlenreihen, die auf Grund bestimmter Messungen
oder Zählungen entstehen und an sich stationär sind, können
Zahlenreihen treten, die aus unmittelbar beobachteten Zahlenwerten
erst durch bestimmte Rechenoperationen abgeleitet sind.
Insbesondere fragt es sich, ob sich nicht unter Umständen eine
stationäre Reihe durch Verbindung mehrerer Beobachtungsreihen
ableiten läßt. Wir erläutern dies am besten gleich durch ein der
Physik entnommenes Beispiel. Man denke sich eine U-förmig
gebogene Röhre, deren unterer, gekrümmter Teil mit Quecksilber
gefüllt ist, während der eine, geschlossene Schenkel Luft enthält.
Der andere Schenkel der Röhre ist offen. Wenn hierin Quecksilber
zugegossen wird, wird die Luft im geschlossenen Schenkel komprimiert.
Das Volumen ist aus dem Stande des Quecksilbers sofort
zu bestimmen. Wir messen ferner den Unterschied zwischen der
Höhe des Quecksilbers in dem offenen und in dem geschlossenen
Schenkel und bestimmen daraus den Druck, den die Luft in dem
geschlossenen Schenkel auf das Quecksilber ausübt. Die so bestimmten
Werte von Volumen und Druck zeichnen wir in einer
Tabelle auf und fügen in einer dritten Spalte sogleich das Produkt
zusammengehöriger Werte von Volumen und Druck hinzu.
Aus einer Reihe von Beobachtungen ist so die folgende Tabelle
abgeleitet:
\begin{center}
\begin{tabular}{c|c|c}
\hline
\hline
\ColHeadb{Volumen}{Volumen\\ccm} &
\ColHeadb{cm Hg}{Druck\\cm Hg} &
\ColHead{Produkt}{Produkt} \\
\hline\hline
 20,2 & \Z75,8 & 1531 \\
 19,0 & \Z81,4 & 1547 \\
 17,2 & \Z89,0 & 1531 \\
 15,2 &  100,0 & 1520 \\
 13,8 &  110,0 & 1518 \\
 12,4 &  124,3 & 1541 \\
 11,0 &  139,1 & 1530 \\
\Z9,8 &  156,5 & 1535 \\
\end{tabular}
\end{center}
\DPPageSep{045}{31}

Wir sehen hieraus, daß die Werte von Volumen und Druck
keine stationäre Reihe bilden, wohl aber die durch Multiplikation
zusammengehöriger Zahlen abgeleiteten Werte in der dritten
Spalte. Man sieht nun die durch eine solche Ableitung gefundene
stationäre Reihe als den Ausdruck einer in Wirklichkeit unveränderlichen
physikalischen Größe an. Man setzt daher für die
einzelnen gefundenen Werte eine Konstante~$C$ und findet dann
im vorliegenden Falle, indem man allgemein das Volumen mit~$v$,
den Druck mit~$p$ bezeichnet, als die durch die vorstehende Tabelle
ausgedrückte Beziehung:
\[
p · v = C.
\]

Die Ableitung einer stationären Reihe aus bestimmten gemessenen
Zahlenwerten bedeutet also hier die Ermittelung eines
funktionalen Zusammenhanges zwischen bestimmten physikalischen
Größen oder, wenn man will, ein Naturgesetz, in diesem Falle das
sogenannte \so{Boyle}sche oder \so{Mariotte}sche Gesetz, das die Abhängigkeit
\index{Boylesches (Mariottesches) Gesetz}%
von Druck und Volumen bei gleichbleibender Temperatur
ausdrückt. Die Ermittelung einer stationären Reihe ist
geradezu die Aufgabe bei der Aufdeckung irgend eines physikalischen
Zusammenhanges.

Die Ermittelung eines derartigen einfachen Zusammenhanges
ist meistens nur bei den elementaren Naturerscheinungen möglich.
Es sei gestattet, ein sehr merkwürdiges Beispiel anzuführen, wo sie
auch bei sehr viel höher stehenden Prozessen gelingt. Es ist ein
Beispiel aus der Biologie, das sich auf ein primitives Lebewesen
(Triloculina rotunda), einen mehrkammerigen Kammerling, bezieht.
Hieran hat \so{Iterson} Messungen vorgenommen, durch die er die
\index{Iterson}%
Breite der einzelnen Kammern bestimmte, und dabei gefunden
(vgl.\ \so{Rhumbler}, Die Foraminiferen, Kiel 1911, S.~176):
\index{Rhumbler}%
\[
\begin{array}{c|c|c}
\hline
\hline
\ColHeadb{Kammer}{Kammer} &
\ColHeadb{Kammer-}{Kammer-\\breite} &
\ColHead{jeder Breite zur}{Verhältnis\\jeder Breite zur\\vorhergehenden} \\
\hline
\hline
\Z2 & \Z34 & \Dash \\
\Z3 & \Z45 & 1,32 \\
\Z4 & \Z61 & 1,36 \\
\Z5 & \Z84 & 1,38 \\
\Z6 &  114 & 1,36 \\
\Z7 &  142 & 1,25 \\
\Z8 &  182 & 1,28 \\
\Z9 &  246 & 1,35 \\
 10 &  319 & 1,30 \\
\end{array}
\]
\DPPageSep{046}{32}

Die dritte Spalte bildet wieder eine stationäre Zahlenreihe.
Es ergibt sich also auch hier ein einfacher funktionaler Zusammenhang,
wenn wir die stationäre Reihe als den Ausdruck
einer Konstanten $c$ ansehen. Nennen wir die Breiten der einzelnen
Kammern $y_i$, so finden wir:
\[
\frac{y_{i+1}}{y_{i}} = c,
\]
\dh~die Kammerbreiten bilden eine geometrische Progression,
das sogenannte Gesetz des organischen Wachstums findet sich hier
sehr angenähert verwirklicht.

Die auf die Vorgänge in der menschlichen Gesellschaft bezüglichen
Zahlenreihen zeigen meist keine so einfache Regelmäßigkeit
wie die in der Naturwissenschaft aus bestimmten
Messungen und Zählungen entspringenden Zahlenwerte. So oft
\begin{figure}[hbt!]
  \centering
  \caption{Fig.~3.}
  \Input{046}
\end{figure}
\DPPageSep{047}{33}
man den Versuch gemacht hat, auch sie durch eine Formel darzustellen,
so selten ist es wirklich gelungen, und selbst dann ist
schwer zu sagen, ob die gefundene Formel wirklich einem inneren
Zusammenhange entspricht oder der darzustellenden Reihe rein
äußerlich angepaßt ist. Doch ist bisweilen die Regelmäßigkeit
in den statistischen Zahlenfolgen weit größer, als man gewöhnlich
denkt. Als ein sehr merkwürdiges Beispiel hierfür wollen wir
\index{Pearson}%
nach \so{Pearson} eine Statistik über die \so{Ehescheidungen in den
Vereinigten Staaten}, in der die Häufigkeit der Scheidungen nach
der Dauer der Ehe aufgezeichnet ist, anführen. Man verfährt am
einfachsten so, daß man die Zahlen graphisch aufträgt und dann
durch Probieren eine möglichst einfache Kurve zu finden sucht,
welche dem aufgezeichneten Werte möglichst entspricht. Man
findet in dem vorliegenden Falle eine Kurve von sehr einfachem
Verlauf, die zuerst jäh aufsteigt, etwa bei dem Abszissenwert
$3\frac{1}{2}$~Jahre ein Maximum erreicht und dann allmählich abfällt
(\Fig{3}). Man hüte sich nur, den Ordinaten der Kurve eine unmittelbare
Bedeutung zu geben. Sie ist allein eine Illustration des
Verlaufes der aufgezeichneten Zahlenreihe.

Von Wichtigkeit ist auch, den Verlauf einzelner Verhältniszahlen
näher zu untersuchen, gerade um der Meinung entgegenzutreten,
als ob auch alle \DPtypo{statistische}{statistischen} Verhältniszahlen stationäre
Zahlenreihen lieferten und keine systematischen Veränderungen
zeigten.

Wir wollen als Beispiel die \so{Anzahlen der Lebendgeborenen
in Promille der Einwohnerschaft} während der
einzelnen Jahre im Gebiete des Deutschen Reiches nehmen.
\begin{table}
\centering
\begin{longtable}{@{\,}c||cTc||cTc||c@{\,}}
\hline
\hline
\ColHeadbb{Jahr}{Jahr} &
\ColHeadB{\thsmall Lebendgeborene}{\thsmall Lebendgeborene\\Prom.} &
\ColHeadbb{Jahr}{Jahr} &
\ColHeadB{\thsmall Lebendgeborene}{\thsmall Lebendgeborene\\Prom.} &
\ColHeadbb{Jahr}{Jahr} &
\ColHead{\thsmall Lebendgeborene}{\thsmall Lebendgeborene\\Prom.} \\
\hline
\hline
\endhead
1862 & 36,0 & 1871 & 34,5 & 1880 & 37,6 \\
1863 & 38,3 & 1872 & 39,5 & 1881 & 37,0 \\
1864 & 38,5 & 1873 & 39,7 & 1882 & 37,2 \\
1865 & 38,2 & 1874 & 40,1 & 1883 & 36,6 \\
1866 & 38,3 & 1875 & 40,6 & 1884 & 37,2 \\
1867 & 36,9 & 1876 & 40,9 & 1885 & 37,0 \\
1868 & 36,9 & 1877 & 40,0 & 1886 & 37,1 \\
1869 & 37,9 & 1878 & 38,9 & 1887 & 36,9 \\
1870 & 38,4 & 1879 & 38,9 & 1888 & 36,6 \\
\DPPageSep{048}{34}
1889 & 36,4 & 1897 & 36,1 & 1905 & 33,0 \\
1890 & 35,7 & 1898 & 36,1 & 1906 & 33,1 \\
1891 & 37,0 & 1899 & 35,9 & 1907 & 32,3 \\
1892 & 35,7 & 1900 & 35,6 & 1908 & 32,1 \\
1893 & 36,8 & 1901 & 35,7 & 1909 & 31,0 \\
1894 & 35,9 & 1902 & 35,1 & 1910 & 29,8 \\
1895 & 36,1 & 1903 & 33,8 & 1911 & 28,6 \\
1896 & 36,3 & 1904 & 34,0 &      &      \\
\end{longtable}
\end{table}

Die Zahlenreihe zeigt nach den Einsenkungen in den Kriegsjahren
ein deutlich erkennbares Maximum im Jahre~1876, \dh~auf
dem Gipfel des wirtschaftlichen Aufschwunges nach dem
deutsch-französischen Kriege. Dann folgt eine Abnahme, nach
\begin{figure}[hbt!]
  \centering
  \caption{Fig.~4.}
  \Input{048}
\end{figure}
der sich von etwa 1881 bis~1901 eine anscheinend stationäre
Reihe ergibt, bis etwa von dem Beginn des neuen Jahrhunderts
an sich eine entschiedene Abnahme bemerkbar macht, die von der
Öffentlichkeit auch empfunden und mit Sorge betrachtet wird.
\EndChap
\DPPageSep{049}{35}


\Chapter{Viertes Kapitel}{Das "`Gesetz der großen Zahlen"'}

Von besonderer Bedeutung sind die stationären Reihen, bei
denen die eingetragenen Zahlwerte statistische Verhältniszahlen
sind. Sie bilden sozusagen den Gegenpol der Messungsreihen,
die sich aus wiederholten Messungen derselben physikalischen
Größe ergeben. Während bei diesen die erste Frage die ist, wie
überhaupt eine Abweichung zwischen den gefundenen Zahlwerten
zustande kommt, ist bei den statistischen Verhältniszahlen die
Frage vielmehr die, wie ihre angenäherte Unveränderlichkeit zu
erklären ist, da man ja zunächst für diese Unveränderlichkeit
keinen Grund einsieht, weil die Ereignisse, auf die sich die Verhältniszahlen
beziehen, gewöhnlich voneinander unabhängig sind
und man daher nicht erkennen kann, wie sich aus den Ergebnissen
für die Ereignisse während eines bestimmten Zeitabschnittes
oder allgemein innerhalb irgend eines Zählungsbereiches nach den
Grundsätzen der kausalen Verknüpfung ein Schluß auf die analogen
Ergebnisse während eines neuen Zeitabschnittes oder innerhalb
eines anderen Zählungsbereiches ziehen lassen soll. Derart
würde man dazu geführt werden, die Existenz näherungsweise
konstanter statistischer Verhältniszahlen als eine in einzelnen
Fällen durch die Erfahrung erwiesene, aber nicht zu begründende
Tatsache hinzunehmen. Wenn man für diese Tatsache die gewöhnlich
übliche Bezeichnung "`Gesetz der großen Zahlen"' beibehalten
wird, so muß man sich dabei klar sein, daß es sich nicht
im eigentlichen Sinne um ein Gesetz, \dh~eine unverbrüchliche
Regelmäßigkeit handelt, sondern nur um eine Tatsache, die bisweilen
beobachtet wird. Das "`Gesetz"' bedeutet nur ein Prinzip
der Auswahl, indem man insbesondere solche Verhältniszahlen
herausgreift, die sich als näherungsweise konstant erweisen, ohne
sagen zu können, warum sie es sind, und ohne überhaupt sagen
\DPPageSep{050}{36}
zu können, daß allen so herausgegriffenen Ereignissen eine bestimmte
innere Gleichartigkeit zuzuschreiben sei.

Es ergeben sich aber auch hierbei von vornherein gewisse
Schwierigkeiten, die nicht zu unterschätzen sind. Zunächst ist zu
beachten, daß die Unveränderlichkeit nie eine absolute, sondern
immer nur eine angenäherte ist. Es ist daher nicht allgemein
zu entscheiden, wann überhaupt statistische Verhältniszahlen als
konstant angesehen werden sollen, sondern es bleibt immer der
Willkür überlassen, festzulegen, innerhalb welcher Grenzen die
Schwankungen dieser Zahlen sich halten müssen, damit man sie
noch als konstant ansehen kann. Je nachdem, wie man über diese
Frage entscheidet, wird der Bereich der konstanten statistischen
Verhältniszahlen weiter oder enger gezogen.

Nun ist es aber nicht allein die Größe der Schwankungen, es ist
auch ihre Form, die in Betracht kommt. Wenn die Veränderungen
in einer Reihe von Verhältniszahlen zwar gering sind, aber sich
deutlich ergibt, daß diese Zahlen fortwährend ab- oder zunehmen,
so wird man ungern diese Zahlen als konstant betrachten, vielmehr
springt eine bestimmte Änderungstendenz so deutlich in die
Augen, daß man sie nicht ignorieren kann und deshalb von einer
"`systematischen Änderung"' sprechen muß. Anders ist es, wenn
wenigstens für den ersten Anblick regellos Zu- und Abnahme miteinander
wechseln. Dann erkennt man keine bestimmte Änderungstendenz
und man ist vielmehr geneigt, von einer gewissen
Konstanz in den Verhältniszahlen zu sprechen.

Es ist allerdings zu bemerken, daß solche bloß regellose
Schwankungen verhältnismäßig selten sind und daß die Aufgabe
der Statistik im allgemeinen eher darin besteht, die systematischen
Änderungen in den Zahlenreihen zu finden, als die Fälle herauszugreifen,
in denen solche Änderungen fehlen. Zweifellos aber kann
man, auch wo offenbar systematische Änderungen vorhanden sind,
falls sie in gewissen engen Grenzen bleiben, immer noch die Frage
aufwerfen, wie es denn kommt, daß man nur so geringe Änderungen
findet, während man von vornherein doch auf viel größere
Schwankungen gefaßt sein müßte. Wenn sich jedes Jahr eine
ziemlich gleichbleibende Zahl von Gestellungspflichtigen durch
Selbstverstümmelung dem Militärdienst zu entziehen sucht, so ist
dies eine Tatsache, auf die man von vornherein nicht gefaßt sein
kann. Man könnte sich doch ebensogut denken, daß es in einem
\DPPageSep{051}{37}
Jahr viermal oder zehnmal so viel wie in einem anderen sind, denn
es besteht ja gar kein ursächlicher Zusammenhang zwischen den
Ergebnissen der einzelnen Jahre. Was im einen Jahre geschehen
ist, läßt sich nicht im geringsten übertragen auf das, was im
nächsten Jahre geschehen wird. Es kommen ganz neue Personen
in Betracht, die mit den im Vorjahre Beobachteten in keinerlei
Beziehung stehen. Jeder einzelne handelt für sich, unabhängig
und meist ohne Kenntnis von den übrigen. Alle Versuche zur
Erklärung der geringen Veränderlichkeit statistischer Verhältniszahlen,
die bisher gemacht sind, scheinen mir denn auch nicht
das erstrebte Ziel zu erreichen. Meistens werden folgende Gesichtspunkte
hervorgehoben: Wenn \zB~jedes Jahr ungefähr derselbe
Bruchteil der Menschen durch Selbstmord aus dem Leben scheidet, so
liege dieses daran, daß unter den lebenden Individuen ein gewisser
Prozentsatz in bestimmter Weise krankhaft veranlagt ist, und
durch eine Reihe von Umständen, die fast immer in der gleichen
Weise vorhanden sind, vermöge ihrer krankhaften Veranlagung
zum Selbstmord getrieben wird. Diese Erklärung klingt an sich
durchaus annehmbar. Man muß schon etwas näher zusehen, um
zu erkennen, daß sie in Wirklichkeit gar keine Erklärung im Sinne
einer Zurückführung auf leichter zu durchschauende Tatsachen ist.
Wir können nämlich zunächst fragen: Wie kommt es denn, daß ein
bestimmter Prozentsatz der lebenden Individuen eine krankhafte
Neigung zum Selbstmord besitzt? Selbst wenn diese Neigung in
allen Fällen von den Eltern auf die Kinder überginge und nur
auf diese Weise zustande käme, so daß immer die Kinder der zum
Selbstmord veranlagten Personen und nur diese die gleiche Neigung
besitzen, selbst dann bliebe noch zu erklären, wie es kommt, daß
von einer Gruppe Menschen, die einen bestimmten Prozentsatz der
Bevölkerung ausmacht, auch die Nachkommen immer wieder angenähert
denselben Prozentsatz der Bevölkerung ausmachen, was ja
durchaus nicht selbstverständlich ist, da die Anzahl der Kinder
von einem Ehepaar zum anderen erheblich wechselt, auch die
so veranlagten Personen nicht immer zur Heirat gelangen, und
schließlich bleibt auch zweifelhaft, wenn nur eines der Eltern die
Anlage besitzt, ob dann das Kind sie wieder erbt, denn wenn das
immer der Fall wäre, müßte ja die Anzahl der so disponierten
Personen rapid zunehmen. Eine eigentliche Erklärung ist so
schon bei dieser Annahme nicht gegeben, und noch viel weniger,
\DPPageSep{052}{38}
wenn die Veranlagung zum Selbstmord auch durch andere uns unbekannte
Umstände bei der Zeugung oder im Verlauf der Entwickelung
zustande kommen kann. Endlich läßt sich nicht einmal
behaupten, daß in allen Fällen der Selbstmord auf einer bestimmten
Veranlagung beruhe, durch eine Reihe besonderer Umstände, insbesondere
den wirtschaftlichen oder moralischen Zusammenbruch,
kann möglicherweise auch ein normal veranlagter Mensch zum
Selbstmord getrieben werden. Namentlich ist ja bekannt, daß
Liebespaare, ohne daß beide Teile zum Selbstmord prädisponiert
sein müssen, durch die erotische Stimmung zum Selbstmord gebracht
werden. Alles das sind Umstände, die sich von vornherein
nicht abwägen lassen. Man kann in allen Fällen nur dieselbe
Behauptung wiederholen, es befinde sich in der menschlichen Gesellschaft
von den unter den verschiedenen Einwirkungen stehenden
Individuen immer angenähert ein bestimmter Prozentsatz. Dadurch
wird aber die eigentliche Tatsache der Unveränderlichkeit
nicht erklärt, sondern nur fortgesetzt behauptet. Gewiß können
wir behaupten, es befinde sich in der Gesellschaft immer angenähert
derselbe Prozentsatz von unglücklichen Liebenden oder bankerotten
Existenzen, aber wie dieses wiederum zu erklären sei, dafür fehlt
uns ebensosehr jede Handhabe wie für die ursprüngliche Frage.
Das anfängliche Problem wiederholt sich immer aufs neue.

Auch die Berufung auf eine durchgehende Gesetzmäßigkeit,
die in der menschlichen Gesellschaft ebenso wie in der Natur
walten müsse, erklärt gar nichts, ebensowenig wie der Vergleich
mit den die Ordnung im Staat herstellenden Gesetzen\footnote
  {\mbox{Vgl.\ \so{Ad}.\ \so{Wagner}}, Die Gesetzmäßigkeit in den scheinbar willkürlichen
\index{Wagner, Ad.}%
  menschlichen Handlungen. Hamburg 1864.}.
Allerdings
ist es nicht ganz so, wie \so{Windelband} (Die Lehren vom
\index{Windelband}%
Zufall, Inauguraldiss., Göttingen 1871, S.~47) sagt, daß ein naturwissenschaftliches
Gesetz nur da vorliege, wo sich \so{genau} dasselbe
numerische Verhältnis herausstellt. Denn alle Beobachtung zeigt
wegen der unvermeidlichen Beobachtungsfehler und wegen der
stets wirksamen störenden Nebenerscheinungen nie die genaue,
sondern immer nur die angenäherte Erfüllung des Gesetzes. Wir
können aber überhaupt nicht von einer naturgesetzlichen Erklärung
reden, wo nur in einem bestimmten Bruchteil der in Betracht
kommenden Fälle ein bestimmter Erfolg eintritt. Das Wesen der
\DPPageSep{053}{39}
Naturerklärung ist nämlich, daß wir mit einer Erscheinung immer
eine andere Erscheinung verknüpft finden. Wenn wir daher die
Erklärungsweise der Naturwissenschaft beibehalten wollen, so
müssen wir die wirklich beobachteten Tatsachen derart ergänzen,
daß wir in allen Fällen, wo bestimmte Voraussetzungen erfüllt
sind, auch einen bestimmten Erfolg erhalten. Wir fügen daher
zu den konstanten Bedingungen, die in allen Fällen gleichmäßig
erfüllt sind, variable Bedingungen hinzu, die den Erfolg im einzelnen
Falle entscheiden. Nehmen wir \zB~die Kindersterblichkeit
während der ersten Lebensmonate. Wir können dann sagen, daß
der Tod der Kinder aus ihrer geringen Lebensfähigkeit folgt. Wir
teilen also den Kindern bei ihrer Geburt eine verschiedene Lebenskraft
zu, nach der sich ihre Lebensdauer bestimmt. Es gehen aber
die Kinder nicht ein, wie ein Lichtstummel verlöscht, wenn er abgebrannt
ist, sondern es tritt immer, wenn sie sterben, eine äußere
Ursache hinzu, die auch ausbleiben kann. Ob und wann das geschieht,
dafür fehlt uns jede Kontrolle. Wir sind also auch hier darauf
angewiesen, bloß zu sagen: unter den Kindern mit schwacher
Lebenskraft werden mehr sterben, als unter den kräftigen Kindern.
Selbst das aber kann zweifelhaft erscheinen, denn es könnte doch
auch einmal glücken, daß die schwächlichen Kinder besser davonkommen
wie die kräftigen. Wie es aber zustande kommt, daß
einzelne Kinder lebensfähig sind, die anderen nicht, darüber
können wir nie etwas Bestimmtes sagen. Gewiß können wir eine
Reihe von Umständen angeben, die auf die Lebenskraft des Kindes
Einfluß haben: der Ernährungszustand der Mutter während der
Schwangerschaft, die physische Beschaffenheit der Eltern usw.,
aber nie finden wir Umstände, unter denen in keinem Falle oder
in jedem Falle das Kind lebenskräftig ist. Ebenso übt natürlich
auch die Säuglingspflege ihren Einfluß auf die Sterblichkeit der
Kinder aus, aber wir können wiederum nicht sagen, daß ein
schlecht gepflegtes Kind, wenn es von Geburt an schwach war,
immer, und ein gut gepflegtes Kind, wenn es der Anlage nach
kräftig ist, nie stirbt. Die durchgängige Verbindung zweier Tatsachen,
die das Wesen der Erklärung in der Naturwissenschaft
ausmacht, findet also nicht statt, wenn wir bloß allgemein von
der Lebensfähigkeit oder Lebensmöglichkeit sprechen und nicht
auf alle besonderen Umstände eingehen, die im einzelnen Falle
den Tod des Kindes herbeigeführt haben. Nicht anders ist es mit
\DPPageSep{054}{40}
dem Geschlechtsverhältnis der Geborenen, das zu den konstantesten
Verhältniszahlen der Statistik gehört. Alle beobachtbaren Umstände
reichen nicht aus, um das Geschlecht des geborenen Kindes
mit Bestimmtheit angeben zu können. Allerdings knüpft sich
gerade an diesen Fall eine allgemeine Erklärung an, welche die
Geschlechtsbestimmung auf elementarere Vorgänge zurückführt.
Man nimmt nämlich an (vgl.\ \so{Lexis}, Abhandlungen zur Theorie der
\index{Lexis|f}%
Bevölkerungs- und Moralstatistik, Jena~1903, S.~94), daß schon die
Keimzellen, seien es allein die weiblichen oder auch die männlichen,
geschlechtlich bestimmt seien und das in ihnen angelegte Geschlechtsverhältnis
auch in dem Geschlechtsverhältnis der Geburten
zutage tritt. Der Fall, der hier vorläge, wenn diese Erklärung
richtig sein sollte, läßt sich durch folgendes Bild veranschaulichen.
Ich habe in einer Tonne Bohnen und Erbsen gemischt und gut
durcheinandergerührt; ich greife nun mit einem kleineren Gefäß
eine gewisse Menge aus der Mischung heraus, dann behaupte ich,
daß die Mischung in der herausgegriffenen Probe dieselbe sei wie in
dem ganzen Gefäß. Diese Tatsache wird auch allgemein als richtig
anerkannt. Wo im Handel Mischungen (etwa von zwei Kaffeesorten)
hergestellt werden, verläßt man sich darauf, daß das Verhältnis der
gemischten Substanzen in jedem Teil dasselbe sei wie im ganzen.
Wenn wir an der Richtigkeit der Tatsache aber auch nicht zweifeln,
so fehlt uns doch eine kausale Erklärung dafür. Wir können die
Tatsache auffassen als ein Axiom, was heißt, daß wir sie nur als
richtig annehmen, aber auf ihre Erklärung verzichten. Doch bedeutet
der Verzicht auf eine kausale Erklärung immer noch nicht den
Verzicht auf eine erkenntnistheoretische Erklärung. Auch die
Geometrie nimmt ja eine Reihe von Axiomen als unbewiesene
Tatsachen an, aber die Erkenntnistheorie setzt gerade bei diesen
Axiomen ein und sucht ihr Zustandekommen und ihre Bedeutung
zu erklären.

So geht es auch hier. Wir fühlen das Bedürfnis, eine Erklärung
dafür zu suchen, wie diese Tatsache, die wir kausal nicht als hinreichend
erklärt ansehen können, in Wirklichkeit zustande kommt.
Im Grunde ist es nun folgende Anschauung, die häufig Platz
greift. Da die natürliche Erklärung aus regelmäßigen Verknüpfungen
bestimmter Erscheinungen versagt, greift man zu einer
übernatürlichen Deutung. Man denkt sich eine Art ausgleichender
Gerechtigkeit, die das Gleichmaß herstellt. Wie, das können wir
\DPPageSep{055}{41}
freilich nicht sagen. Wir müßten uns denn kleine Dämonen denken,
die darauf wirken, den Ausgleich herzustellen, die \zB~bei der Befruchtung
die männlichen und weiblichen Keimzellen in dem gehörigen
Verhältnis zur Geltung bringen, die also untereinander im
Verkehr stehen und gegenseitig ihre Tätigkeit regulieren, die auch
für die richtige Verteilung der Krankheitskeime sorgen und dadurch
die gehörige Anzahl Kinder sterben lassen, usw. Wem diese
Erklärung reichlich phantastisch scheint, der möge sich klar machen,
daß es schwer einzusehen ist, wie man ohne die Annahme solcher
übernatürlicher Regulative eine Erklärung erzielen kann. Man
muß eben bedenken, daß der eine Fall mit dem anderen äußerlich
in gar keiner Beziehung steht. Jede solche Beziehung, wie sie \zB~bei
der Kindersterblichkeit durch eine Epidemie gegeben ist, würde
im Gegenteil den Ausgleich verhindern, durch sie würde sich ja
die normale \DPtypo{Sterlichkeit}{Sterblichkeit} erhöhen. Wir dürfen also keine kausale
Beziehung zwischen den einzelnen Fällen annehmen. Wie sollen
wir sie dann miteinander in Verbindung bringen? Welchen Grund
haben wir, anzunehmen, daß wenn ein Ereignis, \zB~ein Verbrechen
wie Diebstahl oder Notzucht, während eines Jahres in
Deutschland eine gewisse Anzahl Male eingetreten ist, daß es dann
im nächsten Jahre zwar nicht genau, aber doch ungefähr ebensooft
eintreten wird. Gewiß können wir rechnen, daß wir in Deutschland
eine gewisse Anzahl zu dem Verbrechen disponierte Personen
haben, aber da diese Personen doch das Verbrechen nicht jedes
Jahr ausführen, so ist gar nicht abzusehen, warum nicht ein Jahr
zufällig frei bleiben soll. Wenn Hinz das Verbrechen nicht ausführt,
so ist das gar kein Grund für Kunz, seinerseits das Verbrechen
zu begehen. Und doch widerstreitet die Annahme einer
großen Unregelmäßigkeit in solchen statistischen Verhältniszahlen
durchaus unserem Empfinden. "`Wenn in einem Lande"', sagt \so{Lexis}
(\aaO, S.~98), "`in einem Jahre $1000$ Unterschlagungen stattgefunden
haben, so ist nicht zu erwarten, daß dieses Verbrechen
im anderen Jahre gar nicht und wieder in anderen Jahren in
$10\,000$ Fällen vorkommen werde"'. "`In einer großen Bevölkerung
sind fortwährend"', fügt er zur Erklärung hinzu, "`alle Abstufungen
zwischen Arm und Reich vorhanden, ebenso alle Arten von Geschäftsbeziehungen
und Amts- und Dienststellungen, die zu einem
solchen Verbrechen Veranlassung geben können, ferner werden
immer wieder viele Personen von wirtschaftlichen Schwierigkeiten,
\DPPageSep{056}{42}
Verlegenheiten und Notständen betroffen, auch sind Leichtsinn,
Gewissenlosigkeit, Verschwendungssucht und andere üble Eigenschaften
stets in mannigfaltigen Graden verbreitet, und so treffen
denn auch immer wieder die Bedingungen, die zu dem genannten
und anderen Verbrechen und Vergehen gegen das Eigentum führen,
in einer Anzahl von Fällen zusammen."' Das ist alles gewiß richtig,
aber unter allen diesen Umständen ist kein einziger, der mit Notwendigkeit
zu dem Verbrechen führt, und wir können deshalb auch
durchaus nicht einsehen, warum mit Notwendigkeit oder nur mit
einer gewissen Sicherheit anzunehmen ist, daß die Schwankungen
in der relativen Häufigkeit des Verbrechens unter einer bestimmten
Grenze bleibt. Man kann vielleicht sagen: vom sozialwissenschaftlichen
Standpunkt ist alles klar, nur vom erkenntnistheoretischen
Standpunkt liegt ein Problem vor. Es ist aber kein Zweifel, daß
dieses Problem, auch wenn wir dafür keine bestimmte Antwort,
sondern nur eine feste Fragestellung finden, von der größten Bedeutung
ist. Denn auf der Tatsache, um deren Erklärung es sich
hier handelt, beruht ja überhaupt die Möglichkeit eines wirtschaftlichen
und staatlichen Lebens. Sonst würde alles durcheinander
geraten. In einem Jahre würde der Stand der Unschuld herrschen,
im Jahre darauf wäre keiner seines Lebens und seines Eigentums
sicher. Die Bevölkerung würde sich nicht gleichmäßig verteilen,
in einem Jahre würden fast gar keine, im anderen zu viel Kinder
geboren werden, einmal würde es an Arbeitskräften fehlen, dann
wären sie wieder im Überfluß da und nähmen sich das Brot weg.
Da aber nicht bloß die vom menschlichen Willen abhängigen
Vorgänge, sondern auch die Ereignisse der Natur auf einem
statistischen Ausgleich beruhen, so würde die Verwirrung sich
immer weiter häufen. Während jetzt, von einzelnen Mißernten
abgesehen, Jahr für Jahr genügend Nahrung für alle emporwächst,
würden dann die fetten und mageren Jahre regellos wechseln, einmal
würde die Nahrung verderben und das andere Mal würden
die Menschen Hungers sterben. So würde alle Ordnung und
Sicherheit verloren gehen, alle menschliche Fürsorge würde unmöglich
gemacht, der Mensch könnte nur stumpfsinnig in den
Tag hineinleben und damit müßte alle Kultur erlöschen. Wir sehen
daher, wie alles von diesem Ausgleich abhängt, für den wir im
strengen Sinne des Wortes, nämlich im Sinne eines unverbrüchlichen
ursächlichen Zusammenhanges, doch keine Erklärung geben können.
\DPPageSep{057}{43}

Die Annahme eines solchen Ausgleichs erweist sich schon in
den elementarsten Naturerscheinungen als notwendig. Auf ihm
beruht \zB~der sogenannte zweite Hauptsatz der Wärmetheorie,
der aussagt, daß Wärme nicht von selbst vom kälteren zum
wärmeren Körper übergeht. Gerade für diesen Fall hat schon
\so{Maxwell} darauf hingewiesen, daß die logische Notwendigkeit des
\index{Maxwell}%
Ausgleichs nicht einzusehen sei. Dieser zweite Hauptsatz ist nicht
ein Naturgesetz wie andere, er hat nur die Bedeutung einer Annahme,
der wir uns nicht entziehen können; diese Annahme ist
im Grunde dieselbe, die auch die Grundlage aller wirtschaftlichen
Regelmäßigkeit bildet.

Die Annahme scheint so natürlich, so unausweichlich, daß man
naturgemäß trachtet, sie auch als selbstverständlich zu erweisen.
Dieser an sich durchaus begreifliche Trieb hat sich auch bei den
Annahmen gezeigt, welche die Geometrie machen muß, ohne sie
weiter beweisen zu können. So hat es lange gedauert, ehe man
das bekannte Parallelenaxiom (wonach es in einer Ebene durch
einen Punkt außerhalb einer Geraden nur eine Gerade gibt, welche
die erste Gerade nicht schneidet) als das erkannte, was es ist, als
eine unbeweisbare Annahme. Vorher glaubte man immer, nach
einer Erklärung oder einem Beweise für eine Tatsache suchen zu
müssen, die vom Standpunkte des reinen Denkens so merkwürdig
scheint und auf die unsere Anschauung uns doch gleichsam von
selbst hinführt.

Ähnlich liegt der Fall auch hier. Die Annahme einer durchgängigen
Regelmäßigkeit in den Massenerscheinungen wurzelt so
tief in uns, daß wir sie uns unmittelbar begreiflich zu machen,
sie uns zu erklären suchen. Zu einer solchen Erklärung haben
viel die besonderen Massenerscheinungen beigetragen, die wir aus
den Glücksspielen ableiten. Diese Massenerscheinungen sind zum
großen Teil nicht wirklich beobachtete Erscheinungen, sondern
bloße Gedankenexperimente. Man denkt sich \zB, es werde ein
Würfel sehr oft geworfen, tausende von Malen, ohne es wirklich
auszuführen, und urteilt dann ohne weiteres, es werde jede der
sechs Seitenflächen des Würfels hierbei annähernd gleich oft oben
zu liegen kommen. Lassen wir es einmal dahingestellt, inwieweit
ein solches Gedankenexperiment möglich ist, inwieweit der Schluß
berechtigt ist: "`Es läßt sich absolut nicht einsehen, warum eine
Seitenfläche öfter als die andere oben zu liegen kommt, und deshalb
\DPPageSep{058}{44}
kommen sie alle gleich oft oben zu liegen"'. Nehmen wir die
Tatsache ohne weiteres als richtig an, so würde aus ihr allerdings
mit Sicherheit folgen, daß, wenn wir jetzt drei Seiten der Würfel
weiß und die anderen drei rot anstreichen, in der \so{Hälfte} der
vorkommenden Fälle eine weiße Seite oben zu liegen kommt.

\so{Windelband}, der (\aaO) mit Recht entschieden davor warnt,
\index{Windelband}%
die gleichbleibenden Verhältniszahlen der Statistik als eine Gesetzmäßigkeit
auf den einzelnen Fall zu übertragen, und ebenso energisch
zurückweist, daß ein mechanischer Ausgleich zwischen den
einzelnen Fällen zustande kommt, da das Resultat eines Falles
auf das Resultat der anderen Fälle keinen Einfluß ausübt, gibt
doch den konstanten Bedingungen der Ereignisse eine Bedeutung,
die über die Grenzen des Erfahrungsmäßigen hinausgeht, wenn
er sagt: "`Je öfter man die konstanten Bedingungen in Wirksamkeit
treten läßt, desto mehr gibt man allen in denselben enthaltenen
Möglichkeiten Gelegenheit, sich zu realisieren, und es liegt im Begriffe
der gleich möglichen Fälle, daß bei einer genügend großen
Anzahl von Fällen jeder Möglichkeit eine gleiche Menge von Gelegenheiten
zu ihrer Realisierung geboten wird. Wenn nun
mehrere Möglichkeiten, weil sie das gemeinsame Merkmal der
günstigen Fälle haben, als eine Möglichkeit angesehen werden,
so werden die dieser Möglichkeit gebotenen Gelegenheiten der
Realisierung eine Summe darstellen, in welcher die jeder einzelnen
Möglichkeit gebotene Anzahl von Gelegenheiten so oft enthalten
ist, als jene angenommene Möglichkeit einzelne Möglichkeiten unter
sich begriff. Wenn man, um das obige erste Beispiel wieder anzuwenden,
fortwährend mit dem Würfel spielt, so werden, da die
Möglichkeit weiß zu werfen drei Möglichkeiten unter sich begreift,
dieser Möglichkeit dreimal soviel Gelegenheit zu ihrer Realisierung
geboten, als jeder einzelnen anderen Möglichkeit. So wird bei gesteigerter
Menge von Fällen allmählich das numerische Verhältnis
der Wiederholungen, in denen die einzelnen Fälle auftreten, demjenigen
der Möglichkeiten mehr und mehr gleichkommen, und es
werden sich in der Summe von Fällen die konstanten Bedingungsverhältnisse
mehr und mehr als die Verhältniszahlen der Wiederholungen
geltend machen."'

In dieser Erklärung steckt unverhüllt der alte Begriff der
Möglichkeit als eines potentiellen Seins, dem die Gelegenheit geboten
werden kann, sich in die Wirklichkeit zu übertragen, das
\DPPageSep{059}{45}
aber auch nicht in die Erscheinung treten kann. Das einzelne
Ereignis ist eine solche Gelegenheit zur Verwirklichung. Daß
diese Gelegenheit in einem bestimmten Bruchteil der vorkommenden
Fälle ergriffen und in den übrigen verschmäht wird, liegt
wohl in dem Charakter der Möglichkeit. Die Möglichkeit begreift
sozusagen einen gewissen Prozentsatz Wirklichkeit in sich, auf
den sie ihrer Besonderheit gemäß eingestellt ist und dem sie zustrebt,
wie ein Mensch die sich ihm bietenden Gelegenheiten zu
essen, zu schlafen oder zu reden in einem bestimmten Maße benutzt.

Statt der \so{Möglichkeiten}, die sich in einem gewissen Bruchteil
der Fälle verwirklichen, kann man auch \so{Ursachen} setzen, die
nur in demselben Bruchteil der Fälle wirksam werden, ohne daß
irgend ein Grund anzugeben ist, warum sie einmal wirken und
einmal nicht, oder man kann auch an Ursachen denken, die verschieden
wirken, ohne daß diese Verschiedenheit irgend welche
Regelmäßigkeit zeigt. Dieses ist die Auffassung, welche die Ursachen
in zwei Arten, konstante und zufällige, zerlegt und danach
das "`Gesetz der großen Zahlen"' begründet. So hat es \so{Poisson}
\index{Poisson}%
eingeführt (Note sur la loi des grands nombres, Comptes Rendus
de l'Académie des Sciences, Bd.~2, Paris~1836). Nach ihm besteht
es darin, daß, "`wenn man sehr große Anzahlen von Erscheinungen
derselben Art beobachtet, welche von konstanten und von unregelmäßig
veränderlichen Ursachen abhängen, die aber nicht \DPtypo{progessiv}{progressiv}
veränderlich sind, sondern bald in dem einem und bald in dem
anderen Sinne wirken, man zwischen diesen Zahlen Verhältnisse
findet, welche fast unveränderlich sind. Diese Verhältnisse haben
bei jeder besonderen Art von Erscheinungen einen speziellen Wert,
welchem sie sich immer mehr nähern, je größer die Anzahl der
beobachteten Erscheinungen wird, und welchen sie in aller Strenge
erreichen würden, wenn die Reihe der Beobachtungen ins Unendliche
fortgesetzt werden könnte"' (Recherches sur la probabilité des
jugements, Paris~1837, deutsch von~\so{Schnuse} unter dem Titel
\index{Schnuse (Übersetzer)}%
Lehrbuch der Wahrscheinlichkeitsrechnung, Braunschweig~1841).

Diese Formulierung wird uns noch klarer verständlich, wenn
wir die entsprechende Stelle in \so{Laplace}s Philosophischem Versuch
\index{Laplace|f}%
über die Wahrscheinlichkeiten (Paris~1814, als Einleitung
zu seinem großen Werke Théorie analytique des probabilités)
nachschlagen. Es heißt dort: "`Inmitten der veränderlichen und
unbekannten Ursachen, die wir unter der Bezeichnung Zufall zusammenfassen
\DPPageSep{060}{46}
und die den Gang der Ereignisse ungewiß und unregelmäßig
machen, sehen wir in dem Maße, wie sie an Zahl zunehmen,
eine auffallende Regelmäßigkeit auftauchen, die einen
planmäßigen Eindruck macht und die man oft als einen Beweis
für die göttliche Vorsehung angesehen hat. Aber wenn man
genauer zusieht, erkennt man bald, daß diese Regelmäßigkeit nur
die Entfaltung der Möglichkeiten für die verschiedenen Einzelereignisse
bedeutet, die um so öfter eintreten müssen, je wahrscheinlicher
sie sind. Denken wir uns \zB, daß man aus einer
Urne, die schwarze und weiße Kugeln gemischt enthält, sehr oft
hintereinander eine Kugel zieht und sie jedesmal wieder zurücklegt.
Das Verhältnis der gezogenen schwarzen und weißen Kugeln
wird dann meist erst sehr unregelmäßig sein, aber die veränderlichen
Ursachen, denen diese Unregelmäßigkeit entspringt, bringen
abwechselnd günstige und ungünstige Wirkungen auf den regelmäßigen
Gang der Ereignisse hervor und lassen, indem sie sich
bei einer großen Anzahl von Ziehungen zerstören, mehr und mehr
das Verhältnis der in der Urne enthaltenen schwarzen und weißen
Kugeln hervortreten."'

Diese Auffassung von \so{Laplace} ist in der philosophischen
Literatur häufig aufgenommen worden. So sagt \zB~ganz in
diesem Sinne W.~\so{Wundt} in seiner Logik: "`Die Annahme des
\index{Wundt, Wilh.}%
Zufalls schließt stets eine bestimmte objektive Bedingung ein.
Diese Bedingung besteht darin, daß die zufälligen Abänderungen
eines Ereignisses in einer unendlich großen Anzahl von Fällen sich
aufheben müssen. Jede konstante, nicht sich ausgleichende Abweichung
von diesem Werte gilt nicht mehr als ein Werk des Zufalls,
sondern als die Wirkung bestimmter Ursachen, deren Ermittelung
ein Problem der wissenschaftlichen Forschung ist. Im
strengsten Sinne gilt nur derjenige Teil einer individuellen Schwankung
als Zufall, welcher sich der Elimination fügt. Die zufälligen
Abweichungen sind jeder kausalen Untersuchung entzogen. Denn
da wir Ursachen nur aus ihren Wirkungen erschließen und an
ihnen messen können, so sind diejenigen Ursachen, deren Wirkungen
sich permament ausgleichen, unerforschbar; glücklicherweise
bedürfen sie eben auch wegen dieser Ausgleichung keiner
Untersuchung."'

Was gegen die zuletzt angeführten Erklärungsversuche eingewendet
werden muß, ist wiederum, daß, wenn wir von Ursachen
\DPPageSep{061}{47}
sprechen, die im Einzelfalle den Erfolg bestimmen, und behaupten,
im Wesen dieser Ursachen liege ein gegenseitiger Ausgleich durch
eine geheimnisvolle Beziehung zwischen ihnen, wir sozusagen diese
Ursachen beleben. Wir deuten sie nach Analogie lebender Wesen,
die zueinander in Beziehung treten können, die ihr Wirken gegenseitig
regulieren und mit Absicht durch ihr Zusammenwirken einen
bestimmten Zustand herbeiführen. So unwissenschaftlich eine
solche Auffassung auch scheinen mag, so verbreitet ist sie selbst
unter den schärfsten Denkern und so stark hat sie sich im Sprachgebrauch
festgeheftet. So behauptet auch \zB~\so{Sigwart} in seiner
\index{Sigwart}%
Logik: "`In den Fällen des Würfelns \zB~wissen wir, sei es
aus der Beschaffenheit der Ursachen, welche die einzelnen Fälle
verwirklichen, sei es aus der Erfahrung, daß in einer größeren
Anzahl von Fällen die einzelnen Würfe annähernd gleich häufig
auftreten, daß die realen Ursachen, welche die bestimmten Würfe
\so{herbeiführen}, in der Weise abwechseln, daß sie keinen Wurf
vor den anderen \so{bevorzugen}."' Ähnlich sagt \so{Friedrich Albert
Lange} in seinen Logischen Studien: "`Es ist a priori und nach
\index{Lange@Lange, Friedr.\ Albert}%
Analyse aller Erfahrung anzunehmen, daß die unbekannten und
in der Rechnung fehlenden Umstände dem Ergebnis \so{ebenso
leicht günstig als ungünstig sein können}."' Wie dies
a priori anzunehmen sein soll, ist mir unverständlich. In völliger
Allgemeinheit ist der Satz ja nicht einmal richtig. Es würden
durch ihn besondere Ereignisse herausgegriffen werden, bei denen
wir in einem bestimmten eng umgrenzten Sinne von Zufall sprechen
können. Wir würden eben definitionsmäßig von Zufall dann
reden, wenn bei verschiedenen Ermittelungen der relativen Häufigkeit
eine Abweichung nach der einen Seite ebensooft eintritt, wie
eine gleich große Abweichung nach der anderen Seite. Gemeint
sind aber wohl nicht die wirklich resultierenden Abweichungen,
sondern die elementaren Abweichungen, die jeder einzelnen der
wirkenden Ursachen zuzuschreiben sind. Daß die unbekannten
Umstände dem Ergebnis ebenso leicht günstig als ungünstig sein
können, ließe sich dann so auffassen, daß die elementaren Abweichungen,
die jeder einzelne dieser Umstände in der relativen
Häufigkeit hervorrufen würde, sich symmetrisch um einen Mittelwert
gruppieren. Wir werden später sehen, wie diese Annahme
rechnerisch zur Geltung kommt. Sie bedeutet in der Tat, daß die
entstehenden Schwankungen im Gesamtergebnis durchaus den
\DPPageSep{062}{48}
Charakter des Zufälligen haben. Sehen wir uns die Sache aber
etwas näher an! Nehmen wir \zB~den Fall einer Knaben- oder
Mädchengeburt, so dürfen wir nicht etwa die Umstände,
die das Geschlecht des Kindes bestimmen, als gleich günstig
einer Knaben- wie einer Mädchengeburt ansehen, denn das Verhältnis
der Knaben- und Mädchengeburten ist nicht das der
Gleichheit. Es würden als solche Umstände vielmehr nur die
Ursachen in Frage kommen, die ein Abweichen von einem gewissen
normalen Wert des Verhältnisses von Knaben- und Mädchengeburten
bedingen. So gelangen wir jedoch nicht zu einer Erklärung
des Tatbestandes, denn die realen Umstände, die in Frage
kommen können, wirken eben nicht auf das Abweichen von einem
normalen Verhältniswert im \DPtypo{statististischen}{statistischen} Gesamtergebnis, sondern
auf das einzelne Ereignis, die Geburt eines Knaben oder
eines Mädchens, hin. Sie gleichen sich bestimmt nicht aus in
dem Sinne, daß sie der Geburt eines Knaben ebenso günstig sind,
wie der Geburt eines Mädchens, vielmehr sind sie der Geburt
eines Knaben günstiger.

Durch das Hineinziehen des Zufallsbegriffes wird in das
"`Gesetz der großen Zahlen"' noch ein neues Moment hineingetragen.
Kann die annähernde Konstanz einer relativen Häufigkeit an sich
das Symptom für das Wirken des Zufalls sein? Zu dieser Frage ist
folgendes zu bemerken. Die völlige Ausgleichung tritt, wie gesagt
wird, bei einer unendlich großen Anzahl von Fällen ein. Sehen
wir einmal davon ab, wieweit eine solche Behauptung begründet
ist, die sich nicht auf ein bestimmtes Tatsachenmaterial bezieht,
sondern auf ein über den Beobachtungen stehendes Ideal (die unendliche
Häufung der Fälle), so bleibt immer noch zu erwägen,
was eintritt, wenn die Anzahl der Fälle nicht unendlich groß
ist. Dabei stellt es sich aber heraus, daß gerade nicht die Konstanz
der relativen Häufigkeit, sondern vielmehr ihre Schwankungen
das Bezeichnende sind. Aus der Art dieser Schwankungen
bestimmen wir erst den Charakter des Zufälligen. Wir finden
konstante Verhältniszahlen, die ganz sicher nicht auf dem Wirken
eines Zufalls, sondern viel eher auf einer festen Unveränderlichkeit
der zugrundeliegenden Bedingungen beruhen. Das Spiel des Zufalls
gibt sich erst da kund, wo Schwankungen auftreten und das schließlich
herauskommende Verhältnis sicher nicht durch innerlich regulierende
Prinzipien, die es in bestimmten Grenzen halten, bestimmt
\DPPageSep{063}{49}
ist. Wenn wir eine Münze in die Luft werfen, so ist nicht in einer
für uns erkennbaren Weise von vornherein begründet, daß bei einer
großen Anzahl von Würfen beide Seiten der Münze gleich oft nach
oben zu liegen kommen.

Das Werfen einer Münze ist ein besonders einfaches Beispiel
eines Glücksspieles. Es scheint nun zweckmäßig, wenn es sich um
die allgemeine Erforschung der Eigenart der Ereignisse handelt,
bei denen die verschiedenen möglichen Ergebnisse sich in annähernd
gleichbleibendem Häufigkeitsverhältnis darbieten, falls
man die Anzahl der beobachteten Fälle groß genug wählt, dann
der Betrachtung als typische Ereignisse die Glücksspiele im allgemeinen
Sinne zugrunde zu legen, wozu man auch Lotterieziehungen
und ähnliches zu rechnen hat, weil bei den Glücksspielen
von vornherein die Art ihres Zustandekommens durchsichtig und
klar erscheint. Mit dieser Betrachtung der Glücksspiele haben
wir uns jetzt also etwas näher zu befassen.
\EndChap
\DPPageSep{064}{50}


\Chapter{Fünftes Kapitel}{Die Theorie der Glücksspiele}

Die Glücksspiele bedeuten Ereignisse, bei denen der Erfolg
auf keine Weise vorher zu bestimmen ist. Wenn ich mit einem
Würfel würfele, so kann ich vorher nicht wissen, welche Augenzahl
fällt. Ich kann auch aus den bei einer Reihe von Würfen
gefallenen Augenzahlen keinen Schluß darauf ziehen, welche Augenzahl
beim nächsten Wurf fällt. Alle einzelnen Würfe sind voneinander
unabhängig, keiner übt einen Einfluß auf den anderen
aus. Trotzdem soll sich ergeben, daß, wenn ich mit einem Würfel
eine große Anzahl Male würfele, die Anzahlen Male, die die verschiedenen
Augenzahlen gefallen sind, in einem bestimmten Verhältnis
zueinander stehen. Dieses Verhältnis ändert sich nur
unbedeutend, wenn ich den Versuch wiederhole, indem ich noch
einmal ebensooft mit demselben Würfel würfele. Wir haben
auf diese Weise ein typisches Beispiel konstruiert, in dem die angenäherte
Unveränderlichkeit bestimmter Verhältniszahlen erfüllt
ist. Dieses Beispiel gibt uns ein Mittel an die Hand, näher in
die Bedeutung der Unveränderlichkeit statistischer Verhältniszahlen
einzudringen. Für die Erkenntnis des inneren Grundes
dieser Unveränderlichkeit gewinnen wir allerdings zunächst nichts,
denn was daran rätselhaft ist, bleibt ebenso rätselhaft auch an
diesem besonderen Falle des wiederholten Würfelns. Die einzelnen
Würfe sind völlig unabhängig voneinander, so nehme ich
wenigstens an, und trotzdem sollen sie sich bei einer großen Anzahl
von Würfen in bestimmter Häufigkeit ergeben. Wie ist das
zu erklären? Wie kann ich zu der Überzeugung gelangen, daß
ich bei $600\,000$ Würfen ungefähr je $100\,000$\,mal die einzelnen
Augenzahlen werfe? Warum kann ich nicht ebensogut doppelt
so oft sechs Augen wie ein Auge werfen? Die einzelnen Würfe
können sich nicht untereinander regulieren, denn sie sind ja unabhängig
\DPPageSep{065}{51}
voneinander. Wenn ich schon hundertmal sechs Augen
geworfen habe, so hindert das nicht, daß ich auch noch das
nächste Mal sechs Augen werfe, aber fördert es auch nicht.

Die Unabhängigkeit der einzelnen Fälle bei solchen Zufallsereignissen
wie das Würfelspiel ist allerdings keineswegs unbestritten.
Schon \so{d'Alembert} hat ernste Zweifel über sie geäußert
\index{Alembert@d'Alembert|f}%
(Réflexions sur le calcul des probabilités, Opuscules math., vol.~2,
1761; Doutes et questions sur le calcul des probabilités, Mélanges
de litérature, d'histoire et de philosophie, vol.~5, 1770). Es ist
merkwürdig, daß dieser Mann, der einer der führenden Geister
der Aufklärung und ein ungemein scharfsinniger Kopf war, gerade
in solchem entscheidenden Punkte so völlig anderer Meinung
war, wie die meisten seiner Zeit- und Gesinnungsgenossen\DPtypo{}{.} Er
konnte sich nicht darein finden, daß, nachdem mit einem Würfel
mehreremal hintereinander sechs Augen geworfen sind, nun das
nächste Mal ebenso leicht sechs Augen sollen fallen können, als
ob das Spiel erst begänne. Er konnte sich anscheinend der Vorstellung
nicht verschließen, daß in dem natürlichen Geschehen
gewisse regulierende Prinzipien wirksam seien, die ein Übermaß
nach der einen oder anderen Seite hin verhüten. Die Schwierigkeit
liegt aber in der Vereinigung dieser Prinzipien mit den Grundsätzen,
auf denen wir sonst die Naturerklärung aufbauen. Wir
müssen, um ihre Möglichkeit einzusehen, entweder annehmen, daß
eine Macht wirksam ist, die über den Zwang des Kausalitätsprinzips
erhaben ist, oder daß dieses Kausalitätsprinzip doch nicht
allgemein gültig ist, daß es gewisse Ereignisse oder gewisse
Momente des Geschehens gibt, die ihm nicht unterliegen, mit anderen
Worten, daß es einen absoluten Zufall gibt, daß aber dieser
Zufall doch nicht blind ist, wie man zu sagen pflegt, sondern
daß er vielmehr in bestimmter Weise gelenkt oder geleitet wird.
Der Ausgleich, den wir bei Zufallsereignissen beobachten sollen,
beruht dann eben darauf, daß diese Ereignisse, die nicht dem
Kausalitätsgesetz unterliegen, auf eine bestimmte Verteilung der
Resultate hingelenkt werden, so daß sie wohl im einzelnen Falle
einen außergewöhnlichen Erfolg oder eine beklagenswerte Zerstörung
mit sich führen, in ihrer Gesamtheit aber den Lauf der
Welt nicht beeinflussen können. Eine derartige Theorie, nach
der das Kausalitätsgesetz zwar eine Lücke hat, aber diese Lücke
durch ein anderes regulierendes Prinzip ergänzt und so erst der
\DPPageSep{066}{52}
wirkliche Verlauf des Geschehens zustande kommt, kann sich
darauf berufen, daß das Kausalitätsprinzip doch auch nur eine
Hypothese und durch die Erfahrung keineswegs vollständig zu
begründen ist.

Der Verwendung, die \so{d'Alembert} von einer solchen Theorie
macht, um die Tatsache des Ausgleichs zu erklären, sind in
gewissem Sinne verwandt die Versuche, in der zeitlichen Anordnung
zufälliger Ereignisse eine bestimmte Regelmäßigkeit zu
finden. Das Gemeinsame ist bei beiden Erklärungen, daß sie die
von der klassischen Wahrscheinlichkeitsrechnung angenommene
Unabhängigkeit der einzelnen Zufallsereignisse leugnet. Man kennt
die seltsame Annahme einer "`Duplizität der Fälle"', daß jedes
außergewöhnliche Ereignis ein anderes von der gleichen Art, das
an sich ebenso ungewöhnlich ist, nach sich zieht. Diese Theorie,
für die jeder bereit sein wird, Belege aus seiner eigenen Erfahrung
beizubringen, ist nicht bloß auf die Mitteilung im persönlichen
Verkehr beschränkt geblieben, durch die sonst meistens
derartige Theorien fortgepflanzt werden, sie ist in einer etwas
anderen Form, die hauptsächlich die allgemeine Tatsache einer
Vergesellschaftung der Zufallsereignisse hervorkehrte, der wissenschaftlichen
Welt vorgelegt worden in der Studie von K.~\so{Marbe}
\index{Marbe}%
(Naturphilosophische Untersuchungen zur Wahrscheinlichkeitslehre,
Leipzig 1899). Die Behauptungen dieses Buches blieben
natürlich nicht ohne Widerspruch. Zunächst wandten sich \so{Brömse}
\index{Bromse@Brömse}%
und \so{Grimsehl} in der Zeitschrift für Philosophie 1901 (Bd.~118)
\index{Grimsehl}%
gegen die \so{Marbe}sche Theorie und ihre angebliche Begründung,
\so{Marbe} erwiderte darauf in der Vierteljahrsschrift für wissenschaftliche
Philosophie 1902, und darauf suchte noch einmal L.~v.~\DPtypo{\so{Borkewitsch}}{\so{Bortkewitsch}}
\index{Bortkewitsch@Bortkewitsch (Bortkiewicz), Lad.\ v.}%
in dem Aufsatz über Wahrscheinlichkeitslehre und Erfahrung
(Zeitschr.\ f.~Philosophie 1903, Bd.~121) nachzuweisen, daß
das von \so{Marbe} angeführte Tatsachenmaterial ebensogut auf der
Grundlage der klassischen Wahrscheinlichkeitsrechnung seine Erklärung
fände. Nach dieser ist ja bei dem bekannten Spiel der
geworfenen Münze, wo es sich darum handelt, ob beim Herunterfallen
Kopf oder Schrift oben liegt, eine genau alternierende Folge
von Kopf oder Schrift ebenso unwahrscheinlich, wie daß andauernd
nur Kopf oder nur Schrift fällt. Es ist also auch hiernach zu erwarten,
daß derselbe Erfolg häufiger mehreremal hintereinander
eintritt, daß sich also eine gewisse "`Knäuelung"' zeigt.
\DPPageSep{067}{53}

Außerdem muß hinzugefügt werden, daß es bei den hier in
Betracht kommenden Ereignissen oft schwer ist, zu sagen, inwiefern
nicht systematische Ursachen mitspielen. Es ist bekannt,
daß man beim Schießen nach einer Scheibe leicht mehrere Treffer
hintereinander bekommt, weil die unbewußten physiologischen
Vorgänge beim Zielen nahezu gleich ablaufen können, wenn
die Aufmerksamkeit auf einen bestimmten Punkt konzentriert
ist, ferner ist ebenso bekannt, daß jemand leichter einen Laden
betritt, wenn er vor sich einen anderen hineingehen sieht, als
wenn er selbst der erste ist. Alles das macht eine objektive
Wertung des Beobachtungsmaterials außerordentlich schwierig.
Jedenfalls ist es meines Erachtens verfrüht, an solche Beobachtungen
eine radikale Kritik der gesamten Wahrscheinlichkeitslehre
anzuknüpfen, wie es neuerdings O.~\so{Sterzinger} (Zur
\index{Sterzinger}%
Logik und Naturphilosophie der Wahrscheinlichkeitslehre, Leipzig
1911) getan hat. Es mag aber vielleicht gut sein, zu bemerken,
daß die uns hier vorliegende Aufgabe von dem Phänomen der
Knäuelung, ob es nun vorhanden ist oder nicht, unberührt bleibt.
Unsere Betrachtungen knüpfen nur an die Durchschnittswerte
an, die sich bei großen Anzahlen von Einzelfällen herausstellen,
nicht aber an die Gruppierung der Einzelergebnisse, die auf den
Durchschnittswert ohne Einfluß bleibt. Es fand auch \so{Sterzinger}
bei seinen Feststellungen an geworfenen Münzen für die Gesamtzahlen
der beiden möglichen Fälle die Verhältnisse $626:606$ und
$1203:1245$, was dem theoretischen Wert~$1:1$ so nahe kommt,
wie es nach der Theorie zu erwarten ist. Wir benutzen demnach
hier die Glücksspiele nur, um die sich bei ihnen ergebenden
statistischen Ergebnisse mit den bei anderen Ereignissen gewonnenen
zu vergleichen. Wenn wir auch nicht unmittelbar auf
eine innere Gleichartigkeit aus der äußeren Übereinstimmung der
statistischen Ergebnisse schließen dürfen, so gewinnen wir doch
ein Bild davon, wie solche Ergebnisse zustande kommen können.

Diese Verwendung der Glücksspiele ist nicht sicher vor Einwendungen,
die dagegen von vornherein erhoben werden können.
Die Zufallsspiele, auch die Ziehungen aus einer Urne, erscheinen
so belanglos und geringwertig, daß sie mit den Vorgängen in der
Natur und in der menschlichen Gesellschaft nicht verglichen
werden \so{dürfen}. "`Welcher blasphemische Gedanke, den Begriff
des Zufallsspieles auf die Allmutter Natur anzuwenden!"' ruft
\DPPageSep{068}{54}
L.~\so{Goldschmidt} (Die Wahrscheinlichkeitsrechnung, Versuch einer
\index{Goldschmidt}%
Kritik, Hamburg 1897) aus. Das ist wohl mehr tief empfunden
als tief gedacht. Eine Blasphemie gibt es nicht, wenn wir bestimmten,
ernsthaften Forschungsgrundsätzen treu bleiben.

Das Zufallsspiel ist uns ebensoviel wert wie die Vorgänge in
der belebten und unbelebten Natur, wenn es unsere Erkenntnis
in einem wesentlichen Punkte fördert. Im übrigen ist der Vergleich
der Glücksspiele mit den Ereignissen im menschlichen Leben
so uralt, daß er geradezu trivial geworden ist. Schon in dem
lateinischen Worte sors (Los) für Schicksal findet er seinen deutlichen
Ausdruck. Das Wort erklärt sich wohl daraus, daß das
Ziehen eines Loses als Orakel benutzt wurde und man das Ergebnis
eines Orakels unmittelbar zur Bezeichnung des wirklichen
Ausganges benutzte. In diesem Sinne aber bedeutet der Vergleich
mit dem Ziehen des Loses keineswegs die Annahme, daß die Ereignisse
des menschlichen Lebens auf einem bloßen Zufall beruhen,
im Gegenteil lag bei den Römern sicher die Vorstellung zugrunde,
daß dieselbe Macht, die die Wechselfälle des menschlichen Lebens
unausweichlich bestimmt, sich auch in der Ziehung des Loses
offenbart, daß ein innerlicher Zusammenhang zwischen dem Ergebnis
der symbolischen Handlung und dem konkreten Ausgang,
der vorausbestimmt werden sollte, bestehe.

Damit fiel für diese Auffassung die Schwierigkeit weg, die
für uns am Anfang steht: wie weit sich das schematische Bild
der Glücksspiele auf die damit verglichenen Ereignisse übertragen
lasse. Auf den inneren Mechanismus des Geschehens werden wir
nur dann einen Schluß ziehen können, wenn wir uns überzeugt
haben, daß die verglichenen Vorgänge wirklich in ihren Einzelheiten
gleichartig sind. Das wäre \zB~bei dem Vergleich des
Geschlechtsverhältnisses mit den Ergebnissen der Ziehungen aus
einer Urne der Fall, wenn die Entscheidung über das Geschlecht
eines geborenen Kindes dadurch getroffen wird, daß von männlichen
und weiblichen Keimzellen durch den Vorgang der Befruchtung
ebenso blindlings eine herausgegriffen wird, wie bei der
Ziehung aus einer Urne, in der schwarze und weiße Kugeln gemischt
enthalten sind, blindlings eine Kugel herausgenommen wird.
Eine solche Vergleichung der beiden Vorgänge in ihrer ganzen
Besonderheit ist nun aber in den seltensten Fällen möglich. Deshalb
sind wir in der Tat auf den anderen Ausweg angewiesen,
\DPPageSep{069}{55}
nur den äußeren Erfolg zu vergleichen und aus seiner Gleichartigkeit
auch auf eine gewisse Gleichartigkeit des inneren Vorganges
zu schließen. Dieser Schluß bleibt allerdings ein kühner
und zweifelhafter, doch hat er immerhin eine gewisse Berechtigung.

Worin besteht nun bei den Glücksspielen der äußere Erfolg?
Das erste, was sich hierbei heraushebt, ist der bei Glücksspielen
in der Tat beobachtete Ausgleich der Chancen bei häufiger Wiederholung
des Spieles. Dieser Ausgleich hat zur Folge, daß, wenn
die Einsätze nicht genau den Chancen der Spieler entsprechend
festgesetzt sind, sondern etwas mehr betragen, der den Gegenpart
haltenden Bank mit großer Sicherheit ein mit der Zahl der Spiele
steigender Gewinn zufällt. Darauf beruhen alle Spielbanken, und
man wird eine Kapitalanlage in der Bank von Monte Carlo trotz
der hohen Summen, die dort täglich auf dem Spiele stehen, für
ebenso sicher halten wie irgend ein Staatspapier oder eine Grundschuld.
An der Tatsache des Ausgleichs, mit anderen Worten,
an der Tatsache, daß nach einer sehr großen Anzahl von Spielen
Gewinn und Verlust ziemlich genau den Spielchancen entsprechen,
besteht also wohl kein Zweifel. Es fragt sich nur, ob sich für
diese Tatsache eine Erklärung finden läßt.

Der erste und einfachste Versuch einer solchen Erklärung
trifft nun von vornherein nicht bloß die Glücksspiele, sondern
alle Ereignisse, die mit den Glücksspielen das Gemeinsame haben,
daß sie eines verschiedenen Erfolges fähig sind, und bei denen
man auf keinerlei Weise vorher bestimmen kann, welcher Art der
Erfolg sein wird. Als derartige Erklärungsversuche sind die im
vorigen Kapitel erörterten Begründungen für das "`Gesetz der
großen Zahlen"' zu verstehen. Dieses Gesetz bedeutet ja die annähernde
Konstanz von Verhältniszahlen, die bei statistischen Erhebungen
auftreten. Auch das Aufzeichnen der Ziehungsresultate
bei der Urne müssen wir als eine statistische Erhebung betrachten.

Als bedenklich erschien uns aber die Erklärung, die \so{Laplace}
\index{Laplace}%
und \so{Poisson} und mit ihnen viele andere für die Konstanz
\index{Poisson}%
der Verhältniszahlen gegeben haben. Was sollen wir unter der
Entfaltung der Möglichkeiten verstehen, auf die sich \so{Laplace}
beruft? Wenn er meint, daß er durch seine Erklärung das äußere
Wirken der Vorsehung beseitigt hat, so hat er eine innere Wirkung
eingeführt, die nicht minder rätselhaft ist, nämlich die Entwickelung
bestimmter Anlagen durch die Wirklichkeit, wobei durch
\DPPageSep{070}{56}
innere regulierende Prinzipien dafür gesorgt ist, daß die vorhandenen
Anlagen beständig in der gleichen Weise heraustreten.
Es ist eine Theorie der objektiven Möglichkeit, die auf diese Weise
gegeben wird.

Der Begriff der Möglichkeit bedeutet ja in der Tat eine solche
vorausbestehende Anlage künftiger Ereignisse, deren Eintreten
nicht gewiß ist, die wir aber in den bestehenden Umständen in
gewisser Weise vorgebildet finden. Unser ganzes Leben zwingt uns
dazu, mit solchen Möglichkeiten zu rechnen, fortwährend Umstände
ins Auge zu fassen, mit denen wir den Gedanken eines bestimmten
künftigen Geschehens verbinden müssen, ohne deshalb sicher zu
sein, daß das, was wir als möglich voraussehen, wirklich eintreten
wird. So gefaßt, erscheint die Möglichkeit nur in subjektiver Bedeutung.
Daraus eine objektive Möglichkeit abzuleiten, liegt nahe,
ist aber nicht ohne Bedenken. Nach der Auffassung der modernen
Naturwissenschaft liegt die ganze Zukunft in der Vergangenheit
und Gegenwart als notwendig begründet. Der Verlauf des Geschehens
wickelt sich nach dem Kausalgesetz so ab, daß, was in
jedem Augenblick geschieht, mit Notwendigkeit geschehen muß.
Bei \so{Aristoteles} (vgl.\ insbesondere De interpretatione, Cap.~X) ist
\index{Aristoteles}%
diese Auffassung nicht vorhanden. Nach ihm braucht von zwei
entgegengesetzten Behauptungen über Zukünftiges nicht notwendigerweise
die eine falsch und die andere richtig zu sein, die
Sache selbst ist noch unentschieden und beide Behauptungen
können als problematische, als Möglichkeitsurteile, auch in objektivem
Sinne gelten. \so{Ueberweg} sucht in seiner Logik den aristotelischen
\index{Ueberweg}%
Gedanken mit der modernen Auffassung in Übereinstimmung
zu bringen, indem er sagt, "`daß unter den Momenten,
von denen die Verwirklichung abhängt, nicht bloß subjektiv durch
unser Wissen und Nichtwissen, sondern auch objektiv durch die
Natur der Sache eine wesentliche Scheidung begründet ist. Die
Gesamtheit dieser Umstände zerlegt sich in den (inneren) Grund
und die (äußeren) Bedingungen. Wo nur eines davon gegeben ist,
besteht eine reale oder objektive Möglichkeit, wo beides zusammen,
eine reale oder objektive Notwendigkeit. In der Eichel liegt in
diesem Sinne die objektive oder reale Möglichkeit der Entstehung
eines Eichbaumes."' Diese Begriffsbildung verdankt wohl hauptsächlich
der Verlegenheit des Philosophen ihren Ursprung, der sich
von dem Einfluß des großen Begründers seiner Wissenschaft nicht
\DPPageSep{071}{57}
losmachen kann und doch dem Standpunkt der modernen Forschung
Rechnung tragen soll. Wenn wir den Komplex aller Ursachen teilen
und sagen: ein Teil der Ursachen begründet keine Notwendigkeit,
so bedeutet das doch keine reale oder objektive Möglichkeit,
auch wenn die Teilung der Ursachen sich noch so natürlich ergibt.
Auch \so{Trendelenburg} sagt in seinen Logischen Untersuchungen:
\index{Trendelenburg}%
"`Aus dem Samen kann ein Baum, aus dem Ei ein Tier werden.
Es ist kein leeres Spiel des Gedankens. Die Möglichkeit liegt
gleichsam sinnlich vor Augen."' In dieser Formulierung ist verhüllt,
ob der bestimmte Artikel (\so{der} Same, \so{das} Ei) kollektiv gemeint
ist oder sich auf einen bestimmten Gegenstand bezieht. In
dem ersten Falle heißt die Behauptung nur: aus einigen Samenkörnern
werden Bäume, aus einigen Eiern Tiere, und das bedeutet
nicht im eigentlichen Sinne ein Möglichkeitsurteil. Das Wort
"`möglich"' bedeutet dann nur, wie F.~A.~\so{Lange} mit Recht bemerkt,
\index{Lange@Lange, Friedr.\ Albert}%
eine sprachliche Ausdrucksweise. Sprechen wir dagegen von einem
bestimmten Samenkorn, das wir in die Erde gelegt haben, und
sagen: es ist möglich, daß aus \so{diesem} Samenkorn ein Baum emporwächst,
so wenden wir die gemachte allgemeine Erfahrung auf
einen Fall an, von dem wir nicht wissen, wie er ausgehen wird.
Das Urteil ist ein subjektives, weil wir sicherlich nicht sagen
können, es sei auch in der Wirklichkeit unentschieden, ob aus dem
Samen ein Baum wird oder nicht, aber es ist doch objektiv begründet,
weil wir zu diesem Urteil auf Grund bestimmter realer
Erfahrungen gelangen.

Wir empfinden aber bei einem solchen Möglichkeitsurteil das
Bedürfnis, die Möglichkeit auch graduell zu werten. Schon \so{Laurentius
Valla} hebt hervor, daß jede Möglichkeit als eine nach bestimmten
\index{Valla, Laurentius}%
Graden abgestufte Wahrscheinlichkeit zu betrachten sei. Diese
Abstufung des Möglichkeitsurteiles ist auf zwei grundverschiedenen
Wegen zu erreichen. Der eine Weg ist der, daß wir wissen, wie
oft in einer größeren Anzahl von beobachteten Fällen der Erfolg,
den wir als möglich ins Auge fassen, unter den beobachteten Bedingungen
eingetreten ist. Dieses Verfahren ist die \so{statistische
Methode}. Wir werten unsere Erwartung nach dem Prozentsatz
der Fälle, in denen der Erfolg bereits unter den festgestellten Bedingungen
eingetreten ist. Wir können aber auch davon ausgehen,
wieviele von den Bedingungen, die wir als notwendig für das Eintreten
des Erfolges erkannt haben, sich wirklich feststellen lassen.
\DPPageSep{072}{58}
Je mehr von ihnen erfüllt sind, mit um so größerer Sicherheit
können wir auf den in Rede stehenden Erfolg rechnen. Dieses
Verfahren nennen wir die \so{genetische Methode}. Es ist aber
schwer zu sehen, wie wir hierbei zu einer zahlenmäßigen Festlegung
gelangen können, denn alle die günstigen Momente, die wir konstatieren,
sind doch in den seltensten Fällen unmittelbar quantitativ
zu werten, während bei der statistischen Methode die beobachtete
relative Häufigkeit unmittelbar einen Anhaltspunkt für die quantitative
Wertung des Möglichkeitsurteiles liefert.

Deshalb erscheint auch bei den Glücksspielen zunächst der
aussichtsreichere Weg nicht die genetische, sondern die statistische
Methode. Es handelt sich dabei allerdings nicht darum, bestimmte
relative Häufigkeiten zu beobachten und dann zur Grundlage des
Spieles in künftigen Fällen zu machen, sondern man kann sich
mit der Tatsache begnügen, daß sich in gewissen Grenzen eine
bestimmte Häufigkeitszahl und damit auch eine bestimmte Wertung
der Erwartung ergibt. Trotzdem ist es gerade die genetische
Methode gewesen, die sich bei den Glücksspielen zunächst durchgesetzt
hat. Sie hat der an die Glücksspiele anknüpfenden Theorie
ihren eigentümlichen Charakter gegeben, hat aber dann später zu
weitläufigen Erörterungen geführt, die die mehr und mehr auftauchenden
methodischen Bedenken betrafen. Fast alle diese Erörterungen
konzentrierten sich auf die Frage, wann wir auf Grund
der genetischen Methode zwei verschiedene Möglichkeiten als gleich
anzusehen haben. Diese Fragestellung ist recht zu verstehen nur,
wenn wir die geschichtliche Entwickelung, welche die Theorie
genommen hat, ins Auge fassen. Diese Entwickelung ist Schritt
für Schritt mit innerer Notwendigkeit weiter gegangen, aber die
Schwierigkeiten haben sich bei ihr immer mehr gehäuft, bis die
neueste Zeit den Knoten durchhauen und sich von dem Ballast der
Überlieferung einigermaßen frei gemacht hat. Den Ausgangspunkt
bildete die Berechnung der Spielchancen beim Würfelspiel oder der
Spieleinsätze, die den Spielchancen proportional sein müssen. Hierfür
hatte sich schon \so{Cardano}~($\dagger$\,1576), der ein leidenschaftlicher
\index{Cardano}%
Spieler war, lebhaft interessiert und eine Schrift De ludo aleae
verfaßt. Zu einer mathematischen Disziplin erhob diese Betrachtungen
aber erst \so{Galilei} (Considerazioni sopra il giuoco dei dadi,
\index{Galilei@Galilei|f}%
Opere Vol.~3, Florenz 1718). Daß mit drei Würfeln viel häufiger
zehn Augen als drei Augen geworfen werden, war bekannt. Wie
\DPPageSep{073}{59}
sich diese Tatsache aber zu einer quantitativen Bestimmung verdichten
ließe, war völlig unbekannt. Da faßte \so{Galilei} die Aufgabe
so an, daß er die verschiedenen Fälle trennte, in denen eine
bestimmte Augenzahl zustande kommt. Als einzelner Fall hat das
Werfen einer bestimmten Augenzahl mit dem ersten, mit dem
zweiten und mit dem dritten Würfel zu gelten. Zählt man diese
Fälle ab, so ergeben sich im ganzen $216$. Davon ist nur in einem
Falle die Augenzahl drei, dagegen in $27$ Fällen die Augenzahl zehn.
So hat das Fortschreiten von einer qualitativen Aussage zu einer
quantitativen Bestimmung, das überhaupt das entscheidende Moment
an der Entwickelung aller exakten Wissenschaft bildet, auch den
Ursprung der Wahrscheinlichkeitsrechnung ausgemacht. Die Zählung
der verschiedenen Fälle beim Würfelspiel ist aber nur von
Bedeutung, wenn mit den einzelnen Fällen eine gleiche Wertung verknüpft
werden kann. Das natürliche Gefühl stimmt dieser Annahme
sofort zu. Eine exakte wissenschaftliche Begründung dafür zu
finden, ist hingegen recht schwer und hat später viel Kopfzerbrechen
verursacht. \so{Galilei} ging davon aus, daß man ohne weitere Begründung
die Chancen, mit einem Würfel die eine oder andere
Augenzahl zu werfen, als gleich ansehen und deshalb diese sechs
verschiedenen Möglichkeiten gleich werten kann. Es fragt sich
dann nur, ob daraus folgt, daß auch die Chancen, bei dreimaligem
Werfen mit einem Würfel hintereinander oder mit drei Würfeln
zugleich eine bestimmte Augenzahl zu werfen, bei jedem Wurf
oder für jeden Würfel einander gleich sind. Das ist nun offenbar
der Fall, denn man braucht ja nur anzunehmen, daß jeder der
Spieler hintereinander auf das Werfen einer bestimmten Augenzahl
mit jedem einzelnen Würfel setzt, also drei Spiele zugleich
macht. Nehmen wir an, der Gewinn, den er erhoffen kann, betrage
$216$ Dukaten, dann setze er beim ersten Wurf einen Dukaten. Gewinnt
er, so hat er sechs Dukaten. Diese sechs Dukaten setzt er
wieder beim zweiten Wurf. Gewinnt er, so hat er $36$ Dukaten.
Diese $36$ Dukaten setzt er beim dritten Wurf aufs neue, um
$216$ Dukaten zu gewinnen. Er hat also für $216$ einen Dukaten
einzusetzen, und das unabhängig von den Augenzahlen, auf die er
bei den einzelnen Würfen oder Würfeln setzt. Setzt er nun nicht
auf bestimmte Augenzahlen bei den einzelnen Würfen, sondern
auf eine bestimmte Gesamtaugenzahl, so bedeutet das, daß er
mehrere der soeben betrachteten Spiele zugleich macht, nämlich so
\DPPageSep{074}{60}
viel, auf wieviel Arten sich durch bestimmte Augenzahlen bei den
einzelnen Würfen die fragliche Gesamtaugenzahl erreichen läßt,
das wäre also $27$, wenn die Gesamtaugenzahl zehn beträgt.

In dieser einfachen Betrachtung liegt der Kern der ganzen
Wahrscheinlichkeitsrechnung enthalten. Zugrunde gelegt wird
eine Annahme gleicher Spielchancen, die nicht weiter begründet
wird und auch nicht weiter begründet werden kann, sondern nur
nach bestimmten Überlegungen oder aus einem gewissen Gefühl
heraus plausibel scheint. Wenn diese Annahme einmal gemacht
ist, so werden daraus andere, im allgemeinen ungleiche Spielchancen
durch bestimmte Rechnungen auf Grund eines sicheren Verfahrens
abgeleitet. Es erwies sich hierbei als zweckmäßig, die Spielchancen
allgemein als Verhältnis von Einsatz und Gewinn, \dh~weil der
Einsatz immer kleiner als der Gewinn ist, als einen bestimmten
echten Bruch zu bestimmen. So geschieht es \zB~bei \so{Huygens}.
\index{Huygens}%
Dieser Bruch heißt die mathematische \so{Wahrscheinlichkeit}, und
nach ihr ist die ganze Rechnung genannt.

Dieser Begriff der mathematischen Wahrscheinlichkeit hat
sich im Laufe der Zeit nun weiter entwickelt. Die ursprüngliche
Festlegung als Verhältnis von Einsatz und Gewinn bringt ihn
noch mit einem fremden Element in Beziehung, nämlich einem
Geldbetrag, der sich aus dem Bruch doch wieder forthebt. Von
diesem fremden Element war der Begriff zu befreien und es zeigte
sich dabei, daß man nur die Frage aufzuwerfen hatte, wie man
das Spiel auf Spielchancen, die alle untereinander gleich sind,
aufbauen kann. So viel solcher gleicher Spielchancen man nimmt,
der so vielte Teil des Gewinnes ist auf jede einzelne Chance zu
setzen, und vereinigt ein Spieler mehrere dieser Chancen auf seine
Person, so wird für ihn die Wahrscheinlichkeit des Gewinnens
das entsprechende Vielfache des Bruches, der einer einzigen Chance
entspricht. Sind nun die Spielchancen gleich groß, so spricht man
von gleich möglichen Fällen des Gewinnens. Die mathematische
Wahrscheinlichkeit wird damit ein Bruch, dessen Nenner die Anzahl
aller der gleich möglichen Fälle und dessen Zähler die Anzahl
der hierunter dem Spieler günstigen Fälle ist. Mit dieser
Festlegung ist die Möglichkeit gegeben, die Definition der Wahrscheinlichkeit
über die Glücksspiele hinaus auf solche Ereignisse
im allgemeinen zu übertragen, die sich nach Analogie der Glücksspiele
beurteilen lassen und die generell als Zufallsereignisse
\DPPageSep{075}{61}
bezeichnet werden. Es wird derart die Beurteilung aller solcher
Ereignisse an die Scheidung gleich möglicher Fälle geknüpft. In
diesem Sinne sagt \zB~\so{Laplace}: "`La théorie des hasards consiste
\index{Laplace}%
à réduire tous les évènements du même genre à un certain nombre
de cas également possibles, c'est-à-dire tels que nous soyons
également indécis sur leur existence."' Die letzten Worte geben
schon an, wie in der klassischen Wahrscheinlichkeitsrechnung
immer die gleich möglichen Fälle festgelegt werden. Zwei Fälle
sollen als gleich möglich angesehen werden, wenn sich kein Grund
findet, unter ihnen einen für wahrscheinlicher zu halten als den
anderen. J.~v.~\so{Kries} (Die Prinzipien der Wahrscheinlichkeitsrechnung,
\index{Kries@Kries, Joh.\ v.}%
Freiburg 1886) hat mit Recht darauf hingewiesen,
daß diese Bestimmung zwar eine notwendige, aber die so gegebene
Erklärung keineswegs eine genügende sei, denn sie läßt noch der
Willkür einen großen Spielraum. Die Aufstellung der gleich möglichen
Fälle müsse aber eine in eindeutiger Weise und ohne jede
Willkür sich ergebende sein. Er findet die Aufstellung gleichberechtigter
Annahme überall da möglich, wo unserem Wissen
gemäß ein meßbarer und in Teile zu zerlegender Spielraum des
Verhaltens möglich ist. Gleichen Teilen des Spielraumes entsprechen
auch gleiche Möglichkeiten. Ich kann nicht finden, daß
die Schwierigkeit dadurch gehoben ist. Es ist nur ein besonderes
Bild für die Vorgänge geschaffen, das wohl sehr anschaulich ist
(wir müssen etwa an die Felder auf der Scheibe der Roulette
denken), aber doch nichts erklärt. \so{Kries} hat eine Art Stoßspiel
ersonnen, das wohl in der Art, wie er es verwendet, die Annahme
gleicher Möglichkeiten als berechtigt erscheinen läßt, an dem sich
aber auch zeigen läßt, daß allein das Vorhandensein eines meßbaren
und bestimmt teilbaren Spielraumes nicht ausreicht. Stoße
ich eine Kugel in einer Rinne vorwärts, die in gleich breite, abwechselnd
rote und schwarze Felder geteilt ist, so scheint es in
der Tat gleich möglich, daß die Kugel auf einem roten oder einem
schwarzen Felde liegen bleibt, aber doch wieder nur aus dem
Grunde, weil wir nicht einsehen können, warum sie eher auf einem
schwarzen als auf einem roten Felde liegen bleiben solle, wenn
die Breite der Felder gegen den Weg, den die Kugel zurücklegt,
sehr groß ist. Ist das aber nicht der Fall, folgt vielmehr auf ein
sehr breites schwarzes Feld ein ebenso breites rotes, so können wir,
wenn die Kugel nur mit schwacher Kraft gestoßen wird, nicht
\DPPageSep{076}{62}
mehr annehmen, daß sie ebenso leicht auf dem ferneren roten wie
auf dem näheren schwarzen Felde liegen bleiben wird.

Um diesen Schwierigkeiten zu entgehen, hat schon F.~A. \so{Lange}
\index{Lange@Lange, Friedr.\ Albert|f}%
in seinen Logischen Studien den Weg gewiesen, die Scheidung
der gleich möglichen Fälle nur als eine logische Disjunktion anzusehen.
Im logischen Sinne, \dh~als getreues Bekenntnis unseres
geistigen Zustandes, kann die Bestimmung der gleich möglichen
Fälle als solcher Fälle, von denen wir keinen eher als den anderen
annehmen können, auf jeden Fall bestehen bleiben. Es ist nur
meines Erachtens zu sehr betont worden, daß hierin wesentlich
das Bekenntnis eines Nichtwissens liegt. In einem neueren Werke
(S.~\so{Lourié}, Die Prinzipien der Wahrscheinlichkeitsrechnung,
\index{Lourié}%
Tübingen 1910) wird die Wahrscheinlichkeitsrechnung geradezu
als die Methodisierung des Nichtwissens behandelt. Wenn wir die
negative Redewendung gebrauchen, daß wir keinen Grund haben,
einen Fall für wahrscheinlicher zu halten als den anderen, so bedeutet
das doch eine bestimmte Summe positiver Kenntnisse von
der Natur des Vorganges, wie wir sie bei den Glücksspielen, den
Lotterieziehungen und anderen Ereignissen mehr haben. Die
Lotterieziehungen haben eine bestimmte Technik, die es verhindert,
die Ziehung eines Loses als wahrscheinlicher erscheinen zu lassen
wie die eines anderen. Die Einrichtung der Roulette, die Art des
Würfelns, die Vorsichtsmaßregeln beim Ziehenlassen einer Karte,
alles das sind bestimmte technische Momente, die gewissen Erfahrungen
und einer Einsicht in die innere Natur der Vorgänge
ihren Ursprung verdanken. Es lassen sich nur die einzelnen Bestandteile
dieser Erfahrungen und Erkenntnisse schwer in Worte
fassen, sie werden meist mehr gefühlsmäßig hingenommen.

Die eigentliche Schwierigkeit ist in der Darstellung, die
F.~A.~\so{Lange} gegeben hat, in eigentümlicher Weise verhüllt. Im
Grunde nähert sich seine Auffassung stark der statistischen
Methode. Er benutzt eine Art graphischer Darstellung, indem er
den gesamten Umfang des Begriffes durch ein Rechteck und die
Disjunktion durch eine Teilung dieses Rechteckes in kongruente
Teile darstellt. Diese Einteilung soll so verstanden werden, "`daß
die verschiedene Ausdehnung der Felder die Bedeutung hat, daß
der Umfang der untergeordneten Begriffe im Verhältnis dieser
Ausdehnung verschieden ist oder, was dasselbe sagen will, daß die
Häufigkeit, mit welcher man einen Fall der einen Klasse erwarten
\DPPageSep{077}{63}
darf, sich zu derjenigen einer anderen Klasse verhält wie die Ausdehnung
der betreffenden Felder"'. Die Schwierigkeit ist in dem
Ausdruck "`erwarten darf"' versteckt. Was heißt dürfen? Aus
inneren Gründen oder nach den äußeren Ergebnissen? Zu vermuten
ist, daß beides zugleich gemeint sein soll, in dem Sinne,
daß die aus inneren Gründen erwartete relative Häufigkeit sich
auch wirklich einstellen wird, und daß andererseits die einmal
beobachtete relative Häufigkeit sich immer wiederfinden wird. Darin
liegt aber schon alles, was überhaupt erörtert werden soll. Es
scheint klar, daß hiernach nicht das disjunktive Urteil in seiner
Allgemeinheit, sondern nur in den besonderen Fällen, wo eine
quantitative Wertung der Disjunktionsglieder möglich ist, gemeint
sein soll. Dem widerspricht aber, daß \so{Lange} als Beispiel ein
Urteil wie "`Ein Mensch kann entweder Europäer oder Asiate oder
Afrikaner oder Amerikaner oder Australier sein"' anführt. Er will
hieran erklären, daß eine weitergehende Disjunktion die ursprüngliche
nicht aufhebt, sondern nur ergänzt, indem die durch die
erste Disjunktion geschaffenen Spielräume nur noch weiter eingeteilt
werden. Wie soll aber in einem solchen Falle der Umfang
der einzelnen Spielräume bemessen werden? Dieser Fall hat doch
mit der quantitativen Wertung der Wahrscheinlichkeitsrechnung
nicht das mindeste zu tun. Es müßte denn die Bemessung der
Möglichkeiten nach den Einwohnerzahlen der verschiedenen Erdteile
getroffen werden, aber es ist offenbar sinnlos, zu schließen,
wenn ich einen unbekannten Menschen treffe, sei die Wahrscheinlichkeit,
daß er aus Asien stamme, ungefähr~$\frac{1}{2}$, weil die Einwohnerzahl
Asiens ungefähr die Hälfte von der Einwohnerzahl
der Erde ausmache. Das meint \so{Lange} offenbar auch nicht, im
Gegenteil scheint in den Worten, die er bei dem Beispiel des
Würfels gebraucht, "`der Umfang komme durch eine Zeitfolge
zustande, welche als räumliche Ausdehnung angeschaut wird"', zu
liegen, daß er sich wesentlich auf das Gesetz der großen Zahlen
stützen will. Die Annahme, daß der Umfang für die sechs Seiten
des Würfels gleich sei, habe nur als eine vorläufige zu gelten, die
durch die spätere Beobachtung entsprechend zu korrigieren sei.

Entschiedener als Lange hat \so{Stumpf} in den Sitzungsberichten
\index{Stumpf}%
der historischen Klasse der Münchener Akademie (1892,
S.~37~ff.)\ den subjektiven Charakter des Wahrscheinlichkeitsbegriffes
betont. Seine Auffassung findet sich in \so{Sigwart}s Logik
\index{Sigwart|f}%
\DPPageSep{078}{64}
(4.~Aufl.,\ II.~Bd., S.~317~ff.)\ wieder. Es werden hier die Glieder der
Disjunktion insofern gleichwertig genannt, "`als sie für unsere
Kenntnis gleiche Spezialisierungen eines Allgemeinen oder gleiche
Teile seines Gesamtumfanges darstellen"'. Damit ist im Grunde
doch wieder alles hereingenommen, was der Begründung der Wahrscheinlichkeit
auch in der klassischen Theorie zugrunde gelegt
wurde. Dem entspricht es durchaus, wenn \so{Sigwart} weiter sagt:
"`Das Recht, die Methoden der Wahrscheinlichkeitsrechnung anzuwenden,
ist nicht auf die Fälle beschränkt, in denen wir befugt
sind, Voraussetzungen über eine gleichmäßige Variabilität der
Ursachen zu machen und zu glauben, daß bei zahlreichen Wiederholungen
alle Disjunktionsglieder sich in gleichem Verhältnis verwirklichen
werden; es gilt überall, wo eine Disjunktion mit gleichwertigen
Gliedern feststeht und wir keinen Grund haben, das eine
eher als das andere anzunehmen."' Es ist zu bedauern, daß in
diesen Darstellungen die wirkliche Anwendung der Wahrscheinlichkeitsrechnung
nie berücksichtigt, sondern immer nur mit allgemein
begrifflichen Festsetzungen operiert wird. Dadurch tritt
nie klar hervor, wie weit denn die tatsächliche Anwendbarkeit der
entwickelten Begriffe geht. Die Wahrscheinlichkeit, daß ein vorliegender
chemisch einfacher Körper Eisen ist, gleich $1/n$ zu setzen,
wenn $n$ die Anzahl der Elemente ist, ist eine leere Spielerei. Das
Auftreten verschiedener Elemente kann nie als gleich wahrscheinlich
angesehen werden, schon weil es sehr verbreitete Elemente
und sehr seltene Elemente gibt. Die Schwierigkeit liegt eben darin,
daß fast immer wirklich ein Grund vorliegt, eher das eine als
das andere anzunehmen, und daß es dann gilt, die Verschiedenheit
der Erwartung richtig zu bewerten. Wenn wir wissen, daß eine
Knabengeburt eher als eine Mädchengeburt zu erwarten ist, so
sollen wir das Verhältnis dieser Erwartungen zahlmäßig bestimmen.
Durch die Zurückführung auf das Schema der gleichmöglichen Fälle
ist das nicht zu erreichen. Wie sollen wir es dann tun? Es gibt
nur einen Weg, und das ist die statistische Methode. Der Einwand
\so{Sigwart}s, daß wir die zu berechnende Wahrscheinlichkeit so
nicht genau finden, ist nicht stichhaltig. Ist es denn als eine
absolut genaue Bestimmung anzusehen, wenn wir beim Würfelspiel
die Wahrscheinlichkeiten für die einzelnen Augenzahlen gleich
$\frac{1}{6}$ setzen, weil wir keinen Grund einsehen, sie für verschieden
zu halten? Wir müssen die Unsicherheit unserer Annahme doch
\DPPageSep{079}{65}
irgendwie in Rechnung ziehen und müssen danach die angesetzten
Zahlen verschieden werten, auch wenn wir davon ausgehen, daß
die Wahrscheinlichkeit nur eine subjektive Bedeutung hat. Dies
läßt sich nur erreichen, indem wir sagen, wir müssen bei der Bestimmung
der Zahlen ihnen einen bestimmten Spielraum geben,
der unserer Unsicherheit entspricht. Ob wir beim Würfeln die
Wahrscheinlichkeit des einzelnen Wurfes gleich $\frac{1}{6}$ oder nur wenig
davon verschieden, vielleicht gleich $0,17$ ansetzen, wird bei der
Unsicherheit der Bestimmung ohne Bedeutung sein.

Welche Bedeutung überhaupt die Feststellung der Wahrscheinlichkeit
als das Maß der subjektiven Erwartung haben soll,
scheint mir schwer einzusehen. Eine solche Bedeutung würde
vorhanden sein, wenn es in allen oder wenigstens in vielen Fällen
gelänge, das Maß der subjektiven Erwartung zahlenmäßig zu werten.
Das ist aber offenbar nicht der Fall. Furcht und Hoffnung kleidet
sich für uns nicht in die Form einer bestimmten zahlenmäßigen
Festsetzung, es bleiben die einzelnen Momente, die das Für und
Wider ausmachen, bestehen, ohne daß sie als ein Beitrag zu einem
zahlenmäßigen Endresultat formuliert werden können. Es sind nur
die Glücksspiele, wo eine solche zahlenmäßige Festsetzung erreicht
wird, und zwar eben dadurch, daß die Vorgänge des Spieles künstlich,
in bestimmter Weise geregelt werden. Aber auch hier ist
das Ursprüngliche nicht die Bildung der Erwartung bei dem einzelnen
Mitspielenden, sondern die Festlegung der Einsätze nach
bestimmten Prinzipien. Tatsächlich bestimmt der Spieler fast immer
seine Erwartung anders, als der Bankhalter den Einsatz regelt.
Auch hier treiben Furcht und Hoffnung ihr trügerisches Spiel.
Die Festlegung der Wahrscheinlichkeit als einer quantitativ gewerteten
subjektiven Erwartung kann daher jedenfalls eine praktische
Bedeutung nie haben. Wenn man also betont, daß die
Wahrscheinlichkeit als das Maß unserer Erwartung ihrem Wesen
nach subjektiver Natur ist, so ist es am besten, diesen Begriff
ganz aufzugeben, wo es sich um rein objektive Feststellungen
handelt, und ihn durch die Tatsache einer gleichbleibenden relativen
Häufigkeit zu ersetzen, wobei dieser Begriff allerdings als
eine Art Grenzwert erscheint, also durch die Wirklichkeit nur
angenähert, aber nie vollkommen erreicht wird, weil sich, wie man
annimmt, der exakte Wert erst bei einer unendlichen Häufung
der Fälle herausstellen würde.
\DPPageSep{080}{66}

Diesen Weg ist in der Praxis \zB~die Lebensversicherungstechnik
gegangen. Die Prämien und Reserven erscheinen nicht als
auf bestimmten mathematischen Wahrscheinlichkeiten begründet,
sondern sie beruhen nur auf den in einer Sterbetafel zusammengefaßten
statistischen Beobachtungen und auf der Annahme, daß
diese "`rechnungsmäßige Sterblichkeit"' auch bei den neuen Versicherten
ihre Geltung behalten werden. Es wird also das Gesetz
der großen Zahlen in der einfachen Form als eine in der Wirklichkeit
anzunehmende Regelmäßigkeit vorausgesetzt. Allerdings
bleibt es die Aufgabe der praktischen Handhabung des Lebensversicherungsgeschäftes,
durch geeignete Auswahl des Versichertenmaterials
dafür zu sorgen, daß die rechnungsmäßige Sterblichkeit
nicht überschritten wird.

Aus diesen Gründen wollen wir es vorziehen, die statistische
Methode so rein wie möglich zur Geltung zu bringen. Der Schluß
auf den einzelnen noch unentschiedenen Fall, durch den der Wahrscheinlichkeitsbegriff
hineinspielen müßte, interessiert uns nicht.
Was wir wollen, ist vielmehr, aus den statistischen Ergebnissen
die Erscheinungsformen herauszuschälen, die als die Offenbarung
des Zufälligen zu gelten haben, und dadurch über den Charakter
des Zufälligen einen gewissen Aufschluß zu erhalten\footnote
  {Die rein empirische Auffassung des Wahrscheinlichkeitsbegriffes
  als eine bestimmte relative Häufigkeit oder den Grenzwert einer solchen
  hat sich in der neueren Zeit mehr und mehr durchgesetzt. Vgl.\ \zB\
  \so{Bruns}, Wahrscheinlichkeitsrechnung und Kollektivmaßlehre, Leipzig
\index{Bruns}%
  1906. Nur die Franzosen halten an der Begriffsbestimmung der klassischen
  Wahrscheinlichkeitsrechnung mit Zähigkeit fest. Dies gilt auch für
  die neuesten Veröffentlichungen, unter denen ich hier nur zwei nennen
  will: E.~\so{Borel}, Le Hasard (Nouvelle collection scientifique, Paris, Alcan,
\index{Borel}%
  1914), eine gemeinverständliche Darstellung ohne Formeln, und E.~\so{Carvallo},
\index{Carvallo}%
  Le calcul des probabilités et ses applications (Paris, Gauthier-Villars,
  1912) mit elementaren mathematischen Entwickelungen.}.

Die Wahrscheinlichkeitsrechnung hat den Weg von dem Wahrscheinlichkeitsbegriff
zu den statistischen Ergebnissen durch einen
Satz gefunden, der als das \so{Bernoullische Theorem} bezeichnet
%[** TN: Typo "Bernoullisches Theorem" in original]
\index{Bernoullische Theorem}%
wird. Um dieses Theorem zu erläutern, ist es zweckmäßig, von
einem bestimmten Schema des Glücksspieles auszugehen. Man
denkt sich in einer Urne schwarze und weiße Kugeln in einem
bestimmten Verhältnis gemischt. Das Spiel besteht nun darin,
daß immer eine Kugel aus der Urne gezogen, ihre Farbe festgestellt
\DPPageSep{081}{67}
und sie dann wieder zurückgelegt wird. Das Bernoullische
Theorem soll dann aussagen, daß, wenn die Ziehung häufig genug
wiederholt wird, die Anzahl der gezogenen weißen zu der Anzahl
der schwarzen Kugeln in annähernd demselben Verhältnis steht, wie
die Anzahl der in der Urne enthaltenen weißen zu der Anzahl der
in der Urne enthaltenen schwarzen Kugeln, \dh~daß das Ziehungsverhältnis
das Mischungsverhältnis annähernd wiedergibt, wenn
die Anzahl der Ziehungen groß genug ist. Daraus würde wirklich
folgen, daß bei einer neuen Serie von sehr viel Ziehungen aus
derselben Urne sich auch wieder annähernd dasselbe Ziehungsverhältnis
ergeben muß, \dh~es würde für die Ziehungen aus einer
Urne die annähernde Konstanz des Verhältnisses, die in dem Gesetze
der großen Zahlen ausgesprochen wird, sich theoretisch begründen
lassen. Aber bei näherem Zusehen ergeben sich doch
gewichtige Bedenken. Zunächst bedeutet die Annahme des Bestehens
einer bestimmten Wahrscheinlichkeit für das Ziehen einer
weißen Kugel nur eine wohl plausible, aber keineswegs evidente
Voraussetzung. Wenn die Annahme einer bestimmten Wahrscheinlichkeit
nur das Maß unserer Erwartung gibt und nur subjektive
Bedeutung hat, wie kann dann hieraus eine objektive empirisch
festzustellende Tatsache gefolgert werden? Wie ist dieser Widerspruch
zu erklären? Es zeigt sich, daß in Wirklichkeit gar nicht
diese Tatsache direkt gefolgert wird, sondern es ergibt sich nur
eine sehr große Wahrscheinlichkeit dafür, daß bei einer großen
Anzahl von Ziehungen das Ziehungsverhältnis annähernd mit dem
Mischungsverhältnis zusammenfällt. Der Schluß ist dann einfach
der, daß, wenn für einen Erfolg eine sehr große, \dh~der Einheit
nahezu gleiche Wahrscheinlichkeit besteht, dieser Erfolg als gewiß
und bei jedem wirklichen Versuch als tatsächlich anzusehen
ist. Dadurch wird aber die Kluft zwischen der subjektiven Wertung,
die in dem Ansatz der Wahrscheinlichkeit liegt, und der
Feststellung einer empirischen Tatsache nur verhüllt, aber nicht
überbrückt. Die theoretische Begründung, die erstrebt wurde,
wird nicht geliefert, es wird nur die Darstellung so gewendet,
daß wir über die Schwierigkeit des Überganges von den Bedingungen
des Ereignisses zu seinem wirklichen Ausgang ahnungslos
hinweggleiten. Es wird \zB~auf keine Weise logisch widerlegt,
daß man aus einer Urne, die nur eine einzige weiße Kugel
enthält, fortwährend diese weiße Kugel ziehen kann. Gerade
\DPPageSep{082}{68}
dafür, daß ein Ereignis, dessen mathematische Wahrscheinlichkeit
wir sehr nahe gleich $1$ gefunden haben, auch so gut wie immer
eintritt, brauchen wir eine empirische Bestätigung. Darin liegt
eine erneute Mahnung, nicht den Begriff der subjektiven Wahrscheinlichkeit,
sondern nur die Bedeutung einer wenigstens näherungsweise
gleichbleibenden relativen Häufigkeit der Betrachtung
zugrunde zu legen.

Daß die Zählung des Vorkommens in einer großen Anzahl
von beobachteten Fällen die einzig sichere Art ist, zu beurteilen,
ob verschiedene Fälle wirklich gleich möglich sind, kann man an
dem Beispiel des Würfelns erkennen. Wenn wir von vornherein
annehmen, daß mit einem Würfel jeder Wurf gleich wahrscheinlich
ist, so ist das zunächst eine unbewiesene und unbestätigte
Annahme, für die wir noch, wenn es sich um eine exakte Bestimmung
handeln soll und nicht bloß um einen ungefähren Ansatz,
wie er bei Glücksspielen allein verlangt wird, eine Kontrolle
durch die Erfahrung finden müssen. Diese Kontrolle kann nur
darin bestehen, daß man mit dem Würfel eine große Anzahl von
Würfen ausführt und aufzeichnet, wie oft dabei die einzelnen
Augenzahlen fallen. Eine wie große Abweichung von der ursprünglichen
Annahme sich hierbei ergeben kann, zeigen die Versuche
von R.~\so{Wolf} (Versuche zur Vergleichung der Erfahrungswahrscheinlichkeit
\index{Wolf, R.}%
mit der mathematischen Wahrscheinlichkeit,
Mitteilungen der naturforschenden Gesellschaft in Bern 1849 bis
1851, 1853), der bei $20\,000$ Würfen statt des Wertes $0,167$ für
die relative Häufigkeit des Auftretens der einzelnen Augenzahlen
die folgenden Werte fand:
\[
\begin{array}{*{6}{c<{\quad}}}
1  &  2  &  3  &  4  &  5  &  6 \\
0,170  &   0,186  &   0,159  &   0,146  &   0,172   &  0,171
\end{array}
\]
Danach betragen die bei dem ursprünglichen Ansatz gemachten
Fehler der Reihe nach rund
\[
\begin{array}{*{6}{c<{\qquad}}}
+2  &  +13  & -5  &  -14 & +3 & +2\rlap{\text{ Proz.}}
\end{array}
\]

Es bedeutet also der Ansatz der gleich möglichen Fälle immer
eine mehr oder minder unbestimmte Vermutung, die noch der Bestätigung
bedarf, und da diese Bestätigung durch das "`Gesetz der
großen Zahlen"' geliefert wird, wird dieses Gesetz durch die Wahrscheinlichkeitsrechnung
nicht begründet, sondern muß ihr vielmehr
als eine unabhängige Tatsache zugrunde gelegt werden.
\EndChap
\DPPageSep{083}{69}


\Chapter{Sechstes Kapitel}{Die mathematische Analyse
stationärer Reihen}

Bis hierher haben wir uns allen mathematischen Rechnungen
ferngehalten und nur die begriffliche Klärung angestrebt. Jetzt
aber wollen wir gerade die Hilfsmittel der mathematischen Analyse
heranziehen, um zu quantitativen Bestimmungen zu gelangen,
die einen sicheren Anhaltspunkt für die Beurteilung des Charakters
der zufälligen Ereignisse liefern. Die quantitative Bestimmung
bedeutet immer mit Notwendigkeit eine Beschränkung in der Betrachtung
der qualitativen Besonderheit. Jedes Beispiel aus der
Physik kann das klarmachen. Der Vorgang des freien Falles
bietet der Beobachtung eine große Mannigfaltigkeit qualitativer
Bestimmungen. Es ist, rein menschlich betrachtet, etwas ganz
anderes, ob ein Hagelkorn vom Himmel auf die Erde, ein
Blumentopf aus dem Fenster auf die Straße herunterfällt, oder ob
ein Dachdecker vom Dach stürzt und sich das Genick bricht.
Die Physik aber vereinigt alle diese Vorgänge unter einem Gesichtspunkte,
und in der Nichtberücksichtigung ihrer besonderen
Bedeutung im menschlichen Leben liegt das, was man wohl als die
Unerbittlichkeit oder die Blindheit der Naturgesetze bezeichnet. Bei
der Analyse, die wir hier beginnen, treten diese Eigentümlichkeiten
noch stärker hervor, eben weil das Interesse an der qualitativen
Besonderheit in den meisten Fällen besonders groß ist, so daß es
uns widerstrebt, von dieser ganzen Besonderheit abzusehen und
rein äußerlich die statistischen Ergebnisse zu betrachten. Es
tritt hier noch augenfälliger zutage, wie verschiedenartig im
Grunde die gemeinsam behandelten Vorgänge sind, und es kann
sinnlos erscheinen, sie nach einer rein äußerlich hervortretenden
quantitativen Gemeinsamkeit zu vereinigen. Und doch ist hierin
die Bedingung für einen wirklichen Fortschritt enthalten.
\DPPageSep{084}{70}

Wir sehen also bei der folgenden Untersuchung davon ab, wie
die Zahlenreihen, die wir vor uns haben, entstanden sind, und
welche besonderen Vorgänge in ihnen ihren Ausdruck finden.
Wir nehmen dabei an, daß die vorgelegte Zahlenreihe eine \so{stationäre}
sei. Wir können jede solche stationäre Reihe auf einen besonderen
Fall zurückführen, wo die Werte der Reihe teils positiv,
teils negativ sind, sich also um den Wert~$0$ gruppieren. Wir erreichen
dies, indem wir von den Werten der vorgelegten Reihe
einen und denselben bestimmten Wert, den Durchschnittswert der
Reihe, abziehen. Dann wird in der neuen stationären Reihe die
Summe aller positiven Werte ebenso groß wie die Summe aller negativen
Werte. Wir wollen gleich bemerken, daß wir auch aus anderen
als stationären Zahlenreihen eine solche, sich um den Wert~$0$
gruppierende stationäre Reihe ableiten können, indem wir von den
Werten der Reihe nun nicht mehr einen und denselben Zahlenwert,
sondern die durch eine bestimmte Näherungsfunktion gegebenen
Werte abziehen, möge diese Näherungsfunktion nun
durch einen analytischen Ausdruck oder graphisch durch eine
Kurve gefunden werden.

Die so abgeleiteten stationären Reihen, die sich um den Wert~$0$
gruppieren, liefern nun aber sofort eine Verteilungsreihe. Das
zweite wird also die besondere Behandlung der \so{Verteilungsreihen}
sein. Für diese lassen sich zunächst allgemeine Begriffsbestimmungen
treffen, durch die man eine Handhabe zur Beurteilung
der vorliegenden Verteilungsreihe gewinnt. Es zeigt sich
aber bald, daß solche allgemeinen Begriffsbestimmungen allein nicht
ausreichen. Vielmehr erweist es sich als nötig, bestimmte Typen
von Verteilungsreihen herauszugreifen, und die Frage wird sein,
wie man zu solchen Typen gelangt. Hierzu verhilft die sogenannte
Wahrscheinlichkeitsrechnung, \dh~die Betrachtung bestimmter
typischer Vorgänge, die einer besonderen mathematischen
Analyse fähig sind. Alle diese Vorgänge lassen sich schließlich
zurückführen auf den einen Vorgang der Ziehung von einer oder
mehreren Kugeln aus einer Urne, in der Kugeln von verschiedener
Farbe gemischt enthalten sind. Mit den aus diesem Urnenschema
abgeleiteten typischen Verteilungsreihen werden dann die irgendwie
entstandenen Verteilungsreihen verglichen.

Unter den Typen von Verteilungsreihen, zu denen das Urnenschema
führt, ragen gewisse hervor, die wir als typische Zufallsreihen
\DPPageSep{085}{71}
ansehen. Ereignisse, die bei der statistischen Zusammenstellung
der Resultate vieler Einzelfälle den Typus einer solchen
Zufallsreihe zeigen, sehen wir als zufällige an. Es ist zu wiederholen,
daß wir dadurch im Grunde keine Aussage über die qualitative
Eigentümlichkeit der betreffenden Ereignisse machen. Eigentlich
handelt es sich gar nicht um eine Eigenschaft des einzelnen Ereignisses,
sondern nur um eine Eigenschaft der statistischen Gesamtheit.
Aber es zeigt sich doch, daß diese Festlegung des Zufälligen
die sicherste und gewisseste ist, die wir finden können,
ohne die Grenzen des durch die Erfahrung Erreichbaren zu überschreiten.
Wir müssen noch allgemein bemerken, daß wir den
Typus einer vorgelegten Verteilungsreihe nur dadurch erkennen,
daß wir versuchen, die empirisch festgestellten Werte durch die
Werte der einer typischen Verteilungsreihe entsprechenden Funktion
zu approximieren. Die dabei sich notwendigerweise ergebenden
Abweichungen können wir aufs neue derart analysieren, daß wir
aus ihnen wieder eine Verteilungsreihe ableiten. So würde sich
an die ursprüngliche Analyse noch eine weitergehende anreihen.
Diese weitere Durchführung der Analyse ist aber meistens unerreichbar.
Die bei dem Vergleich der vorgelegten Reihe mit der
typischen Verteilungsfunktion herauskommenden Abweichungen
sind nämlich verhältnismäßig klein, und die Gruppen, die wir aus
ihnen bei der Bildung der neuen Verteilungsreihe ableiten können,
sind entweder sehr wenig zahlreich oder enthalten jede sehr wenig
Glieder. Beides aber macht eine genaue Analyse unmöglich und
wir werden auf eine solche fast immer verzichten müssen.

Wir wollen nun an die Ausführung der Arbeit im einzelnen
gehen und zunächst die mathematischen Definitionen und Formeln
erörtern, die sich unmittelbar an eine vorgelegte stationäre Zahlenreihe
anknüpfen. Das erste wird sein, daß wir ein bestimmtes
\so{Maß für die Schwankungen} der Werte innerhalb der stationären
Reihe suchen. Wir bezeichnen die aufgezeichneten Werte
der Reihe mit
\[
y_1,\ y_2,\ y_3,\ \dots,\ y_n;
\]
das Maß für die Schwankungen soll dann gegeben sein durch den
Ausdruck
\[
\Tag{(1)}
M = \frac{2}{n(n-1)}\Sum_{i,k}(y_i - y_k)^2,
\]
\DPPageSep{086}{72}
in dem sich die Summe auf die $\dfrac{n(n-1)}{2}$ Wertepaare $i$,~$k$ bezieht,
die sich aus den Zahlen $1$~bis~$n$ bilden lassen. Der Ausdruck
faßt alle Unterschiede zusammen, die überhaupt in der Zahlenreihe
vorkommen; er ist ferner unabhängig davon, in welcher Reihenfolge
die aufgezeichneten Werte genommen werden, ebenso von den
Vorzeichen der vorkommenden Differenzen, und wächst mit deren
absoluten Werten.

Aus dem Wert~$M$ läßt sich ein anderer noch anschaulicherer
Wert ableiten: es ist dies die \so{mittlere Abweichung}~$m$, die gegeben
wird durch die Gleichung
\[
\Tag{(2)}
m = \sqrt{M}.
\]
Es ist nämlich $\dfrac{n(n-1)}{2}$ die Anzahl der Glieder in der Summe
$\Sum(y_i - y_k)^2$, und dividieren wir die Summe durch die Anzahl
ihrer Glieder, so erhalten wir den mittleren Wert des einzelnen
Gliedes. Da dieser Wert sich aber auf die Quadrate der Abweichungen
bezieht, müssen wir noch die Wurzel ausziehen und
finden so für die mittlere Abweichung
\[
\Tag{(2a)}
m = \sqrt{\frac{2\Sum(y_i - y_k)^2}{n(n-1)}},
\]
\dh~den obenstehenden Wert.

Wir formen nun den Ausdruck~$M$ derart um, daß die doppelte
Summation, die er bedingt, durch eine einfache Summation
ersetzt wird. Dies gelingt, indem wir den \so{Durchschnittswert}
(das arithmetische Mittel)
\[
\Tag{(3)}
y_0 = \frac{y_1 + y_2 + \dots + y_n}{n}
\]
einführen. Dann ergibt sich nämlich aus~\Eqref{(1)}:
\begin{align*}
(n-1)M
  & = \Sum_i (y_i - y_0)^2 + \Sum_k (y_k - y_0)^2 \\
  & - \frac{2}{n} \Sum_i (y_i - y_0) \Sum_k (y_k - y_0)
\end{align*}
und, da $\Sum(y_i - y_0) = 0$ und ebenso $\Sum(y_k - y_0) = 0$,
\[
\Tag{(4)}
\frac{n-1}{2}·M = \Sum_i (y_i - y_0)^2,
\]
\DPPageSep{087}{73}
und daraus
\[
\sqrt{\frac{n-1}{n}}m = \sqrt{2}\mu,
\]
wenn wir noch $\mu = \sqrt{\dfrac{\Sum(y_i - y_0)^2}{n}}$ einführen.

Diese Darstellung empfängt noch eine neue Beleuchtung, wenn
man statt eines Maßes für die Abweichung der aufgezeichneten
Werte voneinander ein Maß für die Abweichung von einem beliebig
gegebenen Werte~$y$ einführt. Als solches Maß kann der Ausdruck
\[
\Tag{(5)}
M(y) = \frac{1}{n} \Sum_k(y_k - y)^2
\]
gelten. Man findet hieraus die früher eingeführte Zahl~$M$, indem
man den Ausdruck bildet
\[
\Tag{(6)}
M(y) = \frac{1}{n-1} \Sum_iM(y_i).
\]

Es liegt nun nahe, nach dem Werte~$y$ zu fragen, für den
das Maß der Abweichung von der aufgezeichneten Wertereihe
möglichst klein wird. Dieser Wert bestimmt sich daraus, daß
man allgemein
\begin{align*}
M(y) &= \frac{1}{n} \Sum_k(y_k - y_0)^2 + (y - y_0)^2 \\
     &- 2(y - y_0) \frac{1}{n} \Sum_k(y_k - y_0)
\end{align*}
setzen kann. Nimmt man daher an, daß
\[
\Sum(y_k - y_0) = 0
\]
wird, also für~$y_0$ den Wert
\[
y_0 = \frac{y_1 + y_2 + \dots + y_n}{n},
\]
so wird
\[
\Tag{(7)}
M(y) = M(y_0) + (y - y_0)^2,
\]
und daraus erkennt man, daß das Maß der Abweichung am kleinsten
wird für $y_0$ selbst, denn für jeden anderen Wert~$y$ kommt zu
$M(y_0)$ noch der positive Betrag $(y - y_0)^2$ hinzu. $M(y_0)$~stimmt
aber mit dem Werte von $\mu^2$ überein.
\DPPageSep{088}{74}

Als die \so{mittlere Abweichung} der Zahlenreihe \so{von einem
beliebigen} Werte~$y$ wollen wir den Ausdruck bezeichnen
\[
\Tag{(8)}
\mu(y) = \sqrt{M(y)} = \sqrt{\frac{\Sum(y_i - y)^2}{n}}.
\]
Bilden wir diesen Ausdruck für den Mittelwert~$y_0$, so erhalten wir
den früheren Ausdruck~$\mu$, den wir als die \so{mittlere Ausweichung}
oder Streuung der vorgelegten Reihe bezeichnen wollen.

Wir können aus der Begriffsbestimmung des arithmetischen
Mittels auch eine Regel für die Beurteilung ableiten, ob eine vorgelegte
Reihe als stationär zu gelten hat. Wir müssen dann die
Werte gruppenweise zusammenfassen, etwa zunächst zu~$10$, und
für jede Gruppe den Mittelwert~$y_0$ bestimmen. Dann müssen
wir weiter die aufgezeichneten Werte zu größeren Gruppen, etwa
zu~$100$, zusammenfassen und wieder von jeder Gruppe den Mittelwert
bilden. Es gehört nun zu den Eigenschaften des arithmetischen
Mittels, daß sich derselbe Wert ergibt, ob man erst aus
Gruppen von gleich viel Werten das Mittel und dann von diesen
Mitteln wieder das Mittel bestimmt, oder ob man unmittelbar von
den gegebenen Werten selbst das Mittel nimmt. In der Tat wird
\zB, wenn die Reihe nur sechs Glieder hat,
\begin{align*}
y_0 &= \frac{1}{6}(y_1 + y_2 + y_3 + y_4 + y_5 + y_6) \\
    &= \frac{1}{3}\left(
      \frac{y_1 + y_2}{2}
    + \frac{y_3 + y_4}{2}
    + \frac{y_5 + y_6}{2}\right).
\end{align*}
Wir finden also jetzt mehrere Reihen, die aus immer weniger
Werten bestehen und die sich alle um denselben Mittelwert gruppieren.
Es läßt sich nun zeigen, daß die mittlere Abweichung
der neuen Reihen vom Durchschnittswert immer kleiner ist als
für die ursprüngliche Reihe.

Denken wir uns nämlich eine Reihe, die aus $n = \rho\nu$ Werten
besteht, in $\nu$~Gruppen von je $\rho$~Werten zerlegt und die Durchschnittswerte
\[
Y_1,\ Y_2,\ Y_3,\ \dots,\ Y_\nu
\]
jeder Gruppe gebildet, so wird die mittlere Abweichung der Gesamtreihe
von dem Durchschnittswert gefunden, indem man die
mittleren Abweichungen der einzelnen Gruppen von diesem Mittelwert
bildet und daraus wieder das Mittel nimmt. Wenn wir nun
\DPPageSep{089}{75}
aber die mittlere Ausweichung der $i$ten~Gruppe mit $\mu_i$~bezeichnen,
so ergibt sich für das Quadrat ihrer mittleren Ausweichung von
dem Mittel~$y_0$ aller Werte
\[
(Y_i - y_0)^2 + \mu_i^2
\]
und daraus die einfache Formel
\[
\mu^2
  = \frac{1}{\nu} \Sum (Y_i - y_0)^2 + \frac{1}{\nu} \Sum \mu_i^2
  = \mu_0^2 + \frac{1}{\nu} \Sum \mu_i^2,
\]
wenn wir $\mu_0^2 = \dfrac{1}{\nu} \Sum(Y_i - y_0)^2$ setzen.

Diese Formel zeigt in der Tat, wie die mittlere Ausweichung
mit der Gruppenbildung abnimmt, denn die mittlere Ausweichung
für die Mittelwerte~$Y_i$ der Gruppen wird ja
\[
\Tag{(9)}
\mu_0 = \sqrt{\mu^2 - \frac{1}{\nu} \Sum \mu_i^2}
\]
und ist sonach notwendigerweise kleiner als die ursprüngliche
mittlere Ausweichung~$\mu$.

Wir haben hier die Bildung des arithmetischen Mittels auf
stationäre Zahlenreihen beschränkt. In Wirklichkeit findet sie
in viel weiterem Umfange statt. Es werden Durchschnittswerte
für die verschiedenartigsten Größenfolgen angegeben, um zu einem
zusammenfassenden Ausdruck der ganzen Zahlenfolge zu gelangen.
Vor allen Dingen werden die Durchschnittswerte ohne Rücksicht
darauf gegeben, wie stark die einzelnen Zahlen, von denen der
Durchschnitt genommen ist, voneinander abweichen. So handelt
es sich \zB, wenn das durchschnittliche Vermögen eines Deutschen
berechnet wird, um die verschiedensten Summen, von denen der
Durchschnitt genommen wird, ja auf die größere Anzahl der Personen
entfällt der Betrag~$0$, und von da an steigt der Wert bis
zu Hunderten von Millionen hinauf. Hat es unter solchen Umständen
nun einen Sinn, den Durchschnittswert zu bilden? Seine
Bedeutung ist zunächst nur die, daß er einen Quotienten darstellt,
nämlich den Quotienten der Summe aller Werte der Zahlenfolge
und der Anzahl dieser Werte. Was man aus diesem Wert herauslesen
will, bleibt noch der Willkür überlassen.

Nach dem, was wir gefunden haben, hat es nun keinen Zweck,
den Mittelwert da zu bilden, wo eine deutlich erkennbare Entwickelung
in der Zahlenfolge zu finden ist. Zum Beispiel ist es
\DPPageSep{090}{76}
sinnlos, von der mittleren Bevölkerung des deutschen Reichsgebietes
während der letzten $100$~Jahre zu sprechen, weil in diesen
$100$~Jahren eine deutlich erkennbare Entwickelung, nämlich
eine stetige Zunahme der Bevölkerung, stattgefunden hat. Die
Verteilung der Vermögen unter den einzelnen Einwohnern ist dagegen
eine solche, daß, wenn wir die Einwohner nach einer gewissen
Reihenfolge ihrer Wohnstätten in eine Liste eintragen und
die dazugehörigen Vermögen daneben schreiben, in dieser Zahlenfolge
keine bestimmte Entwickelung erkennbar ist. Die Bildung
der Durchschnittswerte ist daher gestattet, wie weit auch die einzelnen
Werte voneinander abweichen. Die Reihe kann trotzdem
als eine stationäre gelten, weil die absolute Größe der Abweichungen
bei dieser Begriffsbestimmung gar keine Rolle spielt. Im vorliegenden
Falle wird allerdings die Gruppierung der Werte um
den Durchschnittswert eine stark unsymmetrische sein, weil der
Durchschnittswert (etwa $7000\,\mathscr{M}$) sehr viel näher an der unteren
als an der oberen Grenze liegt.

Wir gehen nun zur Betrachtung der \so{Verteilungsreihen}
über. Die Verteilungsreihen waren, wie wir sahen, sozusagen
sekundäre Tabellen, die aus einer ursprünglichen Tabelle dadurch
abgeleitet wurden, daß man die Tabellenwerte der Größe nach
ordnete und angab, wieviel Tabellenwerte zwischen bestimmte
Grenzen fallen. Wir werden diese Bildung einer sekundären Reihe
insbesondere auf die stationären Reihen anzuwenden haben. Wir
wollen aber zunächst die Verteilungsreihen allgemeiner betrachten.

Wir nehmen an, daß sich die vorkommenden Werte, welche
jetzt den Eingang der Tabelle, in der ursprünglichen Tabelle aber
die eingetragenen Werte bilden, über ein bestimmtes Intervall
erstrecken. Wenn dieses Intervall nach einer oder nach beiden
Seiten unbegrenzt ist, so nehmen wir an, daß die zugehörigen
Häufigkeitszahlen schließlich sehr klein werden. Das bedeutet, daß
in der ursprünglichen Tabelle nur verhältnismäßig wenig sehr große
Werte enthalten sein sollen. Wir können uns praktisch immer
ein endliches Intervall abgegrenzt denken (indem wir nötigenfalls
die darüber hinausfallenden Werte vernachlässigen), so daß die
ganze Verteilungsreihe auf dieses Intervall beschränkt bleibt. Es
handelt sich nun zunächst darum, eine Reihe von Begriffen zu
entwickeln, welche zur allgemeinen Beurteilung einer vorgelegten
Verteilungsreihe dienen können.
\DPPageSep{091}{77}

Den ersten Begriff, den wir verwenden, entnehmen wir der Betrachtung
der stationären Reihen, wie wir sie vorhin angestellt
haben. Es ist dies der Begriff des \so{arithmetischen Mittels}.
Wir finden das arithmetische Mittel, indem wir jeden Wert des
Einganges mit dem zugehörigen Tabellenwert multiplizieren und
die Summe aller dieser Produkte durch die Summen aller Tabellenwerte
teilen. Da der Eingang der Verteilungstabelle Intervalle
bedeutet, so müssen wir die Mitte~$y_\rho$ jedes Intervalls nehmen und
mit der Anzahl~$z_\rho$ der in das Intervall fallenden Werte der ursprünglichen
Tabelle multiplizieren. Wir finden also für das
arithmetische Mittel jetzt den Ausdruck
\[
\Tag{(10)}
y_0 = \frac{\Sum y_\rho z_\rho}{\Sum z_\rho}.
\]

Bei der graphischen Darstellung der Tabelle bedeutet das
arithmetische Mittel die Abszisse, die zu dem Schwerpunkt der
aus steifem Papier ausgeschnitten gedachten, die Tabelle darstellenden
Staffelfigur gehört.

Außer dem arithmetischen Mittel wollen wir auch die \so{mittlere
Ausweichung} bilden. Wir finden hierfür
\[
\Tag{(11)}
\mu^2 = \frac{\Sum(y_\rho - y_0)^2 z_\rho}{\Sum z_\rho},
\]
wofür wir mit Rücksicht auf die Bedeutung von $y_0$ auch schreiben
können
\[
\Tag{(11a)}
\mu^2 = \frac{\Sum y_\rho^2 z_\rho}{\Sum z_\rho} - y_0^2.
\]

Unter Umständen ziehen wir der Staffelfigur das Bild einer
stetigen Kurve vor. Dementsprechend haben wir dann in den
obenstehenden Ausdrücken die Summen durch Integrale zu ersetzen
und finden, indem $z$ als Funktion von~$y$ erscheint,
\[
y_0 = \frac{\Int yz\, dy}{\Int z\, dy}, \qquad
\mu^2 = \frac{\Int(y - y_0)^2 z\, dy}{\Int z\, dy},
\]
wobei die Integrale über die ganze Ausdehnung der Verteilungskurve
auszudehnen sind, was man gewöhnlich so ausdrücken kann,
daß man die Grenzen gleich $-\infty$~und~$+\infty$ setzt.

Es gibt nun aber noch eine zweite Art der Mittelbildung,
die an sich noch einfacher ist. Man grenzt nämlich das Intervall
\DPPageSep{092}{78}
ab, für das die Summe aller darunterliegenden Häufigkeitszahlen
möglichst gleich der Summe aller darüberliegenden Häufigkeitszahlen
wird. Wir bezeichnen den so gefundenen Wert der Abszissen als
den \so{Zentralwert}~$y_z$ und die zugehörigen Ordinate als die zentrale
Ordinate. Bei der graphischen Darstellung der Tabelle durch
eine Staffelfigur bedeutet die zentrale Ordinate einen Schnitt, durch
den die ganze Fläche der Figur in zwei gleiche Teile zerlegt wird
und analog bei der Darstellung der Verteilung durch eine stetige
Kurve.

Wir bestimmen schließlich noch das Intervall, bei dem die
Häufigkeitszahl ein Maximum bildet, \dh~größer wird als für die
nach beiden Seiten benachbarten Intervalle. Den so ermittelten
Wert~$y_a$ bezeichnen wir als \so{Normalwert}. Es liegt nun auf
der Hand, daß sich unter Umständen auch mehrere solche Intervalle
finden können. Wir müßten dann von mehreren Normalwerten
sprechen, was aber nicht als zweckmäßig erscheint. Vielmehr
tritt die eigentliche Bedeutung des Normalwertes erst dann
hervor, wenn nur ein Maximum vorhanden ist.

Um ein besonderes Beispiel für die drei verschiedenen Mittelwerte
zu haben, wollen wir die Zahlenreihe nehmen, die in einer
Sterbetafel vorliegt. Der erste Mittelwert, das arithmetische Mittel
oder der Durchschnittswert, wird in diesem Falle die \so{durchschnittliche
Lebensdauer}. Sie ist für die im Auszuge auf
S.~24 mitgeteilte Sterbetafel
\[
44,8 \text{ Jahre.}
\]
Der zweite Mittelwert, der Zentralwert, ist in diesem Falle die
\so{wahrscheinliche Lebensdauer}, \dh~das Alter, das gerade die
Hälfte der Geborenen erreicht. Sie beträgt
\[
55,6 \text{ Jahre.}
\]
Der dritte Mittelwert, der Normalwert, ist in diesem Falle das
\so{normale Lebensalter}, \dh~das Lebensalter, in dem mehr
Menschen sterben als in den auf beiden Seiten benachbarten
Altersstufen, wo also die Sterbekurve ein Maximum hat. Dieses
Alter beträgt
\[
73,2 \text{ Jahre.}
\]
Man erkennt deutlich die Verschiedenheit der drei Mittelwerte und
sieht, daß die wahrscheinliche Lebensdauer zwischen der durchschnittlichen
\DPPageSep{093}{79}
und der normalen Lebensdauer liegt. Die drei Zahlen
zusammen können als die zusammenfassende Charakteristik der
Absterbeordnung gelten.

Wir wollen die auf diese Weise abgeleiteten Begriffe sofort
benutzen, um eine vorgelegte stationäre Reihe weiter zu analysieren.
Das arithmetische Mittel gibt dabei wieder den schon früher betrachteten
Durchschnittswert. Dagegen liefert uns der Zentralwert
etwas wirklich Neues. Um ihn zu finden, haben wir folgendermaßen
zu verfahren. Wir ordnen die aufgezeichneten Werte der
Größe nach, hierauf zählen wir, vom niedrigsten Wert anfangend,
wenn die Anzahl der aufgezeichneten Werte gerade ist, die Hälfte
der Werte ab und notieren den Wert, der in der Mitte zwischen
dem so erreichten Wert und dem nächstfolgenden liegt, oder
direkt den aufgezeichneten Wert, der von dem kleinsten und dem
größten Wert um gleichviel Glieder entfernt ist, wenn die Anzahl
der aufgezeichneten Werte ungerade ist.

Wir können diese Methode weiter fortsetzen, indem wir auch
die abgezählten Hälften der aufgezeichneten Werte aufs neue halbieren,
und die Werte notieren, zu denen wir so gelangen; unter
ihnen oder über ihnen liegt je ein Viertel aller aufgezeichneten
Werte. Die Abweichung dieser Werte voneinander können wir auch
als Maß für die Streuung der stationären Reihe betrachten. Einzeln
können wir die Unterschiede der letzten beiden Werte vom Mittelwert
als Maß für die Abweichung der stationären Reihe von dem
Mittelwert nach unten und nach oben hin ansehen. Wir erhalten
so auch einen Maßstab dafür, in welcher Weise die stationäre
Reihe unsymmetrisch ist. Wenn nämlich \zB~der obere Wert
erheblich weniger von dem Zentralwert abweicht als der untere
Wert, so ist dieses ein Zeichen dafür, daß die Reihe nach unten
zu weiter ausgedehnt ist als nach oben zu, daß sie also nach unten
zu unsymmetrisch ist.

Wir wollen nun eine Art der Verteilung herausgreifen, die
den Typus einer \so{einfachen unsymmetrischen Verteilung}
darstellt. Sie soll durch folgende Merkmale gekennzeichnet sein:
Es ist ein Normalwert vorhanden, von dem aus die Verteilungsfunktion
nach beiden Seiten beständig abnimmt, um schließlich in
Null überzugehen. Die Asymmetrie der Verteilung soll sich dadurch
zu erkennen geben, daß gleiche Werte der Verteilungsfunktion
\DPPageSep{094}{80}
sich für solche Werte des Arguments, der eine $y_1$ rechts,
der andere $y_2$ links vom Normalwert~$y_a$, ergeben, für die
\[
|y_1 - y_a| < |y_a - y_2|
\]
ist, und es soll, wenn auch für $y_1'$,~$y_2'$ gleiche Werte der Verteilungsfunktion
eintreten, auch
\[
|y_1' - y_1| < |y_2 - y_2'|
\]
werden. Man kann aus dieser Ungleichheit auch ableiten
\[
\left|\frac{\Delta\phi(y_1)}{\Delta y_1}\right| >
\left|\frac{\Delta\phi(y_2)}{\Delta y_2}\right|,
\]
indem man $\Delta y_1 = y_1' - y_1$, $\Delta y_2 = y_2' - y_2$ setzt und beachtet,
daß dann der Voraussetzung gemäß $\Delta\phi(y_1) = \Delta\phi(y_2)$ wird.
Aus der letzten Ungleichheit folgt aber, indem wir zur Grenze
übergehen,
\[
\left|\frac{d\phi(y_1)}{d y_1}\right| >
\left|\frac{d\phi(y_2)}{d y_2}\right|.
\]
Die Kurve, welche die Verteilungsfunktion darstellt, ist also auf
der kürzeren Seite vom Normalwert aus überall stärker gegen die
Abszissenachse geneigt als an den entsprechenden (gleich hohen)
Stellen auf der längeren Seite.

Unter diesen Voraussetzungen können wir eine wichtige
Lagenbeziehung zwischen den drei Mittelwerten beweisen. Zunächst
ist leicht zu erkennen, daß, wenn die Verteilungskurve vom Normalwerte
\begin{figure}[hbt!]
  \centering
  \caption{Fig.~5.}
  \Input[0.75\textwidth]{094}
\end{figure}
aus nach rechts hin steiler abfällt, auf der rechten Seite
auch die von der Verteilungskurve über der Abszissenachse abgegrenzte
Fläche kleiner als auf der linken Seite sein muß. Die
zentrale Ordinate, welche die ganze Fläche halbiert, liegt also
notwendigerweise auf der linken Seite. Es handelt sich nun
\DPPageSep{095}{81}
darum, die Lage des Durchschnittswertes zu ermitteln. Zu diesem
Zweck gehen wir von dem Zentralwert~$y_z$ aus. Die zu ihm
gehörige Ordinate halbiert die ganze von der Verteilungskurve
über der Abszissenachse abgegrenzte Fläche. Übertragen wir
also den Teil der Kurve links vom Zentralwert spiegelbildlich auf
die rechte Seite, so muß dort die neue Linie die ursprüngliche
Kurve derart durchsetzen, daß beim Übergang von dieser zu jener
die abzutragenden Stücke an Flächeninhalt gleich den hinzuzufügenden
Stücken sind. Die beiden Kurven können sich aber nur
an einer Stelle~$y_1$ durchsetzen. Für diese Stelle~$y_1$ wird der Wert
der Verteilungsfunktion $\phi(y_1)$ ebenso groß, wie der Wert $\phi(y_2)$ für
die Abszisse~$y_2$, für die $y_z - y_2 = y_1 - y_z$. Gäbe es einen zweiten
solchen Wert~$y'_1$, so daß auch $\phi(y'_1) = \phi(y'_2)$, wenn $y_z - y'_2
= y'_1 - y_z$, dann müßte $|y'_1 - y_1| = |y_2 - y'_2|$ werden, während
wir davon ausgegangen waren, daß immer $|y'_1 - y_1| < |y_2 - y'_2|$
ist. Wir finden also nur einen Durchsetzungspunkt und damit
nur zwei Flächenstücke, die sich ausgleichen, deren Inhalte also
gleich sein müssen. Daraus können wir schließen, daß der
Schwerpunkt der Fläche links von der Zentralordinate weiter von
dieser entfernt ist als der Schwerpunkt der Fläche rechts von der
Zentralordinate, denn um die erstere Fläche in die letztere zu
verwandeln, müssen wir ein weiter entferntes Stück (in der Figur
senkrecht schraffiert) in eine der Zentralordinate näher benachbarte
Lage (in der Figur schräg schraffiert) bringen.

Die Mitte zwischen den beiden Schwerpunktsordinaten liefert
nun aber die Schwerpunktsordinate der ganzen von der Verteilungskurve
abgegrenzten Fläche und die zu dieser Ordinate gehörende
Abszisse ist der Durchschnittswert~$y_0$. Dieser Durchschnittswert
muß also links (auf der flacheren Seite) von dem
Zentralwert~$y_z$ liegen, und wir finden: \so{Der Zentralwert liegt
unter den angegebenen Voraussetzungen immer zwischen
dem Durchschnittswert und dem Normalwert} (\so{Fechnersches
Lagengesetz}).
\index{Fechnersches Lagengesetz}%

Wir haben übrigens gesehen, daß dieses Gesetz \zB~auch für
die Absterbeordnung, trotzdem hierbei nicht eine einfache Verteilung
vorliegt, erfüllt ist.

Wenn eine Verteilungsreihe symmetrisch ist, so fällt der
Durchschnittswert mit dem Zentralwert und, wenn ein solcher
vorhanden, auch mit dem Normalwert zusammen. Es ist noch
\DPPageSep{096}{82}
wichtig, für die Fälle, wo die Verteilung asymmetrisch oder, wie
man sagen kann, \so{schief} ist, ein bestimmtes \so{Maß für die
Schiefe} zu besitzen. Zu einem solchen Maß gelangt man, indem
man den Abstand des Normalwertes vom Durchschnittswert einführt.
Nennt man diesen Abstand~$d$, so würde $d$ in gewissem
Sinne ein Maß für die Schiefe geben. Dieses Maß ist aber ein
lineares und nicht unmittelbar bei den verschiedenen Verteilungsreihen
zu vergleichen. Man kann deshalb ein absolutes Maß für
die Schiefe ableiten, indem man $d$ mit der mittleren Ausweichung~$\mu$
vergleicht. Es wird dann $d/\mu$ ein absolutes Maß für
die Schiefe.

Als Beispiel wollen wir die Verteilungsfunktion
\[
z = z_0e^{-\tfrac{y}{d}}, \quad 0 < y < \infty
\]
(Beispiel einer einseitigen Dispersion) nehmen. Dann ergibt sich
für das arithmetische Mittel:
\[
y_0 = \frac
  {\Int_{0}^{\infty} z_0 e^{-\tfrac{y}{d}} y\, dy}
  {\Int_{0}^{\infty} z_0 e^{-\tfrac{y}{d}}\, dy}
  = d.
\]

Als Normalwert hat in diesem Falle der Wert $y = 0$ zu
gelten, weil für ihn die Verteilungsfunktion den größten Wert
erreicht; $d$~ist also in der Tat der Abstand des Normalwertes
vom Durchschnittswert. Ferner findet man für die mittlere Abweichung~$\mu_0$
vom Anfangswert~$y = 0$:
\[
\mu_0^2 = \frac
  {\Int_{0}^{\infty} z_0 e^{-\tfrac{y}{d}} y^2\, dy}
  {\Int_{0}^{\infty} z_0 e^{-\tfrac{y}{d}}\, dy}
  = 2d^2
\]
und damit für die mittlere Abweichung vom arithmetischen Mittel,
\dh~die mittlere Ausweichung:
\[
\mu^2 = \mu_0^2 - d^2 = d^2,
\]
so daß sich in diesem Falle ergibt:
\[
\frac{d}{\mu} = 1.
\]
\DPPageSep{097}{83}

Eine besondere Auffassung der stationären Reihen kommt
dann zur Geltung, wenn ihre Glieder die verschiedenen beobachteten
Werte einer physikalischen Größe bedeuten. Die Abweichungen
der verschiedenen Werte voneinander führt man bekanntlich
darauf zurück, daß bei den einzelnen Beobachtungen
Fehler gemacht worden sind. Man glaubt in allen diesen Fällen an
die Existenz eines wahren Wertes, dem die beobachteten Werte
mehr oder weniger nahe kommen. Was der wahre Wert unabhängig
von den gemachten Beobachtungen bedeutet, bleibt allerdings zu
beantworten. Die Gewißheit seiner Existenz schöpft man erstlich
aus der Überzeugung von der Unveränderlichkeit des Gegenstandes,
auf den sich die Beobachtungen beziehen, wenigstens während der
Dauer dieser Beobachtungen. Sodann liegt aber auch ein über die
bloße Erfahrung hinausgehendes Urteil zugrunde, das uns die
von unseren Beobachtungen, \dh~von unseren Wahrnehmungen
unabhängige Existenz der Naturobjekte behaupten läßt. Wir gelangen
hiermit jedoch auf das unwegsamste Gebiet der ganzen
Naturphilosophie. Die Frage, um die es sich handelt, läßt sich
mit kurzen Worten gar nicht abmachen, weil sie wesentlich davon
abhängt, was man unter Existenz versteht. Darin sind die Auffassungen
sehr verschieden. Wir können aber die Betrachtung so
führen, daß der metaphysische Einschlag möglichst vermieden wird.
Dies läßt sich auf folgende Weise erreichen.

Das arithmetische Mittel der beobachteten Werte, für das die
Abweichung der Beobachtungsreihe am kleinsten wird, bedeutet
den Wert, der dem durch die Beobachtungen erhaltenen Resultate
so nahe kommt, wie nur möglich, und den man als den zusammenfassenden
Ausdruck der Beobachtungen ansehen kann.

Wenn die Beobachtungen nun mehr und mehr gehäuft
werden, so nähert sich das arithmetische Mittel mehr und mehr,
wie man annimmt, einer bestimmten Grenze, und als diese Grenze
läßt sich der "`wahre Wert"' festlegen. Derart würde der wahre
Wert nicht als etwas, was unabhängig von den Beobachtungen
existiert, wohl aber als ein auf den wirklich gemachten Beobachtungen
aufgebauter Idealwert erscheinen, dem man näher und
näher kommen kann, je mehr man die Beobachtungen häuft, ohne
ihn je mit Sicherheit zu erreichen. Im mathematischen Sinne
würde er also, wenn die Beobachtungen als eine beliebig weit
fortsetzbare Reihe angesehen werden, den Grenzwert bedeuten,
\DPPageSep{098}{84}
dem sich das arithmetische Mittel aus den Gliedern dieser Reihe
bei unbegrenzt wachsender Gliederzahl nähert.

Wir können daher in bekannter Symbolik den so gebildeten
Wert, wenn wieder $y_1,~y_2,~\ldots$ der Reihe nach die beobachteten
Werte sind, mit
\[
y = \lim_{N = \infty} \frac{y_1 + y_2 + \dots + y_N}{N}
\]
bezeichnen. Wir können auch die beobachteten Werte immer zu
einer bestimmten Zahl, etwa~$r$, aufeinander folgender Werte zusammenfassen
und das arithmetische Mittel dieser Gruppen aufeinander
folgender Werte nehmen. So würde sich, wenn
\[
u_{\rho}' = \Sum_i \frac{y_{\rho r + i}}{r}
\]
das arithmetische Mittel für die $\rho$te~Wertegruppe ist, unmittelbar
ergeben, daß auch
\[
y = \lim_{\nu = \infty} \frac{y_0' + y_1' + \dots + y_{\nu}'}{\nu + 1}
\]
wird. Der wahre Wert ist auch der Grenzwert für das arithmetische
Mittel der neuen Zahlenreihe. Die durch die Mittelbildung
aus $r$ Beobachtungen erreichte engere Annäherung an den wahren
Wert gibt sich dadurch zu erkennen, daß die mittlere Ausweichung
der neuen Zahlenreihe kleiner ist als die der ursprünglichen.

Wenn die Beobachtungen außerordentlich gehäuft werden, so
wird sich jeder der beobachteten Werte (der natürlich nur mit
beschränkter Genauigkeit bestimmt werden kann) eine größere
Anzahl Male wiederfinden. Wir werden aber, falls sich eine regelmäßige
Verteilung der beobachteten Werte ergibt, für den jenem
unmittelbar benachbarten Wert annähernd die gleiche Häufigkeit
finden müssen. Es ist also die Häufigkeit des Vorkommens eines
Wertes $\eta$ zwischen zwei Grenzen, wenn diese Grenzen sehr nahe
benachbart sind, dem Intervall~$d\eta$ zwischen ihnen proportional,
und wir können die relative Häufigkeit eines Wertes~$\eta$ in einem
solchen Intervall in der Form
\[
\psi(\eta)\, d\eta
\]
ansetzen, wo $\psi(\eta)$ eine bestimmte Funktion von~$\eta$, die \so{Häufigkeitsfunktion},
bezeichnet.
\DPPageSep{099}{85}

Da der Wert~$\eta$ zwischen den Grenzen $-\infty$~und~$+\infty$ liegen
muß, wird die relative Häufigkeit hierfür
\[
\Tag{(12)}
\Int_{-\infty}^{+\infty} \psi(\eta)\, d\eta = 1.
\]

Nach unserer Voraussetzung ist der wahre Wert~$y$ gegeben
durch das arithmetische Mittel aller Werte~$\eta$, also durch das
Integral
\[
\Tag{(13)}
y = \Int_{-\infty}^{+\infty} \eta\psi(\eta)\, d\eta.
\]

Bilden wir nun die Differenzen
\[
x = \eta - y,
\]
die wir als den \so{Fehler} der einzelnen Beobachtung bezeichnen, so
zeigt sich sofort, daß, wenn wir $\psi(\eta) = \psi(y + x) = \phi(x)$
setzen,
\[
\psi(\eta)\, d\eta = \phi(x)\, dx
\]
wird. Wir erhalten weiter
\[
\Tag{(14)}
\Int_{-\infty}^{+\infty} \phi(x)\, dx = 1
\quad\text{und}\quad
\Int_{-\infty}^{+\infty} x\phi(x)\, dx = 0.
\]
Ferner soll noch eine Größe $\mu$ durch die Gleichung
\[
\Tag{(15)}
\mu^2 = \Int_{-\infty}^{+\infty} x^2 \phi(x)\, dx
\]
eingeführt werden. Diese Größe bedeutet, da ja $x = \eta - y$, die
mittlere Abweichung der Werte~$\eta$ von dem "`wahren Wert"' und
heißt der \so{mittlere} (quadratische) \so{Fehler}. Sie entspricht genau
der früher eingeführten mittleren Ausweichung.

Wir wollen nun noch fragen, was der Durchschnittswert für
das \so{Produkt}~$x·x'$ der Fehler zweier Beobachtungen wird. Für
die relative Häufigkeit eines bestimmten Wertes dieses Produktes
$X = x·x'$, \dh~eines Wertes, der zwischen den Grenzen $X$~und
$X + dX$ liegt, erhält man sofort das Integral
\[
\iint \phi(x)\phi(x')\, dx\, dx',
\]
wobei für $x$,~$x'$ alle Werte zu nehmen sind, für die der Wert von
$X = x·x'$ zwischen den Grenzen $X$~und~$X + dX$ liegt.
\DPPageSep{100}{86}

Dies bedeutet, wenn wir $x$,~$x'$ als rechtwinklige Koordinaten
eines Punktes in der Ebene deuten, daß das Integrationsgebiet
ein unendlich schmaler, zwischen zwei gleichseitigen Hyperbeln
\[
x' = \frac{X}{x},\qquad  x' = \frac{X + dX}{x}
\]
liegender Streifen ist. Dieser Streifen läßt sich aber auf andere
Weise in Flächenelemente zerlegen. Wir teilen ihn durch unendlich
benachbarte Ordinaten. Zwei solche schneiden dann ein
unendlich kleines Parallelogramm aus dem Streifen aus, von dem
die in den Streifen fallenden parallelen Seiten die Länge $\dfrac{dX}{x}$
und den Abstand~$d$x haben,
so daß der Inhalt dieses
Flächenelementes
\[
= \frac{dx}{x}\, dX
\]
wird\DPtypo{}{.} Damit verwandelt
sich das obenstehende Integral,
wenn wir darin
\[
x' = \frac{X}{x}
\]
einsetzen, in
\[
dX \int\phi(x) \phi\left(\frac{X}{x}\right) \frac{dx}{x}.
\]
%[** TN: Illustration inset in the original]
\begin{figure}[hbt!]
  \centering
  \caption{Fig.~6.}
  \Input[0.6\textwidth]{100}
\end{figure}

Setzen wir also die relative Häufigkeit der Fälle, wo $X$
zwischen $X$~und~$X + dX$ liegt,
\[
= \Phi(X)\, dX,
\]
so folgt
\[
\Phi(x)
  = \Int_{-\infty}^{+\infty} \phi(x) \phi\left(\frac{X}{x}\right) \frac{dx}{x}.
\]

Nun wird der Durchschnitt aller Werte~$X$ gegeben durch das
Integral
\[
\Int_{-\infty}^{+\infty} X\Phi(X)\, dX,
\]
\DPPageSep{101}{87}
wir erhalten dafür also den Wert
\[
\Int_{-\infty}^{+\infty} \Int_{-\infty}^{+\infty}
  X \phi(x) \phi\left(\frac{X}{x}\right) \frac{dx}{x}\, dX
\]
oder, indem wir in diesem über die ganze Ebene zu erstreckenden
Doppelintegral wieder die ursprünglichen Flächenelemente einführen,
\[
\Int_{-\infty}^{+\infty} \Int_{-\infty}^{+\infty}
  x · x' \phi(x) · \phi(x')\, dx\, dx'.
\]
Es wird aber dieses Doppelintegral das Produkt zweier einfacher
Integrale:
\[
\Int_{-\infty}^{+\infty} x \phi(x)\, dx · \Int_{-\infty}^{+\infty} x'\phi(x')\, dx',
\]
und diese beiden Integrale sind~$0$, also auch ihr Produkt. \so{Der
Durchschnittswert des Produktes~$x·x'$ ist demnach~$0$.}

Wir wollen dies benutzen, um den Zusammenhang des
mittleren Fehlers~$\mu$ der direkten Beobachtungen~$y_i$ mit dem mittleren
Fehler~$\mu'$ der zu $r$ zusammengefaßten und zum Mittelwert~$y'_{\rho}$
vereinigten Beobachtungen zu suchen. Wir müssen, um
$\mu'^2$~zu erhalten, den Durchschnittswert bilden von
\[
\frac{1}{r^2} (x_1 + x_2 + x_3 + \dots + x_r)^2
\]
oder
\[
\frac{x_1^2}{r^2} + \frac{x_2^2}{r^2} + \dots +
\frac{x_r^2}{r^2} + \frac{2x_1 x_2}{r^2} + \dots.
\]
Die Durchschnittswerte der $n$ ersten Glieder sind aber alle
\[
\Int_{-\infty}^{+\infty} x^2 \phi(x)\, dx = \frac{\mu^2}{r^2}
\]
und die Durchschnittswerte der Produkte verschwinden, so daß
wir schließlich erhalten
\[
\mu'^2 = r·\frac{\mu^2}{r^2}
\]
oder
\[
\Tag{(16)}
\mu' = \frac{\mu}{\sqrt{r}}.
\]
\DPPageSep{102}{88}
Der mittlere Fehler ist also umgekehrt proportional der Quadratwurzel
aus der Anzahl der Beobachtungen, von denen man das
arithmetische Mittel nimmt.

Setzen wir nun aber
\[
\lambda_i = y_i - y_0,
\]
wobei $y_0 = \dfrac{1}{r}(y_1 + y_2 + \dots + y_r)$, so ergibt sich (da ja
$x_i = y_i - y = y_i - y_0 + y_0 - y$, wenn die Summation über
die $r$ zusammengefaßten Beobachtungen erstreckt wird,
\[
\Sum x_i^2 = \Sum \lambda_i^2 + r(y_0 - y)^2
\]
und daraus
\[
\Sum \lambda_i^2 = \Sum x_i^2 - r(y_0 - y)^2.
\]

Nehmen wir nun den Durchschnittswert, so ergibt sich für
das erste Glied der rechten Seite der Wert~$r·\mu^2$, für das zweite
Glied $r·\dfrac{\mu^2}{r} = \mu^2$, also wird der Durchschnittswert von~$\Sum\lambda_i^2$
\[
= (r - 1)\mu^2,
\]
und $\mu$ kann als der Durchschnittswert von
\[
\sqrt{\frac{\Sum \lambda_i^2}{r - 1}}
\]
angesehen werden. Sofern diese Größe von einer Beobachtungsserie
zur anderen sich wenig ändert, kann sie selbst für den
Wert~$\mu$ genommen, also
\[
\Tag{(17)}
\mu = \sqrt{\frac{\Sum \lambda_i^2}{r - 1}}
\]
gesetzt werden.

Wir wollen nun auch noch den Durchschnittswert des Ausdruckes
\begin{gather*}
\Tag{(18)}
\frakM = \frac{1}{r - 1} \bigl[
  (y_1 - y_2)^2 + (y_2 - y_3)^2 + (y_3 - y_4)^2 + \dots \\
  + (y_{r-1} - y_r)^2\bigr]
\end{gather*}
suchen. Wir können diesen Ausdruck schreiben
\[
\frakM = \frac{1}{r - 1} \bigl[
  (x_1 - x_2)^2 + (x_2 - x_3)^2 + \dots + (x_{r-1} - y_r)^2
\bigr]
\]
\DPPageSep{103}{89}
oder
\begin{align*}
\frakM
  &= \frac{1}{r - 1} (x_1^2 + 2x_2^2 + 2x_3^2 + \dots + x_r^2) \\
  &- \frac{2}{r - 1} (x_1x_2 + x_2x_3 + \dots + x_{r-1}x_r),
\end{align*}
und daraus folgt sofort für den Mittelwert
\[
2\mu^2.
\]

Ist also die Anzahl der Beobachtungen groß genug und die
Verteilung der beobachteten Werte derart, daß man den gefundenen
Wert mit dem Mittelwert identifizieren kann, so muß man, da
offenbar auch
\[
%[** TN: Broken across two lines in the original]
\frakM = \frac{1}{r-1} \bigl[
  (\lambda_1 - \lambda_2)^2 + (\lambda_2 - \lambda_3)^2 +
  (\lambda_3 - \lambda_4)^2 + \dots + (\lambda_{r-1} - \lambda_r)^2
\bigr]
\]
wird, zwischen diesem Ausdruck und dem Ausdruck
\[
\mu^2 = \frac{\lambda_1^2 + \lambda_2^2 + \dots + \lambda_r^2}{r - 1}
\]
die Beziehung finden
\[
\Tag{(19)}
\frakM = 2\mu^2,
\]
und die erste Quadratensumme muß das Doppelte von der zweiten
Quadratensumme sein.

Hiermit haben wir ein Kriterium, das \so{Abbesche Kriterium}\footnote
  {E.~\so{Abbe}, Dissertation, Werke Bd.~II, letzte Abhandlung. Vgl.\
\index{Abbe}%
  \so{Helmert}\DPtypo{}{,} Sitzungsberichte der Kgl.\ Preußischen Akademie der Wissenschaften
\index{Helmert}%
  1905, S.~594, der zeigt, daß sowohl die Vorzeichensumme der
  Abweichungen $\lambda_i$ gleich $0$ wie der Ausdruck $\dfrac{\frakM}{2\mu^2}$ gleich $1$ wird mit
  einem mittleren Fehler, der der Quadratwurzel aus der Anzahl der
  Beobachtungen gleich ist.},
gefunden, das sich sehr leicht anwenden läßt. Dieses
Kriterium gilt dafür, daß die Werte der stationären Reihe dieselbe
Verteilung zeigen, die sich bei wiederholten, gleich sorgfältigen
Beobachtungen derselben physikalischen Größe ergibt, wo
in der Tat angenommen werden kann, daß bei genügender Häufung
der Beobachtungen die idealen Mittelwerte mit großer Annäherung
erreicht werden. Insofern die bei solchen Beobachtungsreihen
entstehende Verteilung die typische Verteilung ist, die da
\DPPageSep{104}{90}
entsteht, wo die Abweichungen der einzelnen Werte der Reihe
voneinander auf bloßen Zufälligkeiten beruhen, kann des Kriterium
auch direkt als Zufallskriterium bezeichnet werden.

Wir wollen es noch an einem Beispiel bestätigen. Wir nehmen
dafür die früher (S.~30) als Produkte zweier beobachteten Größen
gefundenen Zahlenwerte für die Konstante im \so{Boyle}schen
(\so{Mariotte}schen) Gesetz, so daß die Werte der stationären Reihe
jetzt sind
\begin{gather*}
y_1 = 1531,\ y_2 = 1547,\ y_3 = 1531,\ y_4 = 1520,\ y_5 = 1518, \\
y_6 = 1541,\ y_7 = 1530,\ y_8 = 1535.
\end{gather*}
Der Durchschnittswert ist rund 1532, wir finden also
\begin{gather*}
\lambda_1 = -1,\ \lambda_2 = +15,\ \lambda_3 = -1,\ \lambda_4 = -12,\ \lambda_5 = -14, \\
\lambda_6 = +9,\ \lambda_7 = -2,\ \lambda_8 = +3.
\end{gather*}

Nun ist ein erstes Mittel, um zu beurteilen, ob diese Abweichungen
auf Rechnung des Zufalls gesetzt werden können, die
Untersuchung, ob sie eine symmetrische Verteilung zeigen. Man
kann sich hierbei darauf beschränken, festzustellen, ob der Durchschnittswert
mit dem Zentralwert ungefähr zusammenfällt. Der
Durchschnittswert der Zahlen~$\lambda$ ist aber $0$ (wegen der Abrundung
bei den obenstehenden Zahlen~$-0,~4$). Soll nun auch der Zentralwert~$0$
sein, so müssen unter den $\lambda$ ebensoviel positive wie negative
sein. Wir können die sich so ergebende Regel fassen wie folgt:
Man ersetze alle positiven~$\lambda$ durch den Wert~$+1$, alle negativen
durch~$-1$, diejenigen, welche $0$ sind, lasse man gleich~$0$, dann
muß die algebraische Summe dieser Werte klein im Verhältnis zu
der Anzahl der Beobachtungen sein. Im vorliegenden Falle haben
wir fünf negative und drei positive Werte, würden also statt~$0$
den Wert~$-2$ erhalten, was klein genug ist.

Bilden wir jetzt die mittlere Ausweichung nach der Formel~\Eqref{(17)},
so erhalten wir
\[
2\mu^2 = 2·\frac{661}{7} = 189.
\]
Ferner wird
\[
\frakM = \frac{1}{7}(16^2 + 16^2 + 11^2 + 2^2 + 23^2 + 11^2 + 5^2)
\]
oder
\[
\frakM = 187.
\]
Die Übereinstimmung zwischen den Werten $2\mu$~und~$\frakM$ ist so
gut, wie man nur wünschen kann.
\EndChap
\DPPageSep{105}{91}


\Chapter{Siebentes Kapitel}{Das Urnenschema}

Wir gehen nun den Weg, daß wir einen besonderen Fall von
stationären Zahlenreihen ins Auge fassen. In diesem Falle sollen
die beobachteten Werte relative Häufigkeiten gleichartiger Ereignisse
sein. Um aber ein bestimmtes Bild vor Augen zu haben,
denken wir uns eine Urne, in der schwarze und weiße Kugeln
gemischt enthalten sind und aus der eine bestimmte, sehr große
Anzahl Male hintereinander eine Kugel gezogen wird, die jedesmal
nach der Ziehung zurückgelegt wird. Das Verhältnis der Anzahl der
gezogenen weißen Kugeln zu der Anzahl der gemachten Ziehungen
überhaupt ergibt dann die aufzuzeichnende relative Häufigkeit.
Wir können es dabei als eine Erfahrungstatsache ansehen, daß
diese Verhältniszahl annähernd mit dem Verhältnis der in der
Urne enthaltenen weißen Kugeln zu der Gesamtzahl der überhaupt
vorhandenen Kugeln übereinstimmt. Wir können auch, wenn das
einfacher scheint, diese Behauptung so wenden, daß wir zunächst
von einer Urne ausgehen, in der die Kugeln einzeln, etwa mit
Zahlen, bezeichnet sind. Die Behauptung lautet dann so, daß bei
einer großen Anzahl von Ziehungen die verschiedenen Kugeln annähernd
gleich oft erscheinen, falls beim Ziehen gewisse Vorsichtsmaßregeln
(stets erneutes, gründliches Durcheinanderschütteln usw.)
beobachtet werden. (Die Behauptung geht sogar noch weiter, die
Anzahlen der Ziehungen für die verschiedenen Kugeln sollen um
so genauer einander relativ gleich werden, je größer ihre absoluten
Werte sind.) Die relative Häufigkeit wird sonach für die einzelnen
Kugeln, wenn $s$ Kugeln in der Urne enthalten sind, annähernd
gleich~$\dfrac{1}{s}$, und wenn darunter $r$ weiß gefärbt sind, wird die relative
Häufigkeit der Ziehung einer weißen Kugel annähernd gleich~$\dfrac{r}{s}$,
also gleich dem Mischungsverhältnis.
\DPPageSep{106}{92}

Fassen wir nun die relativen Häufigkeiten ins Auge, die bei
einer Serie von Ziehungsgruppen (zu je $n$~Ziehungen) tatsächlich
gefunden sind, so können wir von vornherein sagen, daß die so
gefundenen Werte, weil sie keine systematische Veränderung zeigen,
sich vielmehr alle mehr oder weniger dem Mischungsverhältnis der
Kugeln nähern, in dem früher erörterten Sinne eine stationäre
Reihe bilden.

Ist das Mischungsverhältnis also nicht bekannt, so liefert die
Bestimmung der relativen Häufigkeit der gezogenen weißen Kugeln
bei einer Serie von Ziehungsgruppen, deren jede eine große Anzahl
von Ziehungen umfaßt, ein Mittel, den Wert des Mischungsverhältnisses
wenigstens angenähert zu finden. Es sei eine Serie
von $m$ mal $n$ Beobachtungen angestellt und es seien hierbei
\[
w_1 = \frac{p_1}{n},\quad
w_2 = \frac{p_2}{n},\quad
\dots,\quad
w_m = \frac{p_m}{n}
\]
die bei den einzelnen Beobachtungsgruppen gefundenen relativen
Häufigkeiten. Diese bilden die Elemente der stationären Reihen,
um die es sich handelt. Der Durchschnittswert aber, um den sich
die Werte der Reihe gruppieren, wird:
\[
w = \frac{w_1 + w_2 + \dots + w_m}{m}
  = \frac{p_1 + p_2 + \dots + p_n}{m·n},
\]
er ist demnach nichts anderes als die relative Häufigkeit, die sich
ergibt, wenn wir direkt die relative Häufigkeit für die Gesamtheit
aller angestellten Beobachtungen bilden. Denken wir uns nun die
Beobachtungen weiter fortgesetzt, so daß wir neue Ziehungsserien
von je $m·n$~Ziehungen erhalten, dann bilden die aus diesen
folgenden relativen Häufigkeiten eine neue stationäre Reihe, von der
wir allgemein gezeigt haben, daß die Abweichung ihrer Werte voneinander
geringer ist als die der ursprünglichen Reihe. So können
wir noch weiter fortfahren, die gefundenen Reihen werden sich
dann immer enger um einen bestimmten Mittelwert zusammenziehen.
Es zeigt sich also, daß man einem bestimmten Wert
näher und näher kommt, der mit der beobachteten relativen
Häufigkeit um so genauer zusammenfällt, je größer die Anzahl
der beobachteten Fälle ist. Daß der so ermittelte Wert
das wirkliche Mischungsverhältnis der Kugeln in der Urne ist,
kommt nicht unmittelbar in Betracht. Dieser Wert, den wir
\DPPageSep{107}{93}
als Idealwert oder Grenzwert einer relativen Häufigkeit erhalten,
ist derselbe, der sonst als mathematische Wahrscheinlichkeit
bezeichnet wird. In dem hier angegebenen Sinne wurde der Begriff
vielleicht zum erstenmal von \so{Gauss} eingeführt (Theoria
\index{Gauß}%
combinationis observationum erroribus minimis obnoxiae 1821,
Werke, Bd.~IV, S.~5) und durch den Ausdruck \so{facilitas relativa}
bezeichnet. In der weiteren Darstellung gebraucht er jedoch durchweg
den gewöhnlicheren Ausdruck probabilitas und wir könnten
ebenso die Bezeichnung Wahrscheinlichkeit verwenden. Es scheint
aber doch besser, in dieser kurzen Darstellung, die nur das erkenntnistheoretische
Problem, nicht aber die weiteren Ausführungen
zu behandeln hat, um alle Mißverständnisse gegenüber der sonst
üblichen Definition der Wahrscheinlichkeit auf Grund der "`gleich
möglichen Fälle"' zu vermeiden, überall den Ausdruck "`relative
Häufigkeit"' zu verwenden, trotzdem dieser dann auch über seine
ursprüngliche Bedeutung hinaus eine besondere Prägung als
Kunstausdruck erhält. Wir müssen im folgenden immer die
Anzahl der Ziehungen so groß voraussetzen, daß die erreichte
Annäherung an den Idealwert als hinreichend angesehen werden
kann.

Die Ziehung aus einer Urne läßt sich als Typus eines \so{einfachen}
Ereignisses ansehen. Wollen wir uns nun ein \so{zusammengesetztes}
Ereignis bilden, so denken wir uns zwei Urnen. Zuerst
wird aus der ersten Urne gezogen und nur, wenn hierbei eine weiße
Kugel gefunden ist, wird auch aus der zweiten Urne gezogen. Daß
hierbei wieder eine weiße Kugel gefunden wird, wird als das Eintreten
des in Betracht gezogenen zusammengesetzten Ereignisses
angesehen. Es fragt sich dann, ob die relative Häufigkeit dieses
zusammengesetzten Ereignisses sich aus den relativen Häufigkeiten
der Einzelereignisse ableiten läßt. Zu diesem Zweck denken wir
uns wieder eine Serie von Ziehungsgruppen. Wir nehmen zunächst
an, es sei $n$\,mal aus der ersten Urne gezogen worden. Nur bei
einem Teil dieser Ziehungen, etwa $p$ Ziehungen, ist dann eine weiße
Kugel gezogen worden, und in einem Teil dieser Fälle, etwa bei
$q$ Ziehungen, sei auch aus der zweiten Urne eine weiße Kugel gezogen
worden. Die relative Häufigkeit des zusammengesetzten
Ereignisses ist dann
\[
w = \frac{q}{n}.
\]
\DPPageSep{108}{94}

Die relative Häufigkeit der Ziehung einer weißen Kugel aus
der ersten Urne wird aber
\[
w_1 = \frac{p}{n},
\]
und die relative Häufigkeit der Ziehung einer weißen Kugel aus
der zweiten Urne wird
\[
w_2 = \frac{q}{p},
\]
man findet also
\[
\Tag{(1)}
w = w_1·w_2,
\]
\dh~die \so{relative Häufigkeit des zusammengesetzten Ereignisses
ist das Produkt aus den relativen Häufigkeiten
der Einzelereignisse}.

Wir müssen aber beachten, welche Voraussetzung hierbei gemacht
worden ist. Durch die Ziehungen aus der ersten Urne
werden bestimmte Fälle, die durch das Finden einer weißen Kugel
gegeben sind, herausgegriffen. Nur in diesen Fällen wird aus
der zweiten Urne gezogen und die relative Häufigkeit für diese
Ziehungen notiert. Liegt nun der Fall ebenso, als ob unabhängig
von der ersten Urne aus der zweiten Urne gezogen worden wäre?
Man wird die Frage hier unbedingt bejahen, sie wird sogar als
gänzlich überflüssig erscheinen. Ihre Entscheidung bedeutet aber
eine bestimmte Aussage über die beiden Einzelereignisse, aus
denen sich das Gesamtereignis zusammensetzt, nämlich die Aussage
darüber, daß \so{die durch die erste Urne getroffene Bestimmung
über die Ziehung aus der zweiten Urne keinen
Einfluß auf die Resultate der Ziehungen aus dieser
zweiten Urne ausübt}, daß mit anderen Worten \so{die beiden
Einzelereignisse voneinander unabhängig sind}.

Die gleiche Überlegung bleibt natürlich auch dann bestehen,
wenn das Gesamtereignis sich aus mehr als zwei Einzelereignissen
zusammensetzt. Wir können daher allgemein sagen:

\so{Die relative Häufigkeit eines aus mehreren Komponenten
zusammengesetzten Ereignisses ist gleich dem
Produkt aus den relativen Häufigkeiten seiner Komponenten,
wenn diese voneinander unabhängig sind.}

Ein Ereignis kann aber noch auf eine andere Art aus Teilereignissen
zusammengesetzt sein. Nehmen wir \zB~an, das Ereignis
\DPPageSep{109}{95}
bestände darin, daß mit einem Würfel mehr als drei Augen
geworfen werden. Dann setzt sich dieses Ereignis sofort aus drei
Teilereignissen zusammen. Es können nämlich mit dem Würfel
entweder vier oder fünf oder sechs Augen geworfen sein. In allen
drei Fällen ist das Ereignis eingetreten. Nehmen wir nun an, es
sei allgemein $n$ die Gesamtzahl der Fälle. Dabei seien die Teilereignisse
der Reihe nach $p$-,~$q$-,~$r$\,mal eingetreten, dann ist das Gesamtereignis
$(p + q + r)$\,mal eingetreten. Die relative Häufigkeit
des Gesamtereignisses wird also
\[
w = \frac{p + q + r}{n}
  = \frac{p}{n} + \frac{q}{n} + \frac{r}{n}.
\]
Die relativen Häufigkeiten der Teilereignisse sind aber
\[
w_1 = \frac{p}{n},\quad
w_2 = \frac{q}{n},\quad
w_3 = \frac{r}{n}.
\]
Es ergibt sich demnach
\[
\Tag{(2)}
w = w_1 + w_2 + w_3,
\]
und wir können allgemein den Satz aussprechen:

\so{Wenn bei einem Ereignis verschiedene Fälle möglich
sind, die alle das Eintreten des Ereignisses bedeuten, so
ergibt die Summe der relativen Häufigkeiten aller dieser
Fälle die relative Häufigkeit des betrachteten Ereignisses
selbst.}

Bei jedem Ereignis sind aber immer von vornherein zwei
Fälle zu unterscheiden, die durch das Eintreten und das Ausbleiben
des Ereignisses gegeben sind. Das Eintreten und das Ausbleiben
eines Ereignisses setzen sich jedoch zu einem Ereignis zusammen,
das in allen Fällen eintritt, dessen relative Häufigkeit also gleich
$1$ ist. Nennen wir daher w die relative Häufigkeit des Eintretens
und $w'$ die relative Häufigkeit des Ausbleibens, so muß
\[
w + w' = 1
\]
werden, es ergibt sich also die relative Häufigkeit des Ausbleibens
eines Ereignisses aus der relativen Häufigkeit~$w$ seines Eintretens
durch die Gleichung
\[
w' = 1 - w.
\]

Wir benutzen die angestellten Überlegungen nun, um die
relative Häufigkeit des mehrmaligen Eintretens eines Ereignisses
in einer gewissen Anzahl von Fällen zu bestimmen. Wenn das
\DPPageSep{110}{96}
Ereignis in $n$ Fällen $p$\,mal eintreten soll, so müssen wir zunächst
dabei eine bestimmte Folge des Eintretens und Ausbleibens ins
Auge fassen. Es handelt sich dann um ein Ereignis, das aus
$n$ unabhängigen Teilereignissen besteht. Diese Teilereignisse sind
das Eintreten oder Ausbleiben des betrachteten Erfolges im ersten,
zweiten, dritten usw. Falle. Nach unserem Satze ist die relative
Häufigkeit des Gesamtereignisses das Produkt aus den relativen
Häufigkeiten der Teilereignisse, und von diesen n Faktoren sind $p$
gleich~$w$, wenn wir mit~$w$ die relative Häufigkeit des Einzelereignisses
bezeichnen, von der wir voraussetzen, daß sie sich von
Fall zu Fall nicht ändert, die übrigen $n - p$~Faktoren dagegen
werden gleich~$1 - w$. Wir finden also für die relative Häufigkeit
des Gesamtereignisses den Wert
\[
w^p(1 - w)^{n-p}.
\]

Nun soll aber die Reihenfolge, in welcher der betrachtete Erfolg
eintritt oder ausbleibt, für das in Wirklichkeit betrachtete
Gesamtereignis (das $p$\,malige Eintreten des betrachteten Erfolges
in $n$~Fällen) gleichgültig sein. Wir müssen also alle diese verschiedenen
Reihenfolgen als verschiedene mögliche Fälle, in denen
das in Rede stehende Ereignis eintritt, ansehen und finden die
relative Häufigkeit dieses Ereignisses als die Summe der relativen
Häufigkeiten, die sich für die einzelnen möglichen Reihenfolgen
ergeben, \dh,~da diese relativen Häufigkeiten alle gleich sind, als
das Produkt ihres Wertes mit der Anzahl der Arten, auf die sich
aus $n$~Elementen~$p$ herausgreifen lassen. Diese Anzahl ist
\[
\frac{1·2·3·4·5 \dots n}{1·2 \dots p·1·2 \dots (n - p)}
  = \frac{n!}{p!(n - p)!},
\]
wenn wir in der üblichen Weise
\[
1·2·3 \dots n = n!
\]
setzen, und damit finden wir für die gesuchte relative Häufigkeit
den Wert
\[
\Tag{(3)}
\frac{n!}{p!(n - p)!}\, w^p(1 - w)^{n-p}.
\]

Dieser Wert ist, wie man sieht, einerseits eine einfache Funktion
der relativen Häufigkeit~$w$, andererseits hängt er in bestimmter
Weise von der Zahl~$p$ ab und wir wollen ihn deswegen mit
\[
\phi_p(w) \text{ oder kürzer } \phi_p
\]
bezeichnen.
\DPPageSep{111}{97}

Bei der Bestimmung des vorstehenden Ausdruckes ist zu bedenken,
daß der Wert~$w$ nie mit absoluter Genauigkeit, sondern
immer nur mit einer gewissen Annäherung gefunden werden kann.
Wir wollen nun untersuchen, welchen Einfluß eine kleine Abweichung~$\delta w$
im Werte von~$w$ auf die Bestimmung des Wertes~$\phi_p$
ausübt. Die der Abweichung~$\delta w$ entsprechende Änderung dieses
Wertes wird
\begin{align*}
\delta\phi_p
  &= \frac{n!}{p!(n - p)!}\, w^p(1 - w)^{n-p}
       \left(\frac{p}{w} - \frac{n - p}{1 - w}\right) \delta w \\
  &= \phi_p \left(\frac{p}{w} - \frac{n - p}{1 - w}\right) \delta w.
\end{align*}
Diese Änderung darf nur einen Bruchteil von $\phi_p$ ausmachen, damit
die Bestimmung von $\phi_p$ überhaupt einen Sinn hat. Wir fragen
also, wann
\[
\delta\phi_p < \epsilon·\phi_p
\]
wird, wo $\epsilon$ einen bestimmten echten Bruch bedeutet, und finden
zunächst, daß dann dem absoluten Betrage nach
\[
\left(\frac{p}{w} - \frac{n - p}{1 - w}\right) \delta w < \epsilon
\]
sein muß, woraus sich, indem wir die Werte
\[
u = \frac{p}{n},\quad
1 - u = \frac{n - p}{n}
\]
einsetzen, ergibt:
\[
\left(\frac{u}{w} - \frac{1 - u}{1 - w}\right) n\, \delta w < \epsilon
\]
oder
\[
\frac{u - w}{w(1 - w)}\, n\, \delta w < \epsilon.
\]
Nehmen wir für $\delta w$ die größte zu befürchtende Schwankung in
der Bestimmung von~$w$, so folgt für die zugehörigen Grenzen des
Wertes~$u$
\[
u - w < \frac{w(1 - w)}{n\, \delta w} \epsilon
\]
dem absoluten Betrage nach, oder
\[
p - nw < \frac{w(1 - w)}{\delta w}\, \epsilon.
\]
\DPPageSep{112}{98}
Nur wenn diese Bedingung für einen nicht zu großen Wert des
echten Bruches~$\epsilon$, also sicher auch die Bedingung
\[
p - nw  <  \frac{w(1 - w)}{\delta w}
\]
erfüllt ist, kann von einer Bestimmung des Wertes~$\phi_p$ die Rede
sein. Es ergibt sich also eine gewisse Grenze für die Abweichung
des Wertes~$p$ von dem "`Normalwert"'~$nw$, die überhaupt zulässig
ist. Das ist für alles Folgende wichtig zu beachten.

Nehmen wir nun die Reihe der Werte~$\phi_p$, welche die Häufigkeit
des Vorkommens eines bestimmten Wertes $\dfrac{p}{n} = u$ angeben,
so fragt es sich, welcher Art diese Zahlenreihe ist, wenn wir von
der Annahme eines festen Wertes~$w$ ausgehen. Es zeigt sich sofort,
daß die Reihe in dem früher (S.~79) angegebenen Sinne einen
\so{einfachen Verlauf} hat. Bilden wir nämlich den Ausdruck
\[
\frac{\Delta \phi_p}{\phi_p}
  = \frac{\phi_{p+1} - \phi_p}{\phi_p}
  = \frac{n - p}{p+1}·\frac{w}{1 - w} - 1
  = \frac{(n + 1)w - (p + 1)}{(p + 1)(1 - w)},
\]
so geht dieser durch Null hindurch, wenn mit möglichster Annäherung
\[
\frac{n - p}{p + 1} = \frac{1 - w}{w}
\]
oder
\[
\frac{p + 1}{n + 1} = w
\]
wird. Auf der einen Seite von diesem Werte ist der Ausdruck
von $\dfrac{\Delta \phi_p}{\phi_p}$ beständig positiv und nimmt mit $p$ zu, auf der anderen
Seite wird er negativ und nimmt ebenfalls mit $p$ zu, \dh~dem
absoluten Werte nach ab; es wird nämlich
\[
\frac{\Delta \phi_p}{\phi_p} - \frac{\Delta \phi_{p+1}}{\phi_{p+1}}
  = \frac{n + 1}{(p + 1)(p + 2)}\, \frac{w}{1 - w}
\]
beständig positiv, die Werte von $\phi_p$ nehmen also vom Höchstwert
aus nach beiden Seiten ab, wie \Fig{5} angibt.
\DPPageSep{113}{99}

Auf eine andere Weise untersuchen wir die aus dem Ausdruck~$\phi_p$
folgende Zahlenreihe, indem wir die Summen
\[
\Sum_0^n \phi_p,\quad
\Sum_0^n p\phi_p,\quad
\Sum_0^n p^2\phi_p
\]
bilden. Was zunächst die erste angeht, so ergibt sich aus
\[
1 = \bigl[w + (1 - w)\bigr]^n
  = \Sum_{p=0}^n \frac{n!}{p!(n - p)!}\, w^p(1 - w)^{n-p}
\]
sofort
\[
\Sum_0^n \phi_p = 1.
\]
Für das allgemeine Glied der zweiten Summe finden wir dagegen
\begin{align*}
p·\phi_p
  &= \frac{n!}{(p - 1)!(n - p)!}\, w^p(1 - w)^{n-p} \\
  &= nw·\frac{(n - 1)!}{(p - 1)!(n - p)!}\, w^{p-1}(1 - w)^{n-p}
\end{align*}
und daraus folgt, indem wir die Werte, die aus $\phi_p$ hervorgehen,
wenn man $n - 1$ statt $n$ nimmt, mit $\phi'_p$ bezeichnen,
\[
p·\phi_p = nw·\phi'_{p-1};
\]
es wird also
\[
\Sum_0^n p·\phi_p = nw·\Sum_0^{n-1} \phi'_{p-1}
\]
und damit
\[
\Tag{(4)}
\Sum_0^n p·\phi_p = n·w.
\]
Weiter ergibt sich:
\begin{align*}
p^2·\phi_p
  &= \frac{n!}{(p - 2)!(n - p)!}\, w^p(1 - w)^{n-p} \\
  &+ \frac{n!}{(p - 1)!(n - p)!}\, w^p(1 - w)^{n-p} \\
  &= n(n - 1) w^2·\phi''_{p-2} + nw·\phi'_{p-1},
\end{align*}
indem wir den Ausdruck, der aus $\phi_p$ hervorgeht, wenn man $n - 2$
statt $n$ nimmt, mit $ßphi''_p$ bezeichnen, und damit erhalten wir
\[
\Sum p^2·\phi_p = n(n - 1) w^2·\phi''_{p-2} + nw·\Sum \phi'_{p-1};
\]
\DPPageSep{114}{100}
da aber $\Sum \phi'_{p-1} = 1$, $\Sum \phi''_{p-2} = 1$, folgt hieraus:
\[
\Tag{(5)}
\Sum p^2·\phi_p = n(n - 1) w^2 + nw.
\]

Diese Resultate lassen sich verwerten, um die registrierten
Werte $p$ nach der im vorigen Kapitel angegebenen Methode als
die Glieder einer \so{stationären} Reihe zu untersuchen. Die Anzahl
der insgesamt aufgezeichneten Werte sei~$N$. Der Wert~$p$
findet sich dann $\phi_p·N$\,mal, und wenn wir die Summe aller aufgezeichneten
Werte bilden, so ergibt sich
\[
\Sum \phi_p N · p = N \Sum p · \phi_p = N · nw;
\]
das arithmetische Mittel aller aufgezeichneten Werte wird also
\[
p_0 = n · w.
\]

Berechnen wir nun die Summe der Quadrate der Abweichungen
der aufgezeichneten Werte von diesem Mittelwert, so ergibt sich
dafür der Ausdruck
\[
\Sum \phi_p N · (p - p_0)^2
\]
und hierfür finden wir weiter:
\begin{align*}
  & N · \bigl[\Sum p^2 \phi_p - 2 nw \Sum p \phi_p + n^2 w^2\bigr] \\
 =& N · \bigl[n(n - 1)w^2 + nw - n^2w^2\bigr] = N · nw (1 - w).
\end{align*}
Der Mittelwert aller Abweichungen wird also
\[
\sqrt{nw(1 - w)}.
\]

Nehmen wir statt der Werte~$p$ selbst die Verhältniswerte~$\dfrac{p}{n}$,
so wird
\begin{align*}
&\Sum_0^n \frac{p}{n}·\phi_p = w
\intertext{und}
&\Sum_0^n \left(\frac{p}{n} - w\right)^2 · \phi_p = \frac{w(1 - w)}{n},
\end{align*}
also in diesem Falle die mittlere Ausweichung
\[
\Tag{(6)}
\mu = \sqrt{\frac{w(1 - w)}{n}}.
\]
\DPPageSep{115}{101}

Diese mittlere Ausweichung wird sonach um so kleiner, je
größer~$n$ ist.

Wenn aus einer Urne gezogen wird und sich hierbei unter $n$
Ziehungen $p$\,mal eine weiße Kugel findet, so könnte man diesen
Vorgang als typisch für alle Fälle ansehen, wo bei $n$ Proben
$p$\,mal der gewünschte Erfolg eintritt. Man kann daher versucht
sein, die aus diesem einfachen Urnenschema abgeleiteten Resultate
auf alle Fälle zu übertragen, in denen sich nichts weiter offenbart
hat, als daß ein bestimmter Erfolg $p$\,mal unter $n$\,malen eingetreten
ist. Der Schluß ist aber sehr gewagt und wird in den meisten
Fällen auch als irrig nachgewiesen, wenn man die relative Häufigkeit
nicht bloß einmal, sondern eine größere Anzahl Male bestimmt,
und dann versucht, die mittlere Ausweichung der so gewonnenen
stationären Reihe mit dem nach der obigen Formel sich ergebenden
Ausdruck zu vergleichen. Man kann für diese mangelnde Übereinstimmung
zunächst folgende Erklärung versuchen.

Bei dem Urnenschema ist man von vornherein gewiß, daß
die Bedingungen des Ereignisses, die durch das Mischungsverhältnis
der schwarzen und der weißen Kugeln in der Urne gegeben sind,
unverändert bleiben. Im allgemeinen Falle hat man diese Gewißheit
aber nicht. Man könnte nun diesen allgemeineren Fall an
das zuerst gegebene Urnenschema anschließen, indem man voraussetzt,
daß das Mischungsverhältnis der Kugel in der Urne wechselt,
oder besser noch, daß die Ziehungen nicht aus einer Urne,
sondern aus vielen Urnen mit verschiedenen Mischungsverhältnissen
stattfinden. Es ist dann die Frage, ob sich dadurch die
Verteilung der Anzahl Male, die ein bestimmtes Ziehungsverhältnis
bei einer großen Anzahl von Ziehungen herauskommt, wesentlich
ändert oder nicht.

Um diese Frage zu beantworten, nehmen wir an, es sei das
Mischungsverhältnis der weißen und schwarzen Kugeln bei der
$i$ ten Ziehung~$w_i/w'_i$, wobei immer $w_i + w'_i = 1$.

Bilden wir nun das Produkt
\[
\Prod_i(w_i\xi + w'_i\eta) = \Sum_p \psi_p \xi^p \eta^{n-p},
\]
über alle Ziehungen erstreckt, so gibt der Faktor~$\psi_p$ von~$\xi^p \eta^{n-p}$ in
diesem Ausdruck die relative Häufigkeit der Ziehung von $p$ weißen
Kugeln bei $n = p + q$ Ziehungen an. Dies ist sofort einzusehen,
\DPPageSep{116}{102}
weil das Entstehen eines Ziehungsverhältnisses, bei dem $p$ weiße
Kugeln $q$ schwarzen Kugeln gegenüberstehen, genau analog ist
dem Herausheben eines Gliedes mit $p$ Faktoren $\xi$~und $n - p = q$
Faktoren~$\eta$ bei der Ausrechnung des angeschriebenen Produktes.
So oft sich ein solches Glied ergibt, so oft ergibt sich auch bei
den aufeinanderfolgenden Ziehungen eine Kombination, bei der
gerade $p$ weiße und $q$ schwarze Kugeln gezogen sind.

Da die Summe aller dieser relativen Häufigkeiten gleich~$1$
sein muß, folgt für $\xi = \eta = 1$
\[
\Sum \psi_p\xi^p\eta^q = \Prod_i(w_i\xi + w'_i\eta) = 1.
\]
Für die Zahlenreihe, welche die relativen Häufigkeiten bilden, finden
wir den Mittelwert~$w$, indem wir bilden
\[
nw = \Sum p\psi_p
   = \Sum p\psi_p \xi^{p-1}\eta^q \quad\text{für}\quad \xi = \eta = 1.
\]
Nun ergibt sich aber:
\begin{align*}
\Sum p\psi_p\xi^{p-1}\eta^q
  &= \frac{\partial \Prod(w_i\xi + w'_i\eta)}{\partial\xi} \\
  &= \Prod(w_i\xi + w'_i\eta)·\Sum \frac{w_i}{w_i\xi + w'_i\eta}
\end{align*}
und daraus folgt für den Mittelwert~$w$, wenn wir $\xi = \eta = 1$
setzen,
\[
\Tag{(7)}
nw = \Sum w_i.
\]

Wir haben jetzt auch noch die mittlere Ausweichung zu berechnen
und zu dem Zweck zu bilden
\[
n^2\mu^2 = \Sum (p - nw)^2·\psi_p.
\]
Hierfür ergibt sich zunächst:
\begin{align*}
\Sum (p - nw)^2\psi_p
  &= \Sum p^2\psi_p - n^2w^2 \\
  &= \Sum p(p - 1)\psi_p + nw - n^2w^2,
\end{align*}
und weiter finden wir für $\xi = \eta = 1$
\[
\Sum p(p - 1)\psi_p
  = \Sum p(p - 1)\psi_p\xi^{p-2}\eta^q
  = \frac{\partial \Prod(w_i\xi + w'_i\eta)}{\partial\xi^2}.
\]
\DPPageSep{117}{103}
Es wird aber für $\xi = \eta = 1$
\begin{align*}
\frac{\partial^2 \Prod(w_i\xi + w'_i\eta)}{\partial\xi^2}
  &= 2\Prod(w_i\xi + w'_i\eta)
    · \Sum_{i,k}\frac{w_i w_k}{(w_i\xi + w'_i\eta)(w_k\xi + w'_k\eta)} \\
  &= 2\Sum_{i,k} w_i w_k,
\end{align*}
und damit erhalten wir:
\begin{align*}
n^2\mu^2 &= \Sum p(p - 1)\psi_p + nw - n^2w^2 \\
  &= 2\Sum_{i,k} w_i w_k + \Sum_i w_i - (\Sum_i w_i)^2
\intertext{oder}
n^2\mu^2 &= \Sum_i w_i - \Sum_i w_i^2,
\intertext{also}
n^2\mu^2 &= \Sum_i w_i(1 - w_i).
\end{align*}
In diesem Falle ergibt sich demnach für die mittlere Ausweichung
der Wert
\[
\Tag{(8)}
\mu = \sqrt{\frac{\Sum w_i(1 - w_i)}{n^2}}.
\]

Wir haben bis jetzt über die Verteilung der relativen Häufigkeiten~$w_i$
nichts vorausgesetzt. Wir wollen einmal annehmen,
daß diese Verteilung selbst eine solche ist, wie sie sich für das
Ziehungsverhältnis bei einer Urne ergibt. Die auftretenden
Werte~$w_i$ bilden dann eine typische Zufallsreihe. Der Mittelwert
dieser Reihe,~$w$, wird gegeben durch die Gleichung
\[
\Sum w_i = nw.
\]
Dagegen wird die Quadratsumme~$\Sum w_i^2$ nach den früher gefundenen
Formeln gleich $(n - 1)w^2 + w$. Dies folgt nämlich aus der
Gleichung
\[
\Sum p^2 \phi_p = n(n - 1) w^2 + nw,
\]
wenn wir bedenken, daß $n\phi_p$ die Anzahl Male ist, die der Wert~$p$
unter den $n$~Gliedern der Reihe vorkommt, und daß jetzt $w_i = \dfrac{p}{n}$
einzusetzen ist. Wir finden also:
\DPPageSep{118}{104}
\begin{align*}
\Sum w_i(1 - w_1)
  &= \Sum w_i - \Sum w_i^2 = nw - (n - 1)w^2 - w \\
  &= (n - 1)w(1 - w)
\end{align*}
und damit
\[
\Tag{(9)}
\mu = \sqrt{\frac{(n - 1)w(1 - w)}{n^2}}.
\]
Dieser Wert der mittleren Ausweichung unterscheidet sich von
dem früher gefundenen nur dadurch, daß der Faktor $\sqrt{\dfrac{n - 1}{n}}$
hinzugetreten ist. Dieser Faktor wird für größeres $n$ sehr nahe
gleich~$1$ und wir finden so wieder dieselbe mittlere Ausweichung
wie früher, wenn wir nur für das Mischungsverhältnis den Mittelwert
$w = \dfrac{\Sum w_i}{n}$ nehmen.

Daraus folgt, daß, wenn zwischen dem Wert von $w$ und dem
Wert von $\mu$ der früher gefundene Zusammenhang nicht bestehen
soll, die Abweichung der Werte~$w_i$ vom Mittelwert~$w$ jedenfalls
nicht selbst eine rein zufällige (wie sie sich bei der Ziehung
aus einer Urne als Abweichung des Ziehungsverhältnisses vom
Mischungsverhältnis ergibt) sein darf. Es muß vielmehr eine
andersgeartete Veränderung in dem Mischungsverhältnis der Urne,
aus der gezogen wird, mit anderen Worten eine systematische
Veränderung der dem beobachteten Ereignis zugrunde liegenden
Wahrscheinlichkeit angenommen werden.
\EndChap
\DPPageSep{119}{105}


\Chapter{Achtes Kapitel}{Näherungsformeln}

Für die relative Häufigkeit oder Wahrscheinlichkeit des
$p$\,maligen Ziehens einer weißen Kugel bei $n$ Ziehungen aus der
Urne haben wir, wenn die relative Häufigkeit der Ziehung einer
weißen Kugel $w$ ist, den Ausdruck gefunden:
\[
\phi_p = \frac{n!}{p!(n - p)!}\, w^p (1 - w)^{n-p}.
\]
Um diesen Ausdruck zu berechnen, etwa mit Hilfe von Logarithmen,
brauchen wir eine Tabelle der Fakultäten oder eine Tabelle
für die Logarithmen dieser Fakultäten, \dh~die Summe der
Logarithmen der ganzen Zahlen, von $1$ anfangend. Der Ausdruck
ist dann leicht für gegebene Werte von $p$~und~$n$ zu berechnen,
solange der Wert von $n$ nicht groß ist. Wird $n$ aber größer, so
entsteht schon in den Logarithmen von $w$~und~$1-w$, da der eine
mit~$p$, der andere mit~$n-p$ zu multiplizieren ist, eine erhebliche
Ungenauigkeit, und damit wird das Resultat nur dann zuverlässig,
wenn man Logarithmen mit hinreichend viel Stellen nimmt, was
sehr unbequem ist.

Dann empfiehlt es sich, von bestimmten Näherungsformeln
Gebrauch zu machen. Es zeigt sich nämlich, daß unter gewissen
Umständen der Ausdruck von~$\phi_p$ sich auf einen solchen zurückführen
läßt, der eine Funktion bloß einer Veränderlichen ist und
sich deshalb in einer Tabelle mit einem einzigen Eingang darstellen
läßt.

Der erste Fall, in dem dies eintritt, ist der, wo $n$ sehr groß
ist, aber $w$ sowohl von~$0$ als auch von~$1$ erheblich verschieden
ist. Die Art der sich so ergebenden Verteilung wollen wir uns
zunächst durch eine graphische Darstellung klar zu machen suchen.
\DPPageSep{120}{106}
Sie ist in der untenstehenden Figur für $999$~Ziehungen aus einer
Urne, in der gleich viel weiße und schwarze Kugeln enthalten
sind, angegeben. Es ergibt sich natürlich nicht im eigentlichen
Sinne eine Kurve, aber die $1000$~Punkte, die zu zeichnen sind,
liegen einander so nahe, daß, wenn man je zwei aufeinander
folgende von ihnen durch gerade Strecken verbindet, mit sehr
\begin{figure}[hbt!]
  \centering
  \caption{Fig.~7.}
  \Input[\textwidth]{120}
\end{figure}
großer Annäherung das Bild einer Kurve entsteht. Analytisch
würde das bedeuten, daß, wenn der als Einheit gewählte Abstand
auf der Abszissenachse mit~$e$ bezeichnet wird und die der Kurve
entsprechende Funktion mit~$\phi(x)$, wobei $x = pe$, mit genügender
Annäherung
\[
\frac{d\phi(x)}{dx} = \frac{\phi_{p+1} - \phi_p}{e}
\]
angenommen werden kann oder, falls man unmittelbar $e=1$ setzt,
\[
\frac{d\phi(x)}{dx} = \phi_{p+1} - \phi_p.
\]
Die Kurve nähert sich in ihrem Verlauf so rasch der Abszissenachse,
daß von ihr nur ein kleiner Teil, der sich allein merklich
von der Abszissenachse entfernt, gezeichnet zu werden braucht.
Dieser Teil gruppiert sich hier um die Stelle, bei der die Anzahl
der gezogenen weißen Kugeln der Anzahl der gezogenen schwarzen
Kugeln möglichst gleich wird.
\DPPageSep{121}{107}

Um nun einen angenäherten Ausdruck für $\phi_p$ zu finden,
bilden wir wieder
\[
\frac{\phi_{p+1} - \phi_p}{\phi_p} = \frac{(n + 1)w - (p + 1)}{(p +1)(1 - w)}.
\]

Wir haben dabei vorauszusetzen, daß $n$ sehr groß ist. Wir
müssen dann annehmen, damit sich überhaupt ein von~$0$ hinlänglich
verschiedener Wert von~$\phi_p$ ergibt, daß $p$ in der Nähe des
Maximalwertes liegt. Dieser Maximalwert ergibt sich, wenn der
Zähler des Bruches auf der rechten Seite der vorstehenden Gleichung
möglichst angenähert gleich $0$ wird, also wenn möglichst
angenähert
\begin{align*}
p + 1 &= (n + 1)w \\
\intertext{wird. Es liegt deshalb nahe, allgemein}
p + 1 &= (n + 1)w + x_1
\end{align*}
zu setzen. $x_1$~ist dann eine im Verhältnis zu $n$ kleine, wenn auch
an sich große Zahl.

Die Zunahme um $1$ im Argument von~$\phi_p$ bedeutet demnach
eine relativ sehr kleine Zunahme, und die Differenz $\phi_{p+1} - \phi_p$
kann einstweilen mit dem Differentialquotienten von~$\phi_p$, wenn
wir dies als Funktion eines kontinuierlich sich verändernden
Argumentes, nämlich von~$x_1$, ansehen, identifiziert werden. Wir
können also setzen, indem wir jetzt $\phi_0(x_1)$ statt $\phi_p$ schreiben,
\[
\frac{\phi_{p+1} - \phi_p}{\phi_p}
  = \frac{\ \dfrac{d\phi_0(x_1)}{dx_1}\ }{\phi_0(x_1)}
  = \frac{d \ln \phi_0(x_1)}{dx_1}
\]
und erhalten
\[
\frac{d \ln \phi_0(x_1)}{dx_1}
  = - \frac{x_1}{nw(1 - w)\left(1 + \dfrac{x_1 + w}{nw}\right)}.
\]

In dem Bruch rechter Hand können wir noch in dem letzten
Faktor des Nenners den nach Voraussetzung sehr kleinen Wert
$\dfrac{x_1 + w}{nw}$ weglassen und erhalten so einfach
\[
\frac{d \ln \phi_0(x_1)}{dx_1} = -\frac{x_1}{nw(1 - w)}.
\]
\DPPageSep{122}{108}
Daraus folgt durch Integration
\[
\phi_0(x_1) = Ce^{-\tfrac{x_1^2}{2nw(1 - w)}},
\]
wobei $C$ eine noch zu bestimmende Konstante bezeichnet.

Statt des Verhältnisses $\dfrac{\phi_{p+1} - \phi_p}{\phi_p}$ können wir ebensogut
aber auch das Verhältnis $\dfrac{\phi_p - \phi_{p-1}}{\phi_p}$ bilden und erhalten dann
\[
\frac{\phi_p - \phi_{p-1}}{\phi_p} = \frac{(n + 1)w - p}{(n + 1 - p)w}.
\]
Der Ausdruck auf der linken Seite kann mit demselben Recht wie
der frühere gleich einer logarithmischen Derivierten gesetzt werden.
Auf der rechten Seite zeigt sich jetzt, daß der Ausdruck verschwindet,
wenn mit möglichster Annäherung
\begin{align*}
p &= (n + 1)w \\
\intertext{wird. Wir müssen daher jetzt allgemein}
p &= (n + 1)w + x_2
\end{align*}
setzen, dann erhalten wir genau wie vorher wieder
\begin{align*}
\frac{d \ln\phi_0(x_2)}{dx_2} &= -\frac{x_2}{nw(1 - w)} \\
\intertext{und daraus}
\phi_0(x_2) &= Ce^{-\tfrac{x_2^2}{2nw(1 - w)}}.
\end{align*}

Die genaueste Darstellung wird zwischen den beiden gefundenen
Näherungswerten liegen, \dh~sich auf ein Argument~$x$
beziehen, für das
\[
x_1 > x > x_2
\]
ist. Da nun aber
\begin{align*}
x_1 &= (p - nw) + (1 - w), \\
x_2 &= (p - nw) - w
\end{align*}
ist, liegt es nahe,
\[
x = p - nw
\]
\DPPageSep{123}{109}
anzunehmen. Das kommt darauf hinaus, das Maximum an die
Stelle
\[
w = \frac{p}{n}
\]
zu legen. Wir finden dann schließlich das Resultat
\[
\Tag{(1)}
\phi_0(x) = Ce^{-\tfrac{x^2}{2nw(1 - w)}}.
\]

Hiermit wäre die gesuchte Näherungsfunktion, die \so{Gauß}\-sche
\index{Gaußsche@Gaußsche Verteilungsfunktion|uo}%
Funktion, gefunden. Es ist aber zu beachten, daß das Argument~$x$
eine sehr große Zahl bedeuten kann. Wenn wir statt $x$ das Verhältnis
$\xi = \dfrac{x}{n}$ einführen, erhalten wir statt $\phi_0(x)$ die Funktion
\[
Ce^{-\tfrac{n\xi^2}{2w(1 - w)}}.
\]
Da $\phi_0(x)$ die relative Häufigkeit einer Anzahl der gezogenen
weißen Kugeln, die mit $x$ in den Stellen vor dem Komma übereinstimmt,
war, so ist der vorstehende Ausdruck die relative Häufigkeit
eines Wertes~$\xi$ innerhalb der Genauigkeitsgrenze~$\dfrac{1}{n}$. Setzen wir
\begin{align*}
Cn &= c \\
\intertext{und}
\frac{1}{n} &= d\xi,
\end{align*}
so können wir dafür schreiben:
\[
\Tag{(2)}
\phi_1(\xi)\, d\xi = ce^{-\tfrac{n\xi^2}{2w(1 - w)}}\, d\xi.
\]
Man sieht, daß $\phi_1(\xi)\, d\xi$, wenn wir noch
\[
\Tag{(3)}
t = \frac{x}{\sqrt{2nw(1 - w)}}
  = \sqrt{\frac{n}{2w(1 - w)}}\, \xi
\]
setzen,
\[
= c \sqrt{\frac{2w(1 - w)}{n}} e^{-t^2}\, dt
\]
wird.

Um nun noch die Konstante~$c$ zu bestimmen, kann man einen
zweifachen Weg einschlagen. Einmal nämlich kann man davon
\DPPageSep{124}{110}
ausgehen, daß der Maximalwert der Funktion $\phi_0(x)$, der für $x=0$
eintritt, mit dem Maximalwert von $\phi_p$ für $p = nw$ übereinstimmen
soll. Man hat hierbei wieder einen Näherungsausdruck, der für
sehr große $n$~und~$p$ gilt, zu verwenden. Zu dem Zweck geht man
aus von der sogenannten \so{Stirling}schen Formel
\index{Stirlingsche Formel}%
\[
n! = \sqrt{2\pi}\, n^{n+\tfrac{1}{2}}\, e^{-n},
\]
die für einen sehr großen Wert von $n$ gilt. Ebenso wird natürlich
auch
\[
p! = \sqrt{2\pi}\, p^{p+\tfrac{1}{2}}\, e^{-p},\quad
(n - p)! = \sqrt{2\pi}\, (n - p)^{n-p+\tfrac{1}{2}}\, e^{-n+p}
\]
und es ergibt sich für $p=nw$:
\begin{align*}
\phi_{nw}
  &= \frac{1}{\sqrt{2\pi nw(1 - w)}}
   · \frac{n^n w^{nw} (1 - w)^{n(1-w)}}{\bigl[nw\bigr]^{nw} \bigl[n(1 - w)\bigr]^{n(1-w)}} \\
  &= \frac{1}{\sqrt{2\pi nw(1 - w)}}.
\end{align*}
Dieses muß aber mit der Konstanten~$C$ identisch sein, und wir
haben sonach
\[
C = \frac{1}{\sqrt{2\pi nw(1 - w)}},\quad\text{also}\quad
c = \sqrt{\frac{n}{2\pi w(1 - w)}}
\]
und
\[
\phi_1(\xi) = \sqrt{\frac{n}{2\pi w(1 - w)}}·e^{-\tfrac{n\xi^2}{2w(1 - w)}}.
\]

Andererseits können wir aber auch davon ausgehen, daß die
Summe aller möglichen relativen Häufigkeiten oder Wahrscheinlichkeiten
gleich~$1$ werden muß, und diese Bedingung auch für die
Näherungsfunktion als streng erfüllt annehmen. Es wird nun
\[
\phi_1(\xi)\, d\xi
\]
die Wahrscheinlichkeit dafür, daß der Wert von $\xi$ zwischen $\xi$ und
$\xi + d\xi$ liegt, und damit ergibt sich für die Summe aller möglichen
Wahrscheinlichkeiten das Integral
\[
\Int_{-\infty}^{+\infty} \phi_1(\xi)\, d\xi
  = c \sqrt{\frac{2w(1 - w)}{n}} \Int_{-\infty}^{+\infty} e^{-t^2}\, dt.
\]
\DPPageSep{125}{111}

Um dieses letzte Integral zu berechnen, gehen wir den von
\so{Poisson} angegebenen Weg, daß wir es mit einer anderen Bezeichnung
\index{Poisson}%
der Veränderlichen noch einmal bilden und die beiden so
entstehenden Integrale
\[
I = \Int_{-\infty}^{+\infty} e^{-t^2}\, dt,\quad
I = \Int_{-\infty}^{+\infty} e^{-s^2}\, ds
\]
miteinander multiplizieren. Es ergibt sich so das Doppelintegral
\[
I^2 = \Int_{-\infty}^{+\infty}\Int_{-\infty}^{+\infty} e^{-(s^2+t^2)}\, ds\, dt,
\]
und um dieses auszuwerten, setzen wir
\[
s = r \cos \rho,\quad  t = r \sin \rho.
\]
Dadurch geht, weil das Flächenelement dann $r\, dr\, d\rho$ wird, das
Doppelintegral über in
\[
I^2 = \Int_{0}^{\infty}\Int_0^{2\pi} e^{-r^2} r\, dr\, d\rho.
\]
In diesem neuen Doppelintegral lassen sich die beiden Integrationen
getrennt ausführen. Es wird
\[
\Int_0^{2\pi} d\rho = 2\pi,\quad
\Int_{0}^{\infty} e^{-r^2} r\, dr = \frac{1}{2},
\]
und damit ergibt sich schließlich
\[
I^2 = \pi,\quad\text{also}\quad
I = \sqrt{\pi}.
\]
Hieraus aber folgt:
\[
1 = \Int_{-\infty}^{+\infty} \phi_1(\xi)\, d\xi
  = c \sqrt{\frac{2w(1 - w)}{n}} I
  = c \sqrt{\frac{2\pi w(1 - w)}{n}},
\]
also
\[
\Tag{(4)}
c = \sqrt{\frac{n}{2\pi w(1 - w)}},
\]
\dh~genau dasselbe Resultat, das früher auf anderem Wege gefunden
wurde.
\DPPageSep{126}{112}

Die Veränderliche~$\xi$ kann, da das Verhältnis $\dfrac{x}{n}$ verhältnismäßig
klein bleibt, nur sehr kleine Werte haben. In der Tat zeigt
der Ausdruck von~$\phi_1(\xi)$, daß $n\xi^2$ einen mäßigen Wert haben
muß, damit der Funktionsausdruck $\phi(\xi)$ einen berechenbaren Wert
erhält. Führen wir statt $\xi$ die andere Relativzahl
\[
\frakx = \sqrt{n}·\xi = \frac{x}{\sqrt{n}}
\]
ein, so erhalten wir jetzt ein Argument, das mäßige Werte annimmt,
und damit den Wert
\[
\Tag{(5)}
\phi(\frakx)\, d\frakx
  = \frac{1}{\sqrt{2\pi w(1 - w)}}\,
    e^{-\tfrac{\frakx^2}{2w(1 - w)}}\, d\frakx
\]
für die Wahrscheinlichkeit, daß $\frakx$ zwischen $\frakx$~und~$\frakx + d\frakx$ liegt, \dh~das
ermittelte Ziehungsverhältnis zwischen
\[
\frac{p}{n}\quad\text{und}\quad
\frac{p}{n} + \frac{\frakx + d\frakx}{\sqrt{n}}.
\]
Man sieht daraus unmittelbar, daß die Genauigkeit der Bestimmung
des Mischungsverhältnisses aus dem Ziehungsverhältnis proportional
mit der Quadratwurzel aus der Anzahl der gemachten
Ziehungen wächst.

Der Verlauf der gefundenen Funktion ergibt sich aus folgender
Tabelle, wobei $t$ durch~\Eqref{(3)} bestimmt ist:
\[
\begin{array}{c|c||c|c||c|c}
\hline\hline
\vphantom{\Bigg|}
±t & \dfrac{1}{\sqrt{\pi}}\, e^{-t^2} &
±t & \dfrac{1}{\sqrt{\pi}}\, e^{-t^2} &
±t & \dfrac{1}{\sqrt{\pi}}\, e^{-t^2} \\
\hline\hline
0,0 & 0,5642 & 1,0 & 0,2076 & 2,0 & 0,0104 \\
0,1 & 0,5586 & 1,1 & 0,1683 & 2,1 & 0,0069 \\
0,2 & 0,5421 & 1,2 & 0,1337 & 2,2 & 0,0045 \\
0,3 & 0,5157 & 1,3 & 0,1041 & 2,3 & 0,0029 \\
0,4 & 0,4808 & 1,4 & 0,0795 & 2,4 & 0,0018 \\
0,5 & 0,4394 & 1,5 & 0,0595 & 2,5 & 0,0011 \\
0,6 & 0,3937 & 1,6 & 0,0436 & 2,6 & 0,0007 \\
0,7 & 0,3457 & 1,7 & 0,0314 & 2,7 & 0,0004 \\
0,8 & 0,2975 & 1,8 & 0,0222 & 2,8 & 0,0002 \\
0,9 & 0,2510 & 1,9 & 0,0153 & 2,9 & 0,0001 \\
\end{array}
\]
\DPPageSep{127}{113}

Der zweite Fall, in dem sich ein einfacher Näherungsausdruck
für $\phi_p$ ergibt, ist der, wo wieder $n$ sehr groß, $w$~aber sehr klein
und $p$ nicht groß ist, so daß die Fakultät~$p!$ direkt berechnet
werden kann.

Wir berechnen wieder $n!$ nach der \so{Stirling}schen Formel
\[
n! = \sqrt{2\pi}\, n^{n+\tfrac{1}{2}}\, e^{-n}
\]
und ebenso können wir setzen
\[
(n - p)! = \sqrt{2\pi}\, (n - p)^{n-p+\tfrac{1}{2}}\, e^{-n+p}.
\]
Es ergibt sich dann:
\[
\phi_p = \frac{(n - p)^p}{p!\left(1 - \dfrac{p}{n}\right)^{n+\tfrac{1}{2}}}\,
  e^{-p} w^p(1 - w)^{n-p}.
\]
Nun kann aber für sehr großes~$n$
\[
\left(1 - \frac{p}{n}\right)^{n+\tfrac{1}{2}} = e^{-p}
\]
gesetzt werden und ebenso ergibt sich auch:
\[
(1 - w)^{n-p} = e^{-(n - p)w}.
\]
Mithin wird
\[
\phi_p = \frac{(n - p)^p w^p}{p!}\, e^{-(n-p)w},
\]
also schließlich, wenn noch
\[
(n - p)·w = m \quad\text{(oder angenähert $n·w = m$)}
\]
gesetzt wird,
\[
\phi_p = \frac{m^p e^{-m}}{p!}.
\]
Dies ist die gesuchte Näherungsformel, zu der noch gehört, daß
für~$p=0$ $\phi_p = e^{-m}$~zu nehmen ist. Es zeigt sich, daß, damit
berechenbare Werte herauskommen, die Anzahl~$n$ der gemachten
Ziehungen so groß sein muß, daß das Produkt~$n·w$ einen angebbaren
Wert erhält.
\DPPageSep{128}{114}

Um einen Begriff von dem Verlauf dieser Funktion zu geben,
haben wir die folgende kleine Tabelle für einzelne Werte von~$m$
angefügt:
\[
\begin{array}{c||*{6}{c|}}
\hline\hline
\multirow{2}{*}{p} & \multicolumn{6}{c}{m} \\
\cline{2-7}
   & 0,1 &  0,5&   1,0&   2,0 & 3,0 & 4,0\\
\hline\hline
 0 & 0,9048& 0,6065& 0,3679& 0,1353& 0,0498& 0,0183 \\
 1 & 0,0905& 0,3033& 0,3679& 0,2707& 0,1494& 0,0733 \\
 2 & 0,0045& 0,0758& 0,1839& 0,2707& 0,2240& 0,1465 \\
 3 & 0,0002& 0,0126& 0,0613& 0,1804& 0,2240& 0,1954 \\
 4 & \Dash & 0,0016& 0,0153& 0,0902& 0,1680& 0,1954 \\
 5 & \Dash & 0,0002& 0,0031& 0,0361& 0,1008& 0,1563 \\
 6 & \Dash & \Dash & 0,0005& 0,0120& 0,0504& 0,1042 \\
 7 & \Dash & \Dash & 0,0001& 0,0034& 0,0216& 0,0595 \\
 8 & \Dash & \Dash & \Dash & 0,0009& 0,0081& 0,0298 \\
 9 & \Dash & \Dash & \Dash & 0,0002& 0,0027& 0,0132 \\
10 & \Dash & \Dash & \Dash & \Dash & 0,0007& 0,0053 \\
11 & \Dash & \Dash & \Dash & \Dash & 0,0001& 0,0019 \\
12 & \Dash & \Dash & \Dash & \Dash & \Dash & 0,0006 \\
13 & \Dash & \Dash & \Dash & \Dash & \Dash & 0,0002 \\
14 & \Dash & \Dash & \Dash & \Dash & \Dash & 0,0001 \\
\end{array}
\]

Es bleibt noch der Fall zu erledigen, wo nicht aus einer Urne,
sondern bei jeder Ziehung wieder aus einer anderen Urne gezogen
wird, wobei die Mischungsverhältnisse der weißen und schwarzen
Kugeln in den Urnen, aus denen gezogen wird, der Reihe nach beliebig
gegeben sind. Wir können auch hier die Anzahl der Ziehungen
außerordentlich groß annehmen und dann nach einem Näherungsausdruck
suchen, der die herauskommende Verteilung darstellt.

Wir hatten oben das Mischungsverhältnis der weißen und
schwarzen Kugeln in der $i$ ten Urne mit~$w_i/w'_i$ bezeichnet, wobei
$w_i + w'_i = 1$ war. Es wird hinreichen, wenn wir den Fall ins
Auge fassen, wo sowohl $w_i$ als auch $w'_i$ höchstens in vereinzelten
Fällen einen sehr kleinen Wert hat. Dann führt folgende Betrachtung
zum Ziel.

Für die relative Häufigkeit des $p$\,maligen Ziehens einer
weißen Kugel in $n = p + q$ Fällen hatten wir oben (S.~101) den
Koeffizienten von~$\xi^p\eta^q$ in der Entwickelung des Produktes
\[
\Prod_i(w_i\xi + w'_i\eta)
\]
\DPPageSep{129}{115}
gefunden. Wir können nun, indem wir $\xi = e^{i\zeta}$, $\eta = e^{-i\zeta}$ annehmen,
für diesen Koeffizienten den Integralausdruck setzen:
\[
\psi_p = \frac{1}{\pi} \Int_{-\tfrac{\pi}{2}}^{+\tfrac{\pi}{2}}
    \Prod_i (w_i\xi + w'_i\eta) \xi^{-p} \eta^{-q}\, d\zeta.
\]
Dieses Integral ergibt sich nämlich, wenn wir das Produkt ausführen,
aus einer Reihe von Integralen der Form
\[
\Int_{-\alpha}^{+\alpha} \psi_\mu \xi^{\mu-p} \eta^{\nu-q}\, d\zeta.
\]
Hierin wird
\[
\mu + \nu = p + q = n.
\]
Es findet sich also für das vorstehende Integral der Wert
\[
\psi_\mu \Int_{-\alpha}^{+\alpha} e^{2(\mu - p)i\zeta}\, d\zeta,
\]
oder ausgerechnet, wenn $\mu - p \neq 0$,
\[
\frac{\psi_\mu}{2(\mu - p)i} \bigl[e^{2(\mu-p)i\alpha} - e^{-2(\mu-p)i\alpha}\bigr]
\]
oder
\[
\frac{\psi_\mu}{\mu - p} \sin 2(\mu - p)\alpha.
\]
Werden nun für die Integrationsgrenzen $-\alpha$~und~$+\alpha$ die Werte
$-\dfrac{\pi}{2}$ und~$+\dfrac{\pi}{2}$, also $\alpha = \dfrac{\pi}{2}$ genommen, so verschwindet dieser
Ausdruck, solange~$\mu \neq p$. Nur wenn $\mu = p$, ergibt sich der Wert
$\psi_p·\pi$, womit die Behauptung bewiesen ist.

Um jetzt das eingeführte Integral umzuformen, setzen wir
\[
w_i\xi + w'_i\eta = \rho_i e^{i\theta_i},
\]
dann wird, da $\xi$~und~$\eta$ von der Form $\xi = e^{i\zeta}$, $\eta = e^{-i\zeta}$
sein sollen, weiter
\[
w_i\eta + w'_i\xi = \rho_i e^{-i\theta_i}.
\]
\DPPageSep{130}{116}
Durch Multiplikation der beiden vorstehenden Ausdrücke erhalten
wir
\[
(w_i^2 + w_i'^2) \xi\eta + w_i w'_i (\xi^2 + \eta^2) = \rho_i^2
\]
oder, da $w_i + w'_i = 1$,
\[
\xi\eta + w_i w'_i(\xi - \eta)^2 = \rho_i^2.
\]
Führen wir hierin ein die aus $\xi = e^{i\zeta}$, $\eta = e^{-i\zeta}$ folgenden Werte
\[
\xi\eta = 1,\quad
\xi - \eta = 2i \sin\xi,
\]
so erhalten wir
\[
1 - 4 w_i w'_i \sin^2\zeta = \rho_i^2.
\]

Wenn nun das Produkt sehr viele Faktoren enthält (deren
absolute Werte alle kleiner als $1$ sind) und trotzdem sein absoluter
Wert nicht sehr klein werden soll, so müssen in dem Ausdruck
$\Prod\rho_i$ für den absoluten Wert des Produktes die Werte~$\rho_i$ von~$1$
sehr wenig verschieden sein. Das bedingt aber, daß in dem
Ausdruck
\[
\sqrt{1 - 4 w_i w'_i \sin^2 \zeta} = \rho_i
\]
$\sin \zeta$ und damit $\zeta$ selbst sehr klein werden muß, so daß wir $\sin \zeta$
durch $\zeta$ ersetzen können. Auf diese Weise erhalten wir
\[
\sqrt{1 - 4 w_i w'_i \zeta^2}  = \rho_i,
\]
oder, da $\zeta$ sehr klein ist, mit genügender Annäherung
\[
e^{-2w_i w'_i \zeta^2} = \rho_i.
\]

Ferner finden wir
\[
\frac{w_i\xi + w'_i\eta}{w_i\eta + w'_i\xi} = e^{2i\theta_i},
\]
und daraus
\[
(w_i - w'_i) \tang \zeta = \tang \theta_i.
\]
Wird nun $\zeta$ sehr klein, so läßt sich statt dieser Gleichung
schreiben:
\[
(w_i - w'_i) \zeta = \theta_i.
\]
\DPPageSep{131}{117}

So ergibt sich schließlich für den zu bestimmenden Integralausdruck
der Wert
\[
\frac{1}{\pi} \Int_{-\tfrac{\pi}{2}}^{+\tfrac{\pi}{2}}
    e^{-2\Sum w_i w'_i\zeta^2}\,
    e^{\bigl[\Sum(w_i - w'_i) - (p - q)\bigr]i\zeta}\, d\zeta.
\]
Wir wollen nun einführen
\[
\Tag{(6)}
\frac{2 \Sum w_i(1 - w_i)}{n} = \frac{2 \Sum w_i w'_i}{n} = k^2
\]
und außerdem die Mittelwerte
\[
\frac{\Sum w_i}{n} = w,\qquad
\frac{\Sum w'_i}{n} = w'\quad (w + w' = 1),
\]
indem wir weiter setzen
\[
w  = \frac{p}{n} + \tau,\qquad
w' = \frac{q}{n} - \tau,
\]
dann nimmt der Integralausdruck die Form an:
\[
\frac{1}{\pi} \Int_{-\infty}^{+\infty} e^{-nk^2\zeta^2 + 2ni\tau\zeta}\, d\zeta.
\]
Hierbei haben wir für die Grenzen sogleich $-\infty$~und~$+\infty$ genommen,
weil überhaupt nur kleine Werte des Argumentes~$\zeta$ in
Betracht kommen, indem für größere Werte der absolute Wert
des Integranden sehr klein wird. Ferner wollen wir berücksichtigen,
daß die Stufen, in denen $\tau$ zunimmt, durch $\dfrac{1}{n}$ gegeben sind, und
da nach Voraussetzung $n$ sehr groß ist, können wir $\dfrac{1}{n} = d\tau$\DPnote{** TN: [sic]}
setzen und den Wert des Integralausdruckes
\[
= \Phi(\tau)\, d\tau.
\]
\DPPageSep{132}{118}
So erhalten wir:
\begin{align*}
\Phi(\tau)
  &= \frac{n}{\pi} \Int_{-\infty}^{+\infty}
     e^{-nk^2 \left(\zeta - \tfrac{i\tau}{k^2}\right)^2}\,
     e^{-\tfrac{n\tau^2}{k^2}}\, d\zeta \\
  &= \frac{\sqrt{n}}{\sqrt{\pi}k}\, e^{-\tfrac{n\tau^2}{k^2}} \Int_{-\infty}^{+\infty}
     e^{-nk^2 \left(\zeta - \tfrac{i\tau}{k^2}\right)^2}\, \sqrt{n}k\,
     \frac{d\zeta}{\sqrt{\pi}},
\end{align*}
und daraus
\[
\Phi(\tau) = \frac{\sqrt{n}}{\sqrt{\pi}k}\, e^{-\tfrac{n\tau^2}{k^2}}.
\]

Wenn wir also noch
\[
\Tag{(7)}
h_0 = \frac{\sqrt{n}}{k}
\]
machen, so finden wir genau denselben Ausdruck
\[
\Tag{(8)}
\Phi(\tau)\, d\tau = \frac{h_0}{\sqrt{\pi}}\, e^{-h_0^2\tau^2}\, d\tau
\]
für die relative Häufigkeit der Abweichung~$\tau$ des beobachteten
Verhältnisses von dem Wert~$w$ wie früher. Der Wert~$w$ ist
einfach das Mittel
\[
\Tag{(9)}
w = \frac{\Sum w_i}{n}
\]
aus den einzelnen Werten~$w_i$, und für $h_0$ ergibt sich die Gleichung
\[
\frac{1}{2h_0^2} = \frac{1}{n} \Sum \frac{w_i(1 - w_i)}{n}.
\]
Dieser Ausdruck ist also auch das Mittel aus den entsprechenden
für die einzelnen relativen Häufigkeiten~$w_i$ gebildeten Werten
\[
\frac{w_i(1 - w_i)}{n}.
\]

Das letzte Resultat läßt sich auch so deuten, daß die durch
die Beziehung
\[
\mu^2 = \Int_{-\infty}^{+\infty} e^{-h_0^2\tau^2}\, \tau^2
  \frac{h_0\, d\tau}{\sqrt{\pi}}
\]
\DPPageSep{133}{119}
bestimmte mittlere Ausweichung für den Wert~$\tau$ oder~$\dfrac{p}{n}$, da
\[
\Int_{-\infty}^{+\infty} e^{-h_0^2\tau^2}\, \tau^2 \frac{h_0\, d\tau}{\sqrt{\pi}}
  = \frac{1}{2h_0^2}
\]
ist, den Wert erhält:
\[
\Tag{(10)}
\mu = \sqrt{\frac{\Sum w_i(1 - w_i)}{n^2}}.
\]

Die Formeln \Eqref{(9)}~und~\Eqref{(10)} stimmen genau mit denen überein,
die wir im vorigen Kapitel bereits von dem ursprünglichen Ausdruck
für die relative Häufigkeit ausgehend gefunden haben. Wir
haben jetzt aber noch weiter gefunden, daß die Verteilung, die
sich für das Ziehungsverhältnis bei einer sehr großen Anzahl von
Ziehungen ergibt, wenn das Mischungsverhältnis (\dh~die zugrunde
liegende mathematische Wahrscheinlichkeit) nicht unveränderlich
ist, sondern beliebig wechselt, aber natürlich bei jeder
Ziehungsserie in der gleichen Weise, keine andere ist wie bei
dem gleichbleibenden Mischungsverhältnis, nämlich die durch die
\so{Gauß}sche Funktion gegebene.

Dagegen besteht nicht mehr die frühere Beziehung zwischen
$w$~und~$\mu$
\[
\tag*{($\alpha$)}
\mu = \sqrt{\frac{w(1 - w)}{n}}.
\]
Statt dieser Gleichung läßt sich aber leicht eine Ungleichheit ableiten.
Wir haben
\[
\Sum w_i^2 = \Sum(w_i - w)^2 + nw^2,
\]
also
\[
\Sum w_i^2 > nw^2.
\]
Hieraus und aus $\Sum w_i = nw$ folgt aber
\[
\Sum w_i(1 - w_i) < nw - nw^2,
\]
mithin
\[
\frac{\Sum w_i(1 - w_i)}{n^2} < \frac{w(1 - w)}{n}
\]
und mit Rücksicht auf~\Eqref{(2)}
\[
\tag*{($\beta$)}
\mu < \sqrt{\frac{w(1 - w)}{n}}.
\]
\DPPageSep{134}{120}

Die Verwendung der gefundenen Näherungsformeln geht nun
so vor sich, daß man, wenn eine Verteilungsreihe vorliegt, von
der man vermutet, daß sie einer der Formeln angenähert entsprechen
wird, diese Verteilungsreihe mit den nach der Formel errechneten
Werten zu vergleichen sucht. Bei einer Verteilungsreihe,
die der \so{Gauß}schen Verteilungsfunktion entspricht, muß die Verteilung
eine symmetrische sein, \dh~bei gleichen Abständen von
dem Normalwert müssen sich auch näherungsweise gleiche Häufigkeitszahlen
ergeben. Bei einer Verteilungsreihe, die dem Ausdruck
$\dfrac{m^pe^{-m}}{p!}$ entspricht, ergibt sich dagegen eine wesentliche
Asymmetrie, und zwar ist der Normalwert nach dem Anfang der
Reihe zu verschoben, so daß sich erst eine verhältnismäßig rasche
Zunahme und nachher eine langsamere Abnahme ergibt.

Die Formeln enthalten bestimmte Konstanten, und zwar ist,
wenn wir sie so auffassen, daß sie die jeweiligen Bruchteile der
beobachteten Gesamtfälle liefern, also die Summe aller durch sie
dargestellten relativen Häufigkeiten gleich~$1$ wird, in jeder Formel
nur eine Konstante enthalten.

Im Falle der Formel~\Eqref{(5)} schreiben wir (für $\frakx = x:\sqrt{n}$):
\[
\Tag{(A)}
\phi(\frakx)=\frac{h}{\sqrt{\pi}}\, e^{-h^2\frakx},
\]
wobei $h = 1:\sqrt{2w(1 - w)}$. Im Falle der Formel~\Eqref{(8)} ist $\frakx = \tau\sqrt{n}$
und $h = h_0:\sqrt{n} = 1:k = \sqrt{n}:\sqrt{2\Sum w_i(1- w_i)}$ zu setzen; $\frakx$~und
$h$ sind dann berechenbare Werte.

Ist nun eine dieser Verteilungsfunktion folgende Verteilungsreihe
vorgelegt, so besteht eine erste Methode, um zu der Bestimmung
der Konstanten~$h$ in der Formel zu gelangen, darin, daß
man die Integrale
\[
\Int_{0}^{\infty}  \phi(\frakx)\frakx\, d\frakx \quad\text{und}\quad
\Int_{-\infty}^{0} \phi(\frakx)\frakx\, d\frakx
\]
betrachtet, die einander entgegengesetzt gleich werden und von
denen wir das erste mit $S$ bezeichnen wollen. Es ergibt sich
sofort:
\DPPageSep{135}{121}
\[
S = \frac{1}{\sqrt{\pi}h} \Int_{0}^{\infty} e^{-h^2\frakx^2}h\frakx\, d(h\frakx)
  = \frac{1}{2\sqrt{\pi}h}\bigl[e^{-h^2\frakx^2}\bigr]_\infty^0
  = \frac{1}{2\sqrt{\pi}h},
\]
und daraus
\[
\Tag{(a)}
\frac{1}{2h} = \sqrt{\pi}·S.
\]

Die zweite Bestimmung von $h$ beruht auf der Auswertung
des Integrals
\[
J = \Int_{-\infty}^{+\infty} \phi(\frakx)\frakx^2\, d\frakx.
\]
Für dieses Integral ergibt sich der Wert:
\[
J = \frac{1}{\sqrt{\pi} h^2} \Int_{-\infty}^{+\infty}
    e^{-h^2\frakx^2} h^2\frakx^2\, d(h\frakx)
  = \frac{1}{\sqrt{\pi} h^2} \Int_{-\infty}^{+\infty}
    e^{-t^2} t^2\, dt
  = \frac{1}{2h^2},
\]
weil durch partielle Integration
\[
1 = \frac{1}{\sqrt{\pi}} \Int_{-\infty}^{+\infty} e^{-t^2}\, dt
  = \frac{2}{\sqrt{\pi}} \Int_{-\infty}^{+\infty} e^{-t^2} t^2\, dt
\]
gefunden wird. Also folgt
\[
\Tag{(b)}
\frac{1}{2h} = \sqrt{\frac{J}{2}}.
\]

Die Vergleichung dieser beiden Bestimmungen zeigt, daß
\[
\Tag{(c)}
\sqrt{J} = \sqrt{2\pi}·S
\]
sein muß, und dies ist eine Beziehung, der jede Reihe mit einer
solchen typischen Verteilung genügen muß.

Eine dritte Bestimmung läßt sich schließlich aus der Einführung
des Wertes~$\alpha$ ableiten, für den
\[
\Int_{-\alpha}^{+\alpha} e^{-t^2}\, \frac{dt}{\sqrt{\pi}} = \frac{1}{2}
\]
wird. Dieser Wert läßt sich ein für allemal bestimmen. Man
findet
\[
\alpha = 0,4769.
\]
\DPPageSep{136}{122}

Führt man nun auch den Wert~$\rho$ ein, für den
\[
\Int_{-\rho}^{+\rho} \phi(\frakx)\, d\frakx
  = \Int_{-\rho}^{+\rho} e^{-h^2 \frakx^2}\, \frac{h\, d\frakx}{\sqrt{\pi}}
  = \frac{1}{2}
\]
wird, so ergibt sich sofort, daß
\[
\alpha = h\rho
\]
sein muß. Man findet also
\[
\Tag{(d)}
h = \frac{0,4769}{\rho}
\]
und daraus auch
\[
\Tag{(e)}
\frac{\rho}{0,9538 \sqrt{\pi}} = S.
\]
Dies ist eine zweite Beziehung, der eine typische Verteilungsreihe
genügen muß. Was die Bestimmung von $\rho$ betrifft, so hat man
nur von unten und von oben ein Viertel der beobachteten Fälle
abzuzählen. Der Abstand der beiden so gefundenen Stellen ist
das Doppelte des Wertes~$\rho$.

Wir wollen nun die analogen Bestimmungen auch für die
zweite Näherungsformel
\[
\Tag{(B)}
\phi_p = \frac{m^p e^{-m}}{p!}
\]
durchzuführen suchen. Zunächst wollen wir bestätigen, daß auch
hier sich
\[
\Sum \phi_p = 1
\]
ergibt. Dies ist in der Tat der Fall, denn es wird
\[
\Sum\phi_p
  = \left\{1 + \frac{m}{1!} + \frac{m^2}{2!} + \frac{m^3}{3!} + \dots\right\} e^{-m}
  = e^m·e^{-m} = 1.
\]
Bilden wir nun auch $\Sum p\phi_p$, so finden wir sofort
\[
\Sum p\phi_p = m\left\{1 + \frac{m}{1!} + \frac{m^2}{2!} + \dots\right\} e^{-m},
\]
also
\[
\Tag{(I)}
\Sum p\phi_p = m.
\]
\DPPageSep{137}{123}
Hieraus ergibt sich eine erste Bestimmung für die Konstante~$m$.
Weiter wird aber
\[
\Sum p(p - 1)\phi_p
  = m^2\left\{1 + \frac{m}{1!} + \frac{m^2}{2!} + \dots\right\} e^{-m},
\]
also
\[
\Sum p(p - 1)\phi_p = m^2.
\]
Daraus folgt
\[
\Sum p^2\phi_p = m(m+1)
\]
und
\[
\Sum (p - m)\phi_p = \Sum p^2\phi_p - m^2\Sum \phi_p = m(m + 1) - m^2 = m.
\]
Die so sich ergebende Formel
\[
\Tag{(II)}
\Sum (p - m)^2\phi_p = m
\]
liefert mit~\Eqref{(I)} zusammen eine Beziehung, der die dieser Verteilungsformel
folgenden Verteilungsreihen genügen müssen.

Bis jetzt haben wir überall vorausgesetzt, daß die gezogene
Kugel immer wieder sofort in die Urne zurückgelegt wird. Diese
Voraussetzung entspricht aber nicht der Art, wie man sich etwa
von der Mischung zweier Getreidesorten in einem größeren Behälter
überzeugen würde. Man würde dann einfach ein kleineres
Maß voll Getreide herausschöpfen und durch Abzählen die
Mischung der Getreidesorten in diesem Maße feststellen, um das
gefundene Mischungsverhältnis sofort auf die ganze Getreidemenge
zu übertragen. Die Berechtigung dieses allgemein angewendeten
Verfahrens muß sich nun auch mathematisch begründen
lassen, indem wir von denselben grundlegenden Voraussetzungen
ausgehen wie bei dem gewöhnlichen Urnenschema.

Wir setzen also voraus, in einer Urne seien $u$ weiße und $v$
schwarze Kugeln enthalten, im ganzen $m = u + v$ Kugeln. Wir
greifen nun von den $m$ Kugeln $n$ heraus und fragen nach der
relativen Häufigkeit der Fälle, wo unter diesen $n$ Kugeln $p$ weiße
und $q$ schwarze sind. Wenn aber mit einem Griff $n$ Kugeln gezogen
werden, so ist dies für den Erfolg dasselbe, als wenn die
Kugeln einzeln gezogen, aber nicht wieder zurückgelegt werden.
Sind nun unter den gezogenen $n$ Kugeln $p$ weiße und $q$ schwarze,
so kann dieser Erfolg auf verschiedene Arten zustande gekommen
sein, je nachdem in welcher Reihenfolge die weißen und schwarzen
\DPPageSep{138}{124}
Kugeln erschienen sind. Solcher verschiedener Reihenfolgen der
Farben gibt es im ganzen
\[
\frac{n!}{p!\, q!}.
\]
Für die verschiedenen Arten, auf die der Erfolg zustande kommen
kann, ergibt sich aber dieselbe relative Häufigkeit~$\omega$, für den
Erfolg selbst also die relative Häufigkeit
\[
\frac{n!}{p!\, q!}\omega.
\]

Um $\omega$ zu finden, zerlegen wir den gesamten Ziehungsprozeß,
der die Kugeln in einer bestimmten Reihenfolge liefert, in die
einzelnen Ziehungen, aus denen er besteht, und nehmen der Einfachheit
wegen die Reihenfolge, wo erst alle weißen und dann
alle schwarzen Kugeln erscheinen. Für die Ziehung der ersten
weißen Kugel finden wir die relative Häufigkeit
\[
\frac{u}{m},
\]
für die Ziehung der zweiten Kugel die relative Häufigkeit
\[
\frac{u - 1}{m - 1}.
\]
So geht es fort. Für die Ziehung der letzten weißen Kugel wird
die relative Häufigkeit
\[
\frac{u - p + 1}{m - p + 1},
\]
für die Ziehung der ersten schwarzen Kugel
\[
\frac{v}{m - p},
\]
usw., für die letzte Kugel
\[
\frac{v - q + 1}{m - p - q + 1}.
\]

Die relative Häufigkeit des Gesamtereignisses entsteht durch
Multiplikation aller der vorstehenden Werte, also wird
\[
\omega = \frac{u·(u - 1)\dots(u - p + 1)·v·(v - 1)\dots(v - q + 1)}
              {m·(m - 1)\dots(m - n + 1)}
\]
\DPPageSep{139}{125}
oder
\[
\omega = \frac{u!\, v!}{m!}·\frac{(m - n)!}{(u - p)!\, (v - q)!},
\]
und damit finden wir für die gesuchte relative Häufigkeit den Wert
\[
\psi_p = \frac{n!}{p!\, q!}·\frac{u!\, v!}{m!}·\frac{(m - n)!}{(u - p)!\,(v - q)!}.
\]

Nehmen wir nun an, $m$~sei sehr groß, ebenso auch $u$~und~$v$,
derart, daß $\dfrac{u}{m}$~und~$\dfrac{v}{m}$ von $0$~und~$1$ erheblich verschieden sind,
dagegen sei $n$ eine mäßige Zahl, so wird man in dem ursprünglichen
Ausdruck für $\omega u - 1, \dots, u - p + 1$ durch~$u$, $v - 1, \dots,
v - q + 1$ durch~$v$, $m - 1, \dots, m - n + 1$ durch~$m$ ersetzen
können, und erhält dann statt $\psi_p$ den früheren Ausdruck
\[
\psi_p = \frac{n!}{p!\, q!}\, \frac{u^p v^q}{m^n},
\]
der ja für $\dfrac{u}{m} = w$, $\dfrac{v}{m} = 1 - w$ in die Form
\[
\psi_p = \frac{n!}{p!\, q!} w^p(1 - w)^{n-p}
\]
übergeht. Man sieht also, daß sich in diesem Fall dieselbe Verteilung
ergibt, wie wenn die Kugeln einzeln gezogen und nach der
Ziehung immer wieder zurückgelegt würden.

Es handelt sich nun darum, auch die Fälle zu untersuchen,
wo nicht bloß~$m$, sondern auch $n$ einen großen Wert hat.

Um dann einen Überblick über die so entstehende Verteilungsreihe
zu erhalten (deren Summe wieder gleich~$1$ ist), bilden wir
zunächst den Quotienten
\[
\frac{\psi_{p+1}}{\psi_p} = \frac{q}{p + 1}·\frac{u - p}{v - q + 1}.
\]
Hieraus leiten wir ab:
\[
\frac{\psi_{p+1} - \psi_p}{\psi_p}
  = \frac{(n + 1)(u + 1) - (p + 1)(m + 2)}{(p + 1)(v - n + p + 1)}.
\]
\DPPageSep{140}{126}
Dieser Ausdruck läßt sich einfacher schreiben, wenn wir die neuen
Zahlenwerte einführen
\[
p' = p + 1,\
n' = n + 1,\
u' = u + 1,\
v' = v + 1,\
m' = m + 2
\]
so daß
\[
u' + v' = m'.
\]
Er wird dann
\[
\frac{\psi_{p+1} - \psi_p}{\psi_p} = \frac{n'u' - p'm'}{p'(v' - n' + p')}.
\]

Man sieht sofort, daß dieser Ausdruck verschwindet, daß sich
also ein Maximum der relativen Häufigkeit ergibt, wenn man
\[
p' = n'·\frac{u'}{m'}
\]
macht. Dies entspricht der von vornherein annehmbaren Vermutung,
daß der wahrscheinlichste Wert für das Mischungsverhältnis
der schwarzen und weißen Kugeln innerhalb der herausgenommenen
Stichprobe durch das Mischungsverhältnis der sämtlichen
Kugeln in der Urne gegeben wird.

Genau wie früher wird die relative Häufigkeit eines genauen
Zusammentreffens beider Verhältnisse an sich sehr gering, dagegen
die relative Häufigkeit eines angenäherten Zusammentreffens sehr
groß. Wir setzen dementsprechend wieder
\[
p' = n'\frac{u'}{m'} + x
\]
und finden dann
\[
\frac{\psi_{p+1} - \psi_p}{\psi_p}
  = -\frac{m'x}{\left\{n'\dfrac{u'}{m'} + x\right\}
              · \left\{(m' - n')\dfrac{v'}{m'} + x\right\}}
\]
oder
\[
\frac{\psi_{p+1} - \psi_p}{\psi_p}
  = -\frac{\xi}{\{w\chi + \xi\}·\{(1 - w)(1 - \chi) + \xi\}},
\]
wenn wir einführen
\[
\frac{u'}{m'} = w,\
\frac{v'}{m'} = 1 - w,\
\frac{n'}{m'} = \chi,\
\frac{m' - n''}{m'} = 1 - \chi,\
\frac{x}{m'} = \xi.
\]
\DPPageSep{141}{127}

Wir haben nun, auch vorausgesetzt, daß w nicht nahezu
gleich~$0$ oder gleich~$1$ ist, zwei Fälle zu unterscheiden. Wenn $\chi$
nahe an $0$ liegt, \dh~$n$ wohl an sich groß, aber gegen $m$ klein ist,
können wir auf der rechten Seite der Gleichung in dem einen
Faktor des Nenners den Wert~$\xi$, den wir als relativ klein voraussetzen,
gegen das erste Glied vernachlässigen, im anderen
Faktor aber nicht. Wenn wir also
\[
\frac{1}{m'} = d\xi,\quad
\psi_p = \psi(\xi),\quad
\psi_{p+1} - \psi_p = d\psi(\xi)
\]
setzen, ferner
\[
\frac{\psi_{p+1} - \psi_p}{\psi_p}
  = \frac{1}{m'}\, \frac{d \ln \psi(\xi)}{d\xi},
\]
so ergibt sich, falls wir $\chi$ sehr klein annehmen,
\[
\frac{d \ln \psi(\xi)}{d\xi} = -\frac{m'\xi}{(1 - w)(1 - \chi)(w\chi + \xi)}
\]
oder
\[
\frac{d \ln \psi(\xi)}{d\xi}
  = -\frac{m'}{(1 - w)(1 - \chi)}
   + \frac{m'}{(1 - w)(1 - \chi)} · \frac{1}{1 + \dfrac{\xi}{w\chi}}
\]
und daraus durch Integration
\[
\ln \psi(\xi)
  = \ln c - \frac{m'\xi}{(1 - w)(1 - \chi)}
  + \frac{m'w\chi}{(1 - w)(1 - \chi)} \ln\left(1 + \frac{\xi}{w\chi}\right).
\]
Führen wir hierin noch ein
\[
\frac{m'}{(1 - w)(1 - \chi)} = \gamma,\quad
w\chi = \epsilon,
\]
so können wir dafür schreiben
\[
\ln \psi(\xi)
  = \ln c - \gamma\xi + \gamma\epsilon\ln\left(1 - \frac{\xi}{\epsilon}\right).
\]

Sollte dieser Ausdruck nun direkt berechenbar sein, so müßte
zunächst $\gamma\xi$ berechenbar sein, also auch~$x$. Damit würden wir
aber zu dem Fall zurückkommen, wo nur eine mäßige Anzahl
von Werten~$p$ in Frage kommt, während die vorliegende Ableitung
sich auf den Fall bezieht, wo die Anzahl der in Betracht zu
ziehenden Werte~$p$ sehr groß ist und nur für diesen Fall Gültigkeit
hat. Wir müssen also $\gamma\xi$ als groß voraussetzen und damit
\DPPageSep{142}{128}
$\gamma\epsilon$ als sehr groß auch gegen~$\gamma\xi$. Entwickeln wir nämlich den
letzten Logarithmus in eine Reihe, so erhalten wir
\[
\ln \psi(\xi)
  = \ln c - \frac{\gamma\xi^2}{2\epsilon}
  + \frac{\gamma\xi^3}{3\epsilon^2} - \dots\DPtypo{}{.}
\]
Dieser Wert würde mit $\gamma\xi$ sehr groß werden, wenn $\gamma\epsilon$ nicht sehr
groß auch gegen $\gamma\xi$ wäre. Nun wird aber schon das Verhältnis
des dritten zum zweiten Gliede dem absoluten Werte nach
\[
= \frac{2}{3}\, \frac{\gamma\xi}{\gamma\epsilon}.
\]
Dies ist ein sehr kleiner Wert. Wir können uns also auf die zwei
ersten Glieder beschränken und finden
\begin{align*}
\ln \psi(\xi) &= \ln c - \frac{\gamma\xi^2}{2\epsilon} \\
\intertext{woraus folgt}
\psi(\xi) &= ce^{-\tfrac{\gamma\xi^2}{2\epsilon}} \\
\intertext{oder}
\Tag{(C)}
\psi(\xi) &= ce^{-h_0^2\xi^2}
\end{align*}
für
\[
h_0^2 = \frac{\gamma}{2\epsilon} = \frac{m'}{2w(1 - w)\chi(1 - \chi)}.
\]

Es ist aber $h_0$ eine sehr große, $\xi$~eine sehr kleine Zahl. Zu
berechenbaren Werten gelangen wir, wenn wir
\[
\frakx = \frac{m'\xi}{\sqrt{n'}} = \frac{x}{\sqrt{n'}},\quad
h = \frac{\sqrt{n'}}{m'} h_0
\]
einführen. Dann wird die Verteilungsfunktion
\[
\psi(\frakx) = \frac{h}{\sqrt{\pi}}\, e^{-h^2 \frakx^2},
\]
genau wie früher, und angenähert $h^2 = \dfrac{1}{2w(1 - w)}$. Dies war
zu erwarten, denn wir sahen schon, daß, wenn die Anzahl der
herausgegriffenen Kugeln klein ist im Verhältnis zu der Anzahl
der in der Urne enthaltenen Kugeln, der Fall genau so liegt, als
ob die Kugeln einzeln gezogen und nach der Ziehung jedesmal
zurückgelegt würden.
\DPPageSep{143}{129}

In dem anderen Falle, wo weder $w$ noch $\chi$ nahe an $0$ oder~$1$
liegen, können wir in den beiden Faktoren des Nenners~$\xi$ gegen
das erste Glied vernachlässigen und erhalten dann sofort
\[
\frac{d \ln \psi(\xi)}{d\xi} = -\frac{m'\xi}{w(1 - w)\xi(1 - \xi)}
\]
und daraus durch Integration
\[
\psi(\xi) = ce^{-h_0^2\xi^2},
\]
\dh~dieselbe durch die \so{Gauß}sche Funktion gegebene typische
Verteilung wie vorhin und wie in dem Falle, wo die Kugeln
einzeln gezogen und nach der Ziehung jedesmal zurückgelegt
werden. Nur hat die frühere Größe $\sqrt{\dfrac{n}{2w(1 - w)}}$, in welcher
wir $m'$ statt $n$ geschrieben zu denken haben, sich jetzt verwandelt
in
\[
h_0 = \sqrt{\frac{m'}{2w(1 - w)\chi(1 - \chi)}}.
\]
Es tritt also noch ein Faktor hinzu, der am kleinsten ist, wenn
die herausgegriffenen Kugeln die Hälfte von den in der Urne enthaltenen
Kugeln betragen, und um so größer wird, je mehr sich die
Anzahl der herausgegriffenen Kugeln von diesem Wert entfernt.
Damit die Funktionswerte in den Grenzen der Berechenbarkeit
liegen, muß~$h\xi$, \dh~auch $x:\sqrt{n'}$ einen berechenbaren Wert haben
und $x:n'$ daher einen sehr kleinen Wert. Das Mischungsverhältnis
$\dfrac{p'}{n'} = w + \dfrac{x}{n'}$ des herausgegriffenen Kugelhaufens weicht also
wenig von dem Mischungsverhältnis~$w$ der Kugeln in der Urne ab.

Aus allen bisherigen Betrachtungen hat sich uns für den Fall,
daß sich die Verteilungsreihe einer kontinuierlichen Verteilungsfunktion
nähert, immer eine bestimmte Funktion, die \so{Gauß}sche
Funktion, ergeben. Diese Funktion ist ganz besonderer Art, unter
anderem ist sie wesentlich symmetrisch.

Es gibt aber eine Erweiterung des Urnenschemas, durch
die eine wesentlich unsymmetrische Verteilung entspringt und
\DPPageSep{144}{130}
die sich als von großer Bedeutung erwiesen hat, weil sie den
Weg zeigt, wie man zu viel allgemeineren Verteilungsfunktionen
gelangen kann.

Diese Verallgemeinerung des Urnenschemas besteht darin, daß
wir uns nicht bloß eine, sondern eine ganze Anzahl von Urnen
denken, und zunächst durch das Los bestimmen, aus welcher Urne
wir ziehen wollen. Für die Anzahl Male, die wir auf diese Weise
die $i$te Urne treffen, ergibt sich hierbei eine bestimmte relative
Häufigkeit $w_i$ derart, daß, wenn wir die Summation über alle Urnen
ausdehnen,
\[
\Sum w_i = 1
\]
wird.

Denken wir uns nun die Ziehungen an der $i$ten Urne vollzogen,
so möge $u_{iz}$ die relative Häufigkeit der Fälle bezeichnen, wo das
Verhältnis der Anzahl der gezogenen weißen Kugeln zu der Anzahl
der überhaupt gezogenen Kugeln gleich $z$ ist. Wir haben dann
eine typische stationäre Reihe vor uns und es gelten die früher
abgeleiteten Beziehungen
\[
\Sum_z u_{iz} = 1,\quad
\Sum_z u_{iz} z = u_i,\quad
\Sum_z u_{iz} (z - u_i)^2 = \frac{u_i(1 - u_i)}{n}.
\]

Betrachten wir nun aber die Ziehungen so, daß wir alle Urnen
berücksichtigen, daß also von vornherein nicht entschieden ist, aus
welcher Urne wir ziehen, so müssen wir das zusammengesetzte
Ereignis ins Auge fassen, dessen erster Teil die Bestimmung der
Urne ist, aus welcher gezogen werden soll, und dessen zweiter Teil
in den Ziehungen aus der Urne selbst besteht. Für dieses zusammengesetzte
Ereignis wird nun die relative Häufigkeit
\[
w_i u_{iz}
\]
und daraus ergibt sich der Mittelwert
\[
w = \Sum_i \Sum_z w_i u_{iz} z = \Sum_i w_i u_i.
\]

Die mittlere Ausweichung haben wir durch den Ausdruck zu
bestimmen
\[
\mu^2 = \Sum_i \Sum_z w_i u_{iz} (z - w)^2.
\]
\DPPageSep{145}{131}
Diesen Ausdruck haben wir nun weiter auszurechnen. Zu dem
Zweck beachten wir zunächst, daß
\begin{align*}
\Sum_i \Sum_z w_i u_{iz} (z - u_i)^2
  &= \Sum_i w_i \frac{u_i(1 - u_i)}{n} \\
  &= \frac{w}{n} - \frac{\Sum w_i u_i^2}{n}
\end{align*}
wird. Wir finden dann weiter:
\begin{align*}
\mu^2 &= \Sum_i w_i \left[\Sum_z u_{iz} z^2 - 2\Sum_z u_{iz} z·w + w^2\right] \\
      &= \Sum_i \Sum_z w_i u_{iz} z^2 - w^2.
\end{align*}

Nun wird, da $\Sum_z u_{iz} z^2 = \Sum_z u_{iz} (z - u_i)^2 + u_i^2$,
\begin{align*}
\Sum_i\Sum_z w_i u_{iz} z^2
  &= \Sum_i\Sum_z w_i u_{iz} (z - u_i)^2 + \Sum_i w_i u_i^2 \\
  &= \frac{w}{n} - \frac{\Sum w_i u_i^2}{n} + \Sum w_i u_i^2
   = \frac{w}{n} + \frac{n - 1}{n} \Sum w_i u_i^2 \\
  &= \frac{w}{n} + \frac{n - 1}{n} \Sum w_i(u_i - w)^2 + \frac{n - 1}{n} w^2,
\end{align*}
also ergibt sich:
\[
\mu^2 = \frac{w(1 - w)}{n} + \frac{n - 1}{n} \Sum w_i(u_i - w)^2.
\]

So gelangen wir zu dem Resultat, daß die mittlere Ausweichung
\[
\mu = \sqrt{\frac{w(1 - w)}{n} + \frac{n - 1}{n} \Sum w_i(u_i - w)^2}
\]
wird, also in diesem Falle
\[
\tag*{($\gamma$)}
\mu > \sqrt{\frac{w(1 - w)}{n}}
\]
ist.

Läßt man die Anzahl der jedesmal aus einer Urne gemachten
Ziehungen unbegrenzt zunehmen, so wird die relative Häufigkeit
(oder Wahrscheinlichkeit) der Fälle, wo das Mischungsverhältnis
der gezogenen Kugeln zwischen $z$ und $z + dz$ liegt, wenn feststeht,
daß aus der $i$ten Urne gezogen wird,
\[
= e^{-h_i^2 (z - u_i)^2}\, \frac{h_i\, dz}{\sqrt{\pi}}\quad\text{für}\quad
h_i = \sqrt{\frac{n}{2u_i(1 - u_i)}}
\]
\DPPageSep{146}{132}
und damit wird die Wahrscheinlichkeit, daß überhaupt das Ziehungsverhältnis
zwischen $z$ und $z + dz$ liegt,
\[
\Tag{(D)}
\Phi(z)\, dz = \Sum_i \frac{w_i h_i}{\sqrt{\pi}}\, e^{-h_i^2(z - u_i)^2} dz.
\]

Daraus folgt sofort
\begin{align*}
\Int_{-\infty}^{+\infty} \Phi(z)\, dz &= 1,
\intertext{ferner}
\Int_{-\infty}^{+\infty} z\Phi(z)\,dz
  &= \Sum_i w_i u_i = w.
\intertext{Endlich wird}
\Int_{-\infty}^{+\infty} z^2 \Phi(z)\, dz
  &= \Sum w_i \frac{u_i(1 - u_i)}{n} + \Sum w_i u_i^2,
\end{align*}
entsprechend dem oben gefundenen Wert für~$\mu^2$.

Wir sind so zu einer Verteilungsfunktion
\[
\Phi(z) = \Sum_i\frac{w_i h_i}{\sqrt{\pi}}\, e^{-h_i^2(z - u_i)^2}\quad
(\Sum w_i = 1)
\]
gelangt, die eine sofort einleuchtende Verallgemeinerung der einfachen
\so{Gauß}schen Funktion bildet. Es ist allerdings keine ganz
leichte Aufgabe, eine vorliegende empirische Verteilungsfunktion
auf diese Form zu bringen.

Was die Lösung dieser Aufgabe anbetrifft, so erinnert sie
auf den ersten Anblick stark an die viel einfachere Aufgabe der
Entwickelung einer gegebenen periodischen Funktion in eine
\so{Fourier}sche Reihe, aber bei näherem Zusehen bemerkt man doch
bald die tiefgreifende Verschiedenheit beider Entwickelungen. Zwar
kann man in beiden Fällen sagen, daß die wirklich vorhandene
Funktion aus gewissen Teilfunktionen, im einen Falle die wirkliche
Schwingung aus Sinusschwingungen, im anderen Falle die wirkliche
Dispersion aus typischen (der \so{Gauß}schen Verteilungsfunktion
folgenden) Dispersionen zusammengesetzt wird. Aber
während im Falle der \so{Fourier}schen Reihe die nähere Bestimmung
der Teilschwingungen durch einfache Teilung der ganzen Periode
\DPPageSep{147}{133}
in gleiche Teile gewonnen wird, sind im Falle der Entwickelung
einer Verteilungsfunktion nach \so{Gauß}schen Funktionen in jeder
von diesen zwei zu bestimmende Konstanten, $h_i$ und $u_i$, enthalten.
Will man diese Konstanten nicht von vornherein, sondern so bestimmen,
daß eine möglichste Annäherung an die wirkliche Verteilung
bei einer möglichst geringen Anzahl von Entwickelungsgliedern
erreicht wird, so erhält man schon in dem Falle, wo
die Entwickelung aus nur zwei Gliedern besteht, eine ziemlich
schwierige Rechnung. Es liegt daher nahe, die Reihenentwickelung
einer vorgelegten Verteilungsfunktion auf ganz anderem
Wege zu versuchen. Der einfachste Weg wäre der, daß man
nicht von der Funktion selbst, sondern von ihrer logarithmischen
Derivierten ausgeht und diese in eine gewöhnliche Potenzreihe
entwickelt. Für die Verteilungsfunktion selbst ergibt sich dann
ein Ausdruck
\[
\psi(z) = e^{a_0 + a_1z + a_2z^2 + a_3z^3 + \dots}.
\]
Ein anderer, anscheinend besserer Weg ist der, daß das Produkt
der gegebenen Verteilungsfunktion und einer Funktion $e^{h^2(z - c)^2}$
in eine Potenzreihe $a_0 + a_1z + a_2z^2 + \dots$ entwickelt wird. Für
die Verteilungsfunktion selbst ergibt sich dann ein Ausdruck
\[
\psi(z) = e^{-h^2(z - c)^2} (a_0 + a_1z + a_2z^2 + \dots).
\]
Man kann diese Entwickelung auch so fassen, daß man von der
Funktion $\phi(z) = e^{-h^2(z - c)^2}$ die sukzessiven Derivierten $\phi_1(z),
\phi_2(z), \dots$ einführt und dann setzt
\[
\psi(z) = b_0\phi(z) + b_1\phi_1(z) + b_2\phi_2(z) + \dots.
\]
Was diese Form der Entwickelung betrifft, so sei insbesondere
auf H.~\so{Bruns}, Wahrscheinlichkeitsrechnung und Kollektivmaßlehre
\index{Bruns}%
(Leipzig und Berlin 1906) verwiesen, wo die allgemeine Lösung
in einer allerdings nicht ganz leicht zu übersehenden Weise
gegeben ist.
\EndChap
\DPPageSep{148}{134}


\Chapter{Neuntes Kapitel}{Die statistische Theorie des Zufalls}

Es handelt sich nun darum, aus den Entwickelungen der
letzten Kapitel sozusagen die Nutzanwendung zu ziehen, indem
wir in dem ganzen Bereich der Wirklichkeit die Erscheinungen
suchen, die dem Schema der Zufallsspiele entsprechen. Dieses
Entsprechen kann sich zunächst nur dadurch kundgeben, daß die
Verteilung der empirisch festgestellten Zahlenwerte dieselbe ist,
wie sie sich bei der Aufzeichnung der statistischen Ergebnisse im
Falle häufiger Wiederholung des Zufallsspiels, im besonderen bei
der Aufzeichnung der Ziehungsresultate, wenn das Zufallsspiel in
den Ziehungen aus einer Urne besteht, ergeben würde. Wir
wollen die Frage, inwieweit die äußere Übereinstimmung der
statistischen Ergebnisse auch auf eine innere Gleichartigkeit der
verglichenen Vorgänge schließen läßt, einstweilen beiseite lassen
und vielmehr nur danach fragen, inwieweit die Übereinstimmung
der statistischen Ergebnisse erreicht werden kann und wie man
beurteilen soll, ob sie in hinreichender Weise vorhanden ist. Dies
ist nicht so ganz einfach zu entscheiden, weil man bei der verhältnismäßig
geringen Anzahl von Beobachtungen, die man meistens
nur zur Verfügung hat, nicht eine völlige Regelmäßigkeit erwarten
darf, vielmehr müssen die so gefundenen Werte mehr oder minder
beträchtlich von den Zahlen abweichen, die sich bei unendlicher
Häufung der Beobachtungen herausstellen würden.

Die statistischen Ergebnisse der Ziehungen aus der Urne
werden nicht wirklich aufgezeichnet, sie erscheinen ersetzt durch
die Formeln, welche wir bereits abgeleitet haben, und welchen die
Bedeutung zukommt, daß sie den aus bestimmten theoretischen
Erwägungen gefolgerten Ersatz für eine die wirklichen Ziehungsergebnisse
bei einer sehr großen Zahl von Ziehungen registrierende
Tabelle liefern. Wir haben so bestimmte Formeln, denen die aus
\DPPageSep{149}{135}
der Gesamtheit alles Geschehens herauszugreifenden Vorgänge in
ihren statistischen Ergebnissen zu entsprechen haben, \dh~wenn
wir diese Ergebnisse graphisch auftragen, muß die Formel eine
Kurve liefern, die verhältnismäßig nahe an den die statistischen
Ergebnisse darstellenden Punkten vorbeiläuft. Wir können dies
auch so ausdrücken, daß wir sagen: die Unterschiede zwischen den
empirisch festgestellten und den aus der Formel folgenden Werten
müssen eine stationäre Reihe bilden, die sich um den Mittelwert~$0$
gruppiert. Die sich so ergebende stationäre Reihe läßt sich aber
meistens nicht mit genügender Sicherheit beurteilen, teils weil
ihre Gliederzahl zu gering ist, teils weil die Genauigkeit der bestimmten
Unterschiede verhältnismäßig zu klein ist. So ist eine
exakte Beurteilung der vorliegenden Verteilungsreihe auf diesem
Wege meistens nicht möglich. Deswegen ist es von Wichtigkeit,
bestimmte zahlenmäßige Feststellungen zu haben, die wenigstens
eine vorläufige Beurteilung, inwieweit die vorliegende Verteilungsreihe
sich dem abgeleiteten Schema anpaßt, ermöglichen.

Diese zahlenmäßigen Feststellungen ergeben sich aus dem Gedanken,
daß, wenn die gefundene Verteilungsreihe die Form einer
aus dem Urnenschema folgenden Verteilungsreihe hat, auch für
sie die Beziehungen gelten müssen, die wir bei dem Urnenschema
fanden. Von solchen Beziehungen war die erste die Relation,
die wir bei dem ersten Urnenschema, den Ziehungen einer Kugel
aus einer Urne, zwischen dem Mischungsverhältnis und der mittleren
Ausweichung der entstehenden Verteilungsreihe erhielten.
\index{Lexis|ff}%
Diese Relation hat \so{Lexis}\footnote
  {Vgl.\ die grundlegende Schrift Zur Theorie der Massenerscheinungen
  in der menschlichen Gesellschaft, Freiburg~1877.}
benutzt, um einen ersten Anhaltspunkt
dafür zu gewinnen, inwiefern die Dispersionen, die sich bei statistischen
Verhältniszahlen ergeben, sich mit der aus dem einfachen
Urnenschema folgenden Verteilungsreihe vergleichen lassen. Zur
Aufstellung der Relation ist notwendig, daß zuerst der Durchschnittswert
$y_0$ der sämtlichen beobachteten $r$ Verhältniszahlen~$y_i$
berechnet wird. Daraus wird der Wert für die mittlere Ausweichung
$\mu_1$ in folgender Weise bestimmt (indem $y_0$ an die Stelle
von $w$ tritt):
\[
\Tag{(1)}
\mu_1 = \sqrt{\frac{y_0(1 - y_0)}{n}},
\]
\DPPageSep{150}{136}
wenn $n$ die Durchschnittsanzahl der Fälle bezeichnet, auf die sich
die einzelnen Verhältniswerte beziehen. Dieses Verfahren bezeichnet
\so{Lexis} als die \so{statistische Methode}. Ihr steht die
sogenannte \so{physikalische Methode} gegenüber, bei welcher die
mittlere Ausweichung nach der Formel
\[
\Tag{(2)}
\mu_2 = \sqrt{\frac{\Sum(y_i - y_0)^2}{r - 1}}
\]
bestimmt wird, indem der Fehlertheorie entsprechend $r - 1$ statt
$r$ genommen wird, was an sich belanglos ist (vgl.\ S.~88). Entspricht
die Verteilungsreihe dem einfachen Urnenschema, so müssen die
beiden gefundenen Werte gleich sein. \so{Lexis} setzt daher
\[
\Tag{(3)}
Q = \frac{\mu_2}{\mu_1},
\]
und spricht von einer \so{normalen Dispersion}, wenn wenigstens
angenähert
\[
Q = 1
\]
ist. Wird dagegen $Q > 1$, so spricht er von einer \so{übernormalen
Dispersion} und im Falle $Q < 1$ von einer \so{unternormalen
Dispersion}. Der Wert~$Q$ wird neuerdings als
\so{Divergenzkoeffizient} bezeichnet. Zu beachten ist von vornherein,
daß seine Bildung nur dann einen Sinn hat, wenn $\mu_1$
und $\mu_2$ nicht zu klein sind, weil sonst aus der geringsten Abweichung
in $\mu_1$ oder $\mu_2$ eine große Schwankung im Werte von $Q$
entstehen würde. Insbesondere darf also $y_0$ weder nahe an $0$ noch
nahe an $1$ liegen.

Um einen Begriff davon zu geben, wie sich die Werte des
Divergenzkoeffizienten~$Q$ in der Wirklichkeit gestalten können,
wollen wir mit \so{Lexis}\footnote
  {Conrads Jahrbücher für Nationalökonomie und Statistik, Bd.~32
  (1879), S.~60.}
das Beispiel des \so{Verhältnisses der
Sterblichkeiten für das männliche und weibliche Geschlecht
in den verschiedenen Lebensaltern} nehmen. Die
Zahlen entstammen der belgischen Statistik für die Jahre~1841
bis~1860. Die Kolumne unter $z$ gibt an die Anzahl der gestorbenen
männlichen Individuen auf $1000$ weibliche.
\DPPageSep{151}{137}
\begin{table}[hbt!]
%[** TN: Original uses em-dashes for ranges]
\[
\begin{array}{l||r|lTl||r|l}
\hline
\hline
\ColHeadbb{Alter}{Alter} &
\ColHeadb{$z$}{$z$} &
\ColHeadB{$Q$}{$Q$} &
\ColHeadbb{Alter}{Alter} &
\ColHeadb{$z$}{$z$} &
\ColHead{$Q$}{$Q$} \\
\hline
\hline
\text{Totgeboren}                  &1348&0,99&\text{$15\EnDash20$ Jahre} & 770&2,1 \\
\text{$\Z0\EnDash\Z1$ Monat}         &1359&0,84&\text{$20\EnDash25$ \Ditto}&1095&1,7 \\
\text{$\Z1\EnDash\Z2$ Monate}        &1323&1,15&\text{$25\EnDash30$ \Ditto}& 905&1,5 \\
\text{$\Z2\EnDash\Z3$ \Ditto[Monate]}&1253&0,91&\text{$30\EnDash40$ \Ditto}& 826&2,1 \\
\text{$\Z3\EnDash\Z4$ \Ditto[Monate]}&1224&1,14&\text{$40\EnDash45$ \Ditto}& 943&2,3 \\
\text{$\Z4\EnDash\Z5$ \Ditto[Monate]}&1284&1,04&\text{$45\EnDash50$ \Ditto}&1143&3,4 \\
\text{$\Z5\EnDash\Z6$ \Ditto[Monate]}&1257&1,06&\text{$50\EnDash55$ \Ditto}&1124&4,3 \\
\text{$\Z6\EnDash\Z9$ \Ditto[Monate]}&1179&1,13&\text{$55\EnDash60$ \Ditto}&1055&4,3 \\
\text{$\Z9\EnDash12$  \Ditto[Monate]}&1085&1,12&\text{$60\EnDash65$ \Ditto}& 962&3,5 \\
\text{$\Z1\EnDash\Z2$ Jahre}         &1028&1,53&\text{$65\EnDash70$ \Ditto}& 913&4,3 \\
\text{$\Z2\EnDash\Z3$ \Ditto}        & 990&1,06&\text{$70\EnDash75$ \Ditto}& 906&4,1 \\
\text{$\Z3\EnDash\Z5$ \Ditto}        & 947&1,16&\text{$75\EnDash80$ \Ditto}& 903&2,1 \\
\text{$\Z5\EnDash10$  \Ditto}        & 878&1,66&\text{$80\EnDash85$ \Ditto}& 866&1,26\\
\text{$10\EnDash15$   \Ditto}        & 713&2,5 &\text{$85\EnDash90$ \Ditto}& 800&1,29\\
\end{array}
\]
\end{table}

Aus dieser Tabelle geht hervor, daß während des ersten
Lebensjahres die Dispersion als eine normale angesehen werden
kann, ja sogar während der ersten fünf Jahre, da der einzige zu
große Wert~$1,53$ in den Mängeln der Statistik begründet sein kann.
Während der folgenden Jahre finden wir dagegen zum Teil sehr
weitgehende Abweichungen von dem Normalwert~$1$. In der Tat
läßt sich eine solche Übereinstimmung, wie sie für die normale Dispersion
gefordert wird, nur aus einer vermuteten Gemeinsamkeit
gewisser allgemeiner Eigenschaften des vorliegenden Ereignisses mit
den Vorgängen bei den Ziehungen aus einer Urne erklären. Daß
eine solche Gemeinsamkeit aber nur in sehr vereinzelten Fällen angenommen
werden kann, liegt auf der Hand, und so finden sich
nur wenige Fälle, in denen wirklich angenähert $Q = 1$ wird.

Wir haben aber nachgewiesen, daß auch die Fälle, wo $Q \neq 1$
wird, sich auf Grund eines abgeänderten Urnenschemas erklären
lassen. Nahmen wir nämlich an, daß das Mischungsverhältnis
der schwarzen und weißen Kugeln in der Urne nicht von vornherein
feststeht, sondern während der Ziehungen sich ändert (wir
setzten voraus, es sei eine ganze Reihe von Urnen mit allen möglichen
Mischungsverhältnissen vorhanden, und ließen die einzelnen
Ziehungen aus je einer durch das Los oder sonstwie bestimmten
Urne stattfinden), dann zeigte sich, daß die Verteilung der Ziehungsergebnisse
wohl noch, wenn die Reihenfolge der gewählten Urnen
\DPPageSep{152}{138}
von der einen zur anderen Ziehungsreihe festgehalten wurde, der
gleichen Verteilungsfunktion wie früher, nämlich der \so{Gauß}schen
Funktion folgte, aber die Beziehung $\mu_2 = \mu_1$ zwischen den oben
angegebenen Werten \Eqref{(1)}~und~\Eqref{(2)} aufhörte zu bestehen und in die
Ungleichheit
\[
\mu_2 < \mu_1
\]
überging, so daß sich $Q < 1$, also eine unternormale Dispersion
ergibt. Nennen wir also das Mischungsverhältnis der Kugeln in
der Urne jedesmal die dem Ereignis (\dh~der Ziehung) zugrunde
liegende Wahrscheinlichkeit, so würde sich das allgemeine Resultat
herausstellen:

\so{Die unternormale Dispersion läßt sich erklären
durch eine dem Ereignis zugrunde liegende, von Fall zu
Fall wechselnde Wahrscheinlichkeit.}

Andererseits hatten wir gefunden, daß, wenn die Ziehungen
einer Reihe immer aus derselben Urne stattfinden, aber unter den
Urnen mit allen möglichen Mischungsverhältnissen diejenige, aus
welcher gezogen werden soll, erst durch das Los bestimmt wird,
dann sich eine Verteilung ergibt, bei der
\[
\mu_2 > \mu_1,
\]
die Dispersion also eine übernormale ist.

\so{Die übernormale Dispersion läßt sich also dadurch
erklären, daß die dem Ereignis zugrunde liegende Wahrscheinlichkeit
wohl bei allen den Fällen, die zur Bildung
dieses Wertes der relativen Häufigkeit benutzt wurden,
dieselbe ist, aber nicht dieselbe bei den verschiedenen
Gruppen von Fällen, die zu der Bildung der einzelnen
relativen Häufigkeitswerte benutzt sind.}

Damit ist in der Tat eine gewisse Erklärung für das Auftreten
und die Unterscheidung der drei verschiedenen Dispersionsarten
gefunden\footnote
  {Der Grundgedanke und ein Teil der analytischen Entwickelung
  bei dieser Erklärung geht auf \so{Poisson} zurück; die Deutung der übernormalen
\index{Poisson}%
  Dispersion, die \so{Lexis} ausführlich erörtert hatte, hat insbesondere
  v.~\so{Bortkewitsch} (Das Gesetz der kleinen Zahlen, 1898,
\index{Bortkewitsch@Bortkewitsch (Bortkiewicz), Lad.\ v.}%
  S.~29) noch weiter ausgestaltet. Man vgl., was allgemein die Anwendung
  der Wahrscheinlichkeitsrechnung auf Statistik betrifft, desselben
  Verfassers Kritische Betrachtungen zur theoretischen Statistik, Conrads
  Jahrbücher~(3), Bd.~8, S.~641; Bd.~10, S.~321; Bd.~11, S.~671 (1894--1896).}.
Man darf aber die Bedeutung dieser Erklärung
\DPPageSep{153}{139}
nicht überschätzen. Vor allem ist schwer einzusehen, wie sich
in der Wirklichkeit eine von Fall zu Fall wechselnde, aber bei
jeder Gruppe von Fällen in der gleichen Weise wiederkehrende
Wahrscheinlichkeit ergeben soll. Nicht viel natürlicher ist die
Annahme, daß bei jeder Gruppe von Fällen eine andere, aber bei
den einzelnen Fällen einer Gruppe dieselbe Wahrscheinlichkeit
vorhanden sein soll, denn die Einteilung der Fälle in Gruppen,
an denen man die relative Häufigkeit bestimmt, ist doch meist
eine an sich willkürliche, und die Fälle schließen sich örtlich und
zeitlich kontinuierlich aneinander an. Man wird sich daher
darauf beschränken müssen, zu sagen: \so{ein Wechsel der Wahrscheinlichkeit
innerhalb einer Gruppe von Fällen verringert
die Dispersion, ein Wechsel von einer Gruppe
zur anderen erhöht sie.}

Es bleibt noch übrig, kurz der anderen Deutungsart zu
gedenken, wo die Kugeln aus der Urne nicht einzeln, sondern auf
einmal gezogen werden. In diesem Falle tritt in dem Ausdruck
für die mittlere Ausweichung unter der Wurzel zu $w(1 - w)/n$ noch
ein Faktor $\chi(1 - \chi)$ hinzu, der immer $<1$ ist, es ergibt sich also
\[
\mu_2 < \mu_1
\]
und demnach wird
\[
Q < 1,
\]
die Dispersion ist also unternormal. Diese Erklärung der unternormalen
Dispersion scheint an sich sehr einleuchtend. Aber
wieder erhebt sich der Einwand, daß es meistens durchaus nicht
der Wirklichkeit entspricht, wenn die Fälle einer Gruppe als eine
natürliche Gesamtheit angesehen werden, wie es doch geschieht,
wenn sie durch die mit \so{einem} Griff aus der Urne herausgeholten
Kugeln illustriert werden. Immerhin könnte man ja vermuten,
daß gerade da die unternormale Dispersion sich einstellt, wo die
Verhältniszahlen sich in gewisser Weise auf solche natürliche
Gruppen beziehen.

Das bekannteste Beispiel für eine vermutliche normale Dispersion
bildet das \so{Geschlechtsverhältnis der Geborenen}.
Auch dieses hat \so{Lexis} ausführlich behandelt (Conrads Jahrbücher
für Nationalökonomie und Statistik, Bd.~27 (1876), S.~206; Abhandlungen
zur Theorie der Bevölkerungs- und Moralstatistik, 1903,
S.~130), indem er die Zahlen für die verschiedenen preußischen
\DPPageSep{154}{140}
Regierungsbezirke in den einzelnen Monaten der Jahre~1868
und~1869 zugrunde legte. Wir wollen seine Resultate nur für
die größten Bezirke anführen. Es ergibt sich:
\[
\begin{array}{l||c|c}
\hline
\hline
\ColHeadbb{Bezirk}{Bezirk} &
\ColHeadb{$n$}{$n$} &
\ColHead{$Q$}{$Q$} \\
\hline
\hline
\DotBox{Königsberg} & 3426 & 1,06 \\
\DotBox{Potsdam}    & 3028 & 0,96 \\
\DotBox{Frankfurt}  & 3211 & 0,98 \\
\DotBox{Posen}      & 3738 & 1,01 \\
\DotBox{Breslau}    & 4766 & 0,89 \\
\DotBox{Oppeln}     & 4855 & 0,92 \\
\DotBox{Magdeburg}  & 3650 & 1,02 \\
\DotBox{Düsseldorf} & 4305 & 1,12 \\
\end{array}
\]

Die Zahlen $n$ beziehen sich auf die Geburten während eines
Monates. Die Werte von $Q$ kommen hier der Einheit so nahe, wie
man es überhaupt erwarten kann, so daß wir hier in der Tat mit ziemlicher
Sicherheit von einer normalen Dispersion sprechen können.

Trotzdem wäre der Schluß übereilt, daß wir mit Gewißheit
annehmen können, in dem Geschlechtsverhältnis der Geborenen
liege der Typus einer rein zufälligen Verteilung vor. Abgesehen
davon, daß die bloße Bestimmung des Divergenzkoeffizienten~$Q$
allein dafür nicht ausreichend ist, beruht die Annäherung an
den Wert~$1$, die \so{Lexis} gefunden hat, wie es scheint, auf der
günstigen Auswahl der Beobachtungsbezirke und der verhältnismäßig
kurz genommenen Beobachtungsdauer. Jedenfalls gelangt
man zu anderen Ergebnissen, wenn man als Beobachtungsdauer statt
eines Monates je ein Jahr und als Beobachtungsbezirk das Königreich
Sachsen nimmt\footnote
  {Vgl.\ E.~\so{Blaschke}, Vorlesungen über mathematische Statistik,
\index{Blaschke}%
  Leipzig 1906; H.~\so{Forcher}, Die statistische Methode als selbständige
\index{Forcher}%
  Wissenschaft, Leipzig 1913.}.
Es ergeben sich folgende Werte für das Verhältnis~$y$
der männlichen Geburten zu der Gesamtzahl der Geburten:
\[
\small
\begin{array}{@{}c||cTc||cTc||cTc||c@{}}
\hline
\hline
\ColHeadbb{Jahr}{Jahr} &
\ColHeadB{$y$}{$y$} &
\ColHeadbb{Jahr}{Jahr} &
\ColHeadB{$y$}{$y$} &
\ColHeadbb{Jahr}{Jahr} &
\ColHeadB{$y$}{$y$} &
\ColHeadbb{Jahr}{Jahr} &
\ColHead{$y$}{$y$} \\
\hline
\hline
1891 & 0,512\,14 & 1896 & 0,513\,01 & 1901 & 0,511\,77 & 1906 & 0,511\,14 \\
1892 & 0,513\,94 & 1897 & 0,512\,83 & 1902 & 0,512\,43 & 1907 & 0,512\,35 \\
1893 & 0,512\,13 & 1898 & 0,511\,85 & 1903 & 0,510\,19 & 1908 & 0,511\,04 \\
1894 & 0,510\,36 & 1899 & 0,512\,90 & 1904 & 0,512\,86 & 1909 & 0,513\,21 \\
1895 & 0,512\,14 & 1900 & 0,514\,87 & 1905 & 0,513\,20 & 1910 & 0,512\,02 \\
\end{array}
\]
\DPPageSep{155}{141}

Für die Periode 1891 bis 1900 findet man hieraus den Wert
$Q = 0,904$, für die Periode 1901 bis 1910 den Wert $Q = 0,705$.
Diese Übereinstimmung ist weit weniger gut als die von \so{Lexis}
gefundene.

Daß die Verschiedenheiten der Verhältniszahlen für die einzelnen
Jahre nicht auf bloßen Zufälligkeiten beruhen, kann man
aus den Zahlen für das gesamte Deutsche Reich während der
letzten Jahre ersehen. Es entfallen auf $100$ Mädchengeburten an
Knabengeburten:
\[
\begin{array}{l@{}c|l@{}c}
\DotBox{1906} & 106,0 & \DotBox{1910} & 105,9 \\
\DotBox{1907} & 106,3 & \DotBox{1911} & 106,1 \\
\DotBox{1908} & 106,1 & \DotBox{1912} & 106,5 \\
\DotBox{1909} & 105,9 && \\
\end{array}
\]

Dabei erscheint auffallend die Steigerung im letzten Jahre
1912. Sieht man nun zu, wie sie zustande gekommen ist, so
erkennt man merkwürdigerweise, daß sie wesentlich von den süddeutschen
Staaten herrührt. Die Zahl hat sich in Preußen von
$106,4$ für 1911 nur auf $106,5$ für 1912 bewegt, während wir für
die süddeutschen Staaten finden:
\[
\begin{array}{l||c|c}
\hline
\hline
& \ColHeadb{1911}{1911} & \ColHead{1912}{1912} \\
\hline
\hline
\DotBox[4cm]{Bayern}           & 105,9 & 106,8 \\
\DotBox[4cm]{Württemberg}      & 103,6 & 106,4 \\
\DotBox[4cm]{Baden}            & 105,3 & 106,0 \\
\DotBox[4cm]{Elsaß-Lothringen} & 105,3 & 106,5 \\
\end{array}
\]
Es ist danach kein Zweifel, daß wesentlich auf diesen verhältnismäßig
bedeutenden Verschiebungen auch die Änderung in der
Gesamtziffer beruht.

Der starke Einfluß des Landes auf das Geschlechtsverhältnis
der Geborenen ist bekannt. Es kamen \zB~auf $100$ Mädchengeburten
während des Zeitraumes 1887 bis 1891 an Knabengeburten
\[
\begin{array}{l@{}c}
\DotBox{in England} & 103,6 \\
\DotBox{in Spanien} & 108,3 \\
\end{array}
\]

Nach \so{Bertillon} (Anhang zum Annuaire statistique de la
\index{Bertillon}%
ville de Paris für 1905, Paris 1907) übt das Alter der Mutter
einen deutlich erkennbaren Einfluß auf das Geschlecht des Kindes
\DPPageSep{156}{142}
aus. Nach den Erhebungen in Paris 1891 bis~1905 ergeben sich
auf $100$ Mädchengeburten folgende Zahlen von Knabengeburten:
\[
\small
\begin{array}{l|*{6}{c|}c}
\hline\hline
\ColHeadb{Alter der}{Alter der\\Mutter:} &
15 \EnDash 19 &
20 \EnDash 24 &
25 \EnDash 29 &
30 \EnDash 34 &
35 \EnDash 39 &
40 \EnDash 44 &
45 \EnDash 49 \\
\hline\hline
\text{Eheliche} &
107,1 & 106,2 & 106,4 & 106,5 & 106,6 & 113,0 & 105,0 \\
\text{Uneheliche} &
104,5 & 105,3 & 102,2 & 105,0 & 103,7 & 112,1 & 102,1 \\
\end{array}
\]
Es zeigt sich also eine deutliche Zunahme der Knabengeburten
für die mittleren Lebensjahre der Mutter.

Die Bestimmung des Divergenzkoeffizienten~$Q$ ist gewissermaßen
der erste Schritt zur Beurteilung der Dispersion. Sie gibt
\zB~noch keinen Anhaltspunkt für die Beurteilung einer vorhandenen
Asymmetrie. Hierfür ist, wie wir bereits gesehen haben,
von Wichtigkeit, daß außer dem arithmetischen Mittel auch der
Zentralwert, unter dem und über dem gleich viel der Beobachtungswerte
liegen, und der Normalwert, für den sich in der aus der
Urreihe abgeleiteten Verteilungsreihe die größte relative Häufigkeit
ergibt, gebildet werden.

Fallen diese drei Werte zusammen, so liefert dies einen Anhaltspunkt
dafür, daß die Dispersion eine symmetrische ist. Wir haben
also folgende drei Werte zu bestimmen:

1. Den Durchschnittswert der Beobachtungswerte
\[
y_0 = \frac{\Sum y_i}{r}
\]
oder, wenn wir die Verteilungsfunktion $\phi(y)$ einführen,
\[
\Tag{(4)}
y_0 = \Int_{-\infty}^{+\infty} \phi(y) y\, dy
    : \Int_{-\infty}^{+\infty} \phi(y)\, dy.
\]

2. Den Zentralwert~$y_z$, für den
\[
\Tag{(5)}
\Int_{-\infty}^{y_z} \phi(y)\, dy = \Int_{y_z}^{+\infty} \phi(y)\, dy
\]
wird.

3. Den Normalwert~$y_a$, für den
\[
\Tag{(6)}
\phi(y_a) = \text{Max.}
\]
\DPPageSep{157}{143}
wird. Dann muß, wenn eine symmetrische Verteilung vorliegt,
\[
y_0 = y_z = y_a
\]
werden. Dieser Wert kann als der \so{typische Wert} bezeichnet
werden.

Man wird sich nun aber schwer entschließen, mit dieser Bestimmung
die Beurteilung der Verteilungsreihe abzuschließen. Der
letzte Zielpunkt muß vielmehr sein, ein "`Gesetz"' für die Verteilung
selbst herauszufinden. Auch dazu kann die Betrachtung des
Urnenschemas dienen. Hierbei hat sich uns überall, wo die Anzahl
der beobachteten Fälle sehr groß war, die \so{Gauß}sche Verteilungsfunktion
ergeben, und wenn wir eine allgemeinere Verteilungsfunktion
erstrebten, so mußten wir sie uns aus der Übereinanderlagerung
\so{Gauß}scher Funktionen hervorgegangen denken (ähnlich
wie man sich die allgemeine Schwingung aus der Superposition
von Sinuswellen hervorgegangen denkt). Das legt es nahe, zunächst
zu versuchen, wie weit man mit der einfachen \so{Gauß}schen
Verteilungsfunktion kommt. In diesen Fällen kann, wie wohl
nicht mehr besonders hervorgehoben zu werden braucht, die
Dispersion sowohl eine normale als auch eine unter- oder übernormale
sein, die Gültigkeit des \so{Gauß}schen Verteilungsgesetzes
und die \so{Lexis}sche Beurteilung der normalen Dispersion fallen
keineswegs zusammen. Es zeigt sich nun, daß unter der Voraussetzung
einer \so{typischen} Dispersion, die der \so{Gauß}schen Funktion
\[
\phi(x) = \frac{h}{\sqrt{\pi}}\, e^{-h^2 x^2}
\]
folgt, sich für die Konstante $h$ in dieser Funktion eine dreifache
Bestimmung ergibt. Die eine Bestimmung benutzt die Werte,
unter oder über denen ein Viertel der beobachteten Zahlenwerte
liegt. Nennt man $\sigma$ den Unterschied dieser Werte, so wird
\[
\Tag{(7)}
\frac{1}{h_1} = \frac{\sigma}{0,9539}.
\]
Die zweite Formel benutzt die Summe der Abweichungen~$y$ aller
Beobachtungswerte, \dh~aller Glieder~$y$ der Urreihe, die über
oder unter dem Mittelwert liegen, von diesem Mittelwert. Ist $r$
die Gesamtzahl aller bestimmten Werte, so folgt
\DPPageSep{158}{144}
\[
\Tag{(8)}
\frac{1}{h_2}
  =  2 \sqrt{\pi}\, \frac{\Sum_{+} (y_i - y_0)}{r}
  = -2 \sqrt{\pi}\, \frac{\Sum_{-} (y_i - y_0)}{r},
\]
wenn $\Sum_{+}$, $\Sum_{-}$ bedeutet, daß die Summation über alle positiven oder
alle negativen Werte der Differenz $y_i - y_0$ erstreckt werden soll.
Die dritte Bestimmung beruht auf der Quadratensumme aller vorkommenden
Abweichungen vom Mittelwert und liefert
\[
\Tag{(9)}
\frac{1}{h_3} = \sqrt{2\frac{\Sum (y_i - y_0)^2}{r - 1}}.
\]
Der letzte Wert stimmt bis auf den Faktor~$\sqrt{2}$ mit der mittleren
Ausweichung $\mu_2$ überein. Wenn man im vorliegenden Falle diese
Bestimmungen verwerten will, so muß man alle überhaupt vorliegenden
Bestimmungen, die sich auf die einzelnen Monate der
Jahre 1868 und 1869 beziehen, zusammenfassen und erhält dann
eine Gesamtheit von $816$ Einzelbestimmungen. \so{Lexis} zieht es
aber vor, zunächst eine Gruppe aus den $17$ größten Bezirken zu
wählen, zu denen auch die oben angeführten gehören. Es liegen
dann nur $408$ Einzelbestimmungen vor, für die sich in der Tat
nach den drei möglichen Methoden derselbe Mittelwert $1065,8$
und folgende Verteilungsreihe ergibt:
\[
\begin{array}{c||c|c}
\hline\hline
\ColHeadbb{Abweichung}{Abweichung} &
\multicolumn{2}{c}{\text{\thsize Beobachtete Fälle}} \\
\cline{2-3}
\ColHeadbb{$+$ $-$}{$+$ $-$} &
\ColHeadb{\qquad\qquad}{$+$} &
\ColHead{\qquad\qquad}{$-$} \\
\hline\hline
\Z0 \EnDash \Z20  &  82 &  73 \\
 20 \EnDash \Z40  &  57 &  65 \\
 40 \EnDash \Z60  &  41 &  43 \\
 60 \EnDash \Z80  &  16 & \Z9 \\
 80 \EnDash  100  & \Z5 & \Z9 \\
\PadTxt[r]{$80$\EnDash}{Über } 100 & \Z3 & \Z5 \\
\end{array}
\]

Führt man nun die drei Bestimmungen von $h$ aus, so ergeben
sich die Werte
\[
h_1 = 0,018,\qquad
h_2 = 0,019,\qquad
h_3 = 0,019,
\]
also eine gute Übereinstimmung.

Rechnet man aber mit Hilfe des bestimmten Normalwertes
und des Wertes von $h$ nach der \so{Gauß}schen Funktion die Häufigkeitszahlen
aus, so findet man die folgenden Zahlenreihen:
\DPPageSep{159}{145}
\[
\begin{array}{l@{\,}*{6}{r<{\quad}}}
\DotBox{Berechnet} &   82&  61&  37&  17&   5&   2 \\
\multirow{2}{*}{Beobachtet %
  $\dots\biggl\{\begin{array}{@{}c@{}}+\\-\end{array}$}
& 82 & 57 & 41 & 16& 5 & 3 \\
& 74 & 65 & 43 &  9& 9 & 5 \\
\end{array}
\]
Bei der Beurteilung der so erreichten Übereinstimmung muß man
die Unsicherheit bedenken, die an sich wegen der verhältnismäßig
geringen Zahl beobachteter Fälle vorhanden ist. Dann muß in
der Tat die gefundene Übereinstimmung als eine sehr gute gelten.

Um noch ein Beispiel zu haben, das von vornherein jeder
solchen Bestimmung zu spotten scheint, wollen wir mit \so{Pearson} das
\index{Pearson|ff}%
Verhältnis der unionistischen Stimmen zur Gesamtzahl der Stimmen
bei den englischen Wahlen im Jahre 1891 nehmen. Wir haben
\begin{figure}[hbt!]
  \centering
%[** TN: Verbal part of caption lies below figure in the original.]
  \caption{Fig.~8. Verhältnis der unionistischen Stimmen zur Gesamtzahl der Stimmen
    bei den englischen Wahlen 1891.}
  \Input{159}
\end{figure}
die herauskommende Verteilungsreihe graphisch aufgezeichnet, indem
für die Abszisse die Prozente der Stimmenzahl und für die
Ordinate die zugehörigen Anzahlen von Wahlbezirken genommen
sind. Für den zugrunde zu legenden typischen Wert ergibt sich
$0,51 = 51$~Proz.\ und die drei Bestimmungen von $h_i$ liefern:
\[
h_1 = 0,09,\qquad
h_2 = 0,11,\qquad
h_3 = 0,12.
\]
Die Verteilung, die sich nach der \so{Gauß}schen Funktion ergibt,
ist durch die eingezeichnete Kurve angedeutet.

Die Übereinstimmung, die man hier erhält, darf man aber
nicht so deuten, als ob die herauskommenden Prozentsätze der
Stimmenzahl mit den Ziehungsverhältnissen des Urnenschemas
direkt verglichen werden könnten. Die überhaupt möglichen
\DPPageSep{160}{146}
Prozentsätze von $0$ bis $100$ Proz.\ entsprechen vielmehr alle einem
nur zwischen sehr engen Grenzen schwankenden Ziehungsverhältnis.
Es werden gar nicht mehr die Verhältniswerte als solche verglichen,
sondern nur die herauskommenden Verteilungsreihen. Die
Vergleichung wird damit viel äußerlicher. Wir vergleichen nicht
mehr den wirklichen Vorgang selbst mit dem Vorgang bei den
Ziehungen aus einer Urne. Wir versuchen nur, die aus dem
Urnenschema theoretisch abgeleitete Verteilungsfunktion der wirklich
beobachteten Verteilungsreihe anzupassen. Wir können höchstens
die Vorgänge bei der Ziehung aus der Urne symbolisch
fassen, indem wir sie als den Ausdruck für beliebige Zufallsvorgänge
deuten, die wir so einer Berechnung zugänglich machen.
Es würde in dem vorliegenden Beispiel etwa das Ziehen einer
weißen Kugel einen sehr kleinen Ausschlag der Stimmen nach der
unionistischen Seite bedeuten.

Man kann aber auch von der Herleitung der Formel aus
dem Urnenschema, nachdem sie einmal gewonnen ist, völlig absehen
und sich darauf beschränken, die Vorgänge zu suchen, die
sich dieser Formel anpassen und damit einen gemeinsamen Charakter
zeigen, den man definitionsmäßig als den des Zufälligen
ansehen kann.

Sehr wichtig erscheinen hierbei zunächst die Fälle, wo die
Gültigkeit der \so{Gauß}schen Verteilungsfunktion als eine physikalische
Hypothese erscheint. Dies gilt vor allen Dingen für die
Bewegungen der kleinsten Teile der Materie, zunächst der Moleküle.
Die Bewegungen der Moleküle sind unbeobachtbar und
daher ist eine unmittelbare Kontrolle durch die Erfahrung in
diesem Falle unmöglich. Eine solche gelingt jedoch bei sehr
kleinen, in einer Flüssigkeit suspendierten Teilchen, die den Molekularbewegungen
ähnliche und, wie man glaubt, durch die Molekularbewegungen
(nämlich die Stöße der Flüssigkeitsmoleküle auf
die festen Teilchen) unmittelbar veranlaßte Bewegungen, die sogenannten
\so{Brown}schen Bewegungen, ausführen. J.~\so{Perrin}
\index{Brownsche Bewegung}%
\index{Perrin}%
(Die Atome, deutsch von \so{Lottermoser}, Dresden und Leipzig
\index{Lottermoser (Übersetzer)}%
1914) hat in einem Falle die Verschiebungen der Teilchen in
Zwischenräumen von $30$ Zeitsekunden notiert und daraus folgende
Tabelle gefunden, in der den beobachteten die nach der \so{Gauß}schen
Verteilungsfunktion für die $500$ Beobachtungen berechneten
Anzahlen hinzugefügt sind. Der Wert von $\epsilon$ beträgt $1,96$~Mikron.
\DPPageSep{161}{147}
\index{Poisson|f}%
\[
\begin{array}{c||c|c}
\hline\hline
\ColHeadbb{die enthalten sind}{Verschiebungen,\\die enthalten sind\\zwischen} &
\ColHeadb{berechnet}{Anzahl\\berechnet} &
\ColHead{beobachtet}{Anzahl\\beobachtet} \\
\hline\hline
\Z0 \text{ und } \Z\epsilon        &  32 & 34 \\
\Z\epsilon \Ditto[ und ] 2\epsilon &  83 &  78 \\
 2\epsilon \Ditto[ und ] 3\epsilon & \llap{1}07 & \llap{1}06 \\
 3\epsilon \Ditto[ und ] 4\epsilon & \llap{1}05 & \llap{1}03 \\
 4\epsilon \Ditto[ und ] 5\epsilon &  75 &  75 \\
 5\epsilon \Ditto[ und ] 6\epsilon &  50 &  49 \\
 6\epsilon \Ditto[ und ] 7\epsilon &  27 &  30 \\
 7\epsilon \Ditto[ und ] 8\epsilon &  14 &  17 \\
 8\epsilon \Ditto[ und ] \infty    & \Z7 & \Z9 \\
\end{array}
\]

Die Tabelle ist zugleich lehrreich dafür, welche Übereinstimmung
man erwarten darf, wo die Gültigkeit der \so{Gauß}schen
Verteilungsfunktion von vornherein so gut wie sicher ist\footnote
  {Man vergleiche des weiteren L.~v.\ \so{Bortkewitsch}, Die radioaktive
\index{Bortkewitsch@Bortkewitsch (Bortkiewicz), Lad.\ v.}%
  Strahlung als Gegenstand wahrscheinlichkeitstheoretischer Untersuchungen,
  Berlin 1913.}.
Ein
weiteres besonders hervorragendes Beispiel besteht in der Messung
der Körperlänge erwachsener Personen. Hierfür hat \so{Pearson}\footnote
  {Man vgl.\ die Aufsätze von \so{Pearson} in den Transactions of
  the Royal Society 1894 bis 1903 (Vol.~185 bis~198) und Philosophical
  Magazine 1900, 1901 (Vol.~50,~1), ferner seine Schrift The chances of
  death etc., London 1897. Daneben ist es interessant, die Arbeiten von
  \so{Edgeworth} einzusehen, besonders Journal of the Royal Statistical
\index{Edgeworth}%
  Society, Vol.~60 bis 62 (1897 bis 1899), und als besondere Schrift unter
  dem Titel The representation of Statistics by mathematical formulae,
  London 1900. An zusammenfassenden Darstellungen kann man außer
  den bereits angeführten etwa vergleichen \so{King}, Elements of statistical
\index{King}%
  method, New York u.~London, Macmillan, \so{Davenport}, Statistical
\index{Davenport}%
  Methods, New York, Wiley \& Son. Ferner die Schriften von \so{Westergaard},
\index{Westergaard}%
  Grundzüge der Theorie der Statistik, Jena 1890, Lehre von
  der Mortabilität und Morbidität, 2.~Aufl.\ 1901. Unter den Lehrbüchern
  der Wahrscheinlichkeitsrechnung hat besonders das von
  \so{Czuber} (Leipzig 1902) die statistischen Anwendungen ausführlich
\index{Czuber}%
  behandelt.}
ausgezeichnetes Material in den Messungen der Körpergröße von
$25\,875$~Rekruten der Armee der Vereinigten Staaten angeführt.
Die Körpergrößen sind in Zoll und daneben die Anzahlen der
Rekruten von der betreffenden Größe angeführt.
\DPPageSep{162}{148}
\begin{table}[hbt!]
\[
\begin{array}{c|r<{\ }||c|r<{\ }}
\hline\hline
\ColHeadb{Körpergröße}{Körpergröße} &
\ColHeadbb{Anzahl}{Anzahl} &
\ColHeadb{Körpergröße}{Körpergröße} &
\ColHead{Anzahl}{Anzahl} \\
\hline\hline
78 \EnDash 77 &    2 & 64 \EnDash 63 & 1947 \\
77 \EnDash 76 &    6 & 63 \EnDash 62 & 1237 \\
76 \EnDash 75 &    9 & 62 \EnDash 61 &  526 \\
75 \EnDash 74 &   42 & 61 \EnDash 60 &   50 \\
74 \EnDash 73 &  118 & 60 \EnDash 59 &   15 \\
73 \EnDash 72 &  343 & 59 \EnDash 58 &   10 \\
72 \EnDash 71 &  680 & 58 \EnDash 57 &    6 \\
71 \EnDash 70 & 1485 & 57 \EnDash 56 &    7 \\
70 \EnDash 69 & 2075 & 56 \EnDash 55 &    3 \\
69 \EnDash 68 & 3133 & 55 \EnDash 54 &    1 \\
68 \EnDash 67 & 3631 & 54 \EnDash 53 &    2 \\
67 \EnDash 66 & 4054 & 53 \EnDash 52 &    1 \\
66 \EnDash 65 & 3475 & 52 \EnDash 51 &    1 \\
65 \EnDash 64 & 3019 && \\
\end{array}
\]
\end{table}

Wir beginnen damit, daß wir den Mittelwert auf die drei
angegebenen Weisen bestimmen. Wir finden dann mit ziemlich
genauer Übereinstimmung den Mittelwert oder Normalwert
\[
y_0 = 66,7.
\]
Hierauf berechnen wir die Größe $h$ nach den angegebenen drei
Methoden und finden so
\[
h_1 = 0,27,\qquad
h_2 = 0,27,\qquad
h_3 = 0,28.
\]
Wir erhalten dann das Bild, das in \Fig{9} auf der folgenden Seite
dargestellt ist. Die Übereinstimmung ist recht gut, so daß wir in
der Tat annehmen können, daß die Verteilung der Körpergrößen
erwachsener Personen dem \so{Gauß}schen Verteilungsgesetz folgt.
Dagegen haben Messungen an gleichaltrigen Kindern gezeigt, daß
die Verteilung bei nicht erwachsenen Personen eine andere, nämlich
eine wesentlich unsymmetrische ist, indem ein Zurückbleiben
des Wachstums gegen den normalen Wert häufiger als ein Vorauseilen
ist.

Die Auffassung, daß man in dem \so{Gauß}schen Verteilungsgesetz
das Symptom für eine auf bloßen Zufälligkeiten beruhende
Verteilung zu sehen habe, ist lange Zeit durchaus herrschend gewesen.
Ihr ist \zB~\so{Quételet} durchaus gefolgt, sie findet sich
\index{Quételet}%
auch in dem englischen Werke von \so{Venn}, The logic of chance
\index{Venn}%
\DPPageSep{163}{149}
(London 1876) konsequent vertreten. Diese Ansicht ist aber, wie
wir gesehen haben, weder in dem Sinne richtig, daß, wo die Verteilung
mit hinreichender Annäherung dem \so{Gauß}schen Verteilungsgesetz
folgt, die Abweichungen bestimmt in jedem einzelnen
Falle nur auf Zufälligkeiten beruhen, noch in dem Sinne, daß sich
immer die \so{Gaußs}che Verteilungsfunktion ergibt, wo wir zufällige
Schwankungen anzunehmen haben. Dies geht aus der Verallgemeinerung
hervor, die wir an das Urnenschema angeknüpft
haben, indem wir annahmen, daß erst durch das Los bestimmt
\begin{figure}[hbt!]
  \centering
  \caption{Fig.~9.}
  \Input{163}
\end{figure}
wird, aus welcher von mehreren vorhandenen Urnen gezogen wird.
Wir haben dabei im Gegensatz zu der Symmetrie der \so{Gauß}schen
Verteilungsfunktion eine wesentlich unsymmetrische Verteilung
gefunden, und es scheint von Interesse, auch dafür ein Beispiel
zu finden.

Der einfachste Fall, den wir hierbei annehmen können, ist
der, wo nur zwei Urnen vorhanden sind, wo also nur zwei Wahrscheinlichkeiten
$w_1$~und~$w_2$ dafür, daß aus der einen oder anderen
Urne gezogen wird, in Betracht kommen. Die Relation $w_1 + w_2 = 1$
kommt weiter nicht in Frage, da noch mit einer Konstanten~$c$
multipliziert werden muß. Wir können dann (indem wir $c_1 = cw_1$,
$c_2 = cw_2$ setzen) die Verteilungsfunktion schreiben:
\[
\Tag{(10)}
\Phi(z)
  = \frac{c_1 h_1}{\sqrt\pi}\, e^{-h_1^2(z - u_1)^2}
  + \frac{c_2 h_2}{\sqrt\pi}\, e^{-h_2^2(z - u_2)^2}.
\]
\DPPageSep{164}{150}

Für diese Verteilungsfunktion wollen wir, wiederum nach
\so{Pearson}, ein Beispiel geben. Dieses Beispiel hat eine gewisse
Berühmtheit erlangt, weil es den Ausgangspunkt weitergehender
Untersuchungen gebildet hat. Wenn eine solche Streuung wie
die angeführte besteht, so liegt der Fall genau so, als ob die beobachteten
Individuen aus zwei Gattungen gemischt seien, für deren
Verteilung einzeln die gewöhnliche \so{Gaußs}che Verteilungsfunktion
gilt. Man beobachtet nun eine entsprechende Verteilung bei
biologischen Individuen auch dann, wenn nicht sie selbst, wohl
aber ihre Vorfahren aus zwei verschiedenen Arten gemischt sind.
Es wird also das Bestehen einer solchen Verteilung das Kennzeichen
für eine stattgefundene Bastardierung.

Das Beispiel, das wir geben wollen, bezieht sich auf die
"`Stirnbreite"' von $1000$ Krabben aus dem Golf von Neapel. Die
zugrunde liegende Tabelle ist die auf folgender Seite.

Um die in der graphischen Darstellung (\Fig{10}) eingezeichnete
Kurve zu erhalten, die sich den beobachteten Werten möglichst
anschmiegt, sind für die Konstanten in der Formel folgende Werte
genommen (für den Durchschnittswert ist $z = 0$, woraus $-c_1u_1
= c_2u_2$):
\begin{align*}
c_1 &= 414,5, & u_1 &= -3,517,           & h_1 &= 0,159,\\
c_2 &= 585,5, & u_2 &= \phantom{-}2,490, & h_2 &= 0,228\footnotemark.
\end{align*}
\footnotetext{Außer den hier angeführten Verteilungsfunktionen, die alle auf
  die \so{Gaußs}che Funktion zurückgehen, gibt \so{Pearson} (Transactions of
  the Royal Society, London 1895) noch eine Anzahl anderer an, die er
  ebenfalls an das Urnenschema anknüpft. Es wird hierbei das Urnenschema
  aber nur als heuristisches Prinzip benutzt, indem in der abgeleiteten
  Formel die Grenzen, in denen die Konstanten bleiben müssen,
  und notwendige Voraussetzungen, die bei der Ableitung zu machen
  sind, außer acht gelassen werden. Dieses Verfahren ist gewiß berechtigt,
  wenn es sich um nichts anderes handelt als darum, passende
  Annäherungsfunktionen für die empirisch gefundenen Verteilungen
  zu gewinnen. Es ist dann die Aufgabe, an möglichst zahlreichen
  Beispielen die angesetzten Funktionen zu erproben. In dieser Hinsicht
  ist eine Durchsicht der Zeitschrift Biometrika, A Journal for the statistical
  study of biological problems (Cambridge, seit 1901, herausgegeben von
  \so{Weldon}, \so{Pearson}, \so{Davenport} und \so{Galton}) zu empfehlen, in deren
\index{Davenport}%
\index{Galton}%
\index{Weldon}%
  ersten Bänden sich zahlreiche solche Beispiele finden. Durch die Art aber,
  wie die \so{Pearson}schen Untersuchungen auch in der letzten Zeit (\zB~bei
  \so{Forcher}, Die statistische Methode, Leipzig 1913) wiedergegeben
\index{Forcher}%
  worden sind, wird nur zu leicht der Anschein erweckt, als ob es sich
  um eine wirkliche Ableitung der entstehenden Verteilungen aus dem
  Urnenschema handle. Die Darstellung bei Fechner (Kollektivmaßlehre,
\index{Fechner}%
  herausgegeben von G.~F.~\so{Lipps}, Leipzig 1899), der auf andere Weise
\index{Lipps@Lipps, G. F. (Herausgeber)}%
  eine Verallgemeinerung der \so{Gauß}schen Funktion anstrebt, ist darin
  durchsichtiger.}
\DPPageSep{165}{151}
\index{Lexis}%
\begin{table}[hbtp!]
\begin{minipage}{3cm}
\[
\footnotesize
\begin{array}{@{}c|c@{}}
\hline\hline
\ColHeadb{zahlen}{Maß-\\zahlen} &
\ColHead{Individuen}{Anzahl \\Individuen} \\
\hline\hline
\Z1 & \Z1 \\
\Z2 & \Z3 \\
\Z3 & \Z5 \\
\Z4 & \Z2 \\
\Z5 & \Z7 \\
\Z6 &  10 \\
\Z7 &  13 \\
\Z8 &  19 \\
\Z9 &  20 \\
 10 &  25 \\
 11 &  40 \\
 12 &  31 \\
 13 &  60 \\
 14 &  62 \\
 15 &  54 \\
 16 &  74 \\
 17 &  84 \\
 18 &  86 \\
 19 &  96 \\
 20 &  85 \\
 21 &  75 \\
 22 &  47 \\
 23 &  43 \\
 24 &  24 \\
 25 &  19 \\
 26 & \Z9 \\
 27 & \Z5 \\
 28 & \Dash \\
 29 & \Z1 \\
 30 & \Dash \\
\end{array}
\]
\end{minipage}
\hfill
\begin{minipage}{\textwidth-3cm}
  \centering
  \caption{Fig.~10.}
  \Input{165}
\end{minipage}
\end{table}

Es bleibt noch übrig, die Anwendung der Formel, die für
verhältnismäßig seltene Ereignisse gilt, durch ein Beispiel zu erläutern.
L.~v.~\so{Bortkewitsch} hat in seiner Schrift Das Gesetz
\index{Bortkewitsch@Bortkewitsch (Bortkiewicz), Lad.\ v.|ff}%
der kleinen Zahlen (Leipzig 1898) die Bedeutung dieser Formel
besonders hervorgehoben. Es erscheint beinahe a priori einleuchtend,
daß die störenden Einwirkungen, die sonst das Zustandekommen
einer regulären Verteilung verhindern, indem in den
\DPPageSep{166}{152}
einzelnen verglichenen Bezirken verschiedene Verhältnisse obwalten,
sich am wenigsten geltend machen, wenn an den verschiedensten
Stellen durch ein verhältnismäßig seltenes Ereignis
einzelne Fälle, sozusagen Stichproben, herausgegriffen werden.

Wir hatten gesehen, daß in diesem Falle die Formel gilt:
\[
\Tag{(11)}
\phi_p = \frac{m^p e^{-m}}{p!},
\]
wobei die Beziehungen bestehen müssen:
\[
\Tag{(12)}
\Sum\phi_p = 1, \
m = \Sum p\phi_p, \
m' = \Sum(p - m)^2 \phi_p, \
m' = m.
\]

Es ist zunächst zu prüfen, ob diese Beziehungen erfüllt sind.
Wir wollen nun hierfür ein Beispiel nehmen und wählen mit
\so{Bortkewitsch} die Anzahl der Soldaten, die während der Jahre
1875 bis 1894 innerhalb der Armeekorps II~bis~V, VII~bis~X,
XIV~und~XV des preußischen Heeres durch Hufschlag eines
Pferdes getötet wurden. Die einzelnen Zahlen~$p_i$ usw.\ bedeuten
dann die innerhalb eines Armeekorps während eines Jahres Getöteten.
Es ergeben sich dabei:
\[
\begin{array}{*{6}{c}l}
          &   0 &  1 &  2 & 3 & 4 & 5 \text{ und mehr Getötete} \\
\text{in} & 109 & 65 & 22 & 3 & 1 & 0 \text{ Fällen,}
\end{array}
\]
und daraus folgt der Wert
\[
m = \frac{65·1 + 22·2 + 3·3 + 4·1}{200} = 0,61.
\]
Übereinstimmend damit ergibt sich auch für $m'$ der Wert~$0,61$.
Rechnet man nun mit Hilfe des Ausdruckes
\[
z_0 \frac{m^p}{p!}
\]
die zu erwartenden Häufigkeiten von $p$ Todesfällen aus, indem
man $z_0$ (die Häufigkeit für $p = 0$) daraus bestimmt, daß die
Summe aller Häufigkeiten gleich $200$ sein muß, woraus
\[
z_0 = 200·e^{-m}
\]
folgt, so findet man statt der obigen Werte die Zahlen:
\[
109 \qquad 66 \qquad 20 \qquad 4 \qquad 1 \qquad 0.
\]
Die Übereinstimmung ist außerordentlich gut. Daß sie auf einem
bloßen Zufall beruht, ist nicht anzunehmen. Vielmehr haben wir
\DPPageSep{167}{153}
\index{Lipps@Lipps, G. F. (Herausgeber)}%
uns zu denken, daß alle örtlichen und zeitlichen Besonderheiten,
die sonst als systematische Abweichungen hervortreten, dadurch
unwirksam werden, daß eine rein zufällige Auswahl durch das
betrachtete seltene Ereignis getroffen wird und daß wir deswegen
annähernd dieselben Verhältnisse haben müssen, wie sie bei der
Begründung aus dem Urnenschema vorausgesetzt werden\footnote
  {An kurz zusammenfassenden Darstellungen mit reichen Literaturangaben
  vgl.\ man den Artikel von \so{Bortkiewicz}, Anwendungen der
  Wahrscheinlichkeitsrechnung auf Statistik, Enzyklopädie der math.\
  Wissenschaften, Bd.~I, 2.~Teil, Leipzig 1900--1904, \so{Czuber}, Die Entwickelung
\index{Czuber}%
  der Wahrscheinlichkeitstheorie und ihrer Anwendungen,
  Jahresbericht der Deutschen Math.-Ver., Bd.~VII, Leipzig 1899, ferner die
  Artikel Geschlechtsverhältnis der Geborenen und Gestorbenen (v.~\so{Mayr}),
\index{Mayr, v.}%
  Gesetz (\so{Lexis}), Sterblichkeit (v.~\so{Bortkiewicz}) im Handwörterbuch
\index{Lexis}%
  der Staatswissenschaften von \so{Lexis} und \so{Elster}.}.
\index{Elster (Herausgeber)}%
\EndChap
\DPPageSep{168}{154}


\Chapter{Zehntes Kapitel}{Die genetische Theorie des Zufalls}

Die statistische Theorie des Zufalls offenbart einen gemeinschaftlichen
Charakter in der Verteilung der statistischen Ergebnisse
bei solchen Ereignissen, die wir als zufällige anzusehen
gewohnt sind. Wir erhalten aber keinen unmittelbaren Aufschluß
darüber, wie wir uns das Zustandekommen einer solchen Verteilung
in der Wirklichkeit denken können. Es bleibt daher das Bedürfnis
bestehen, sozusagen in den inneren Mechanismus des Geschehens
einzudringen und sich klar zu machen, wie die als typisch für die
Zufallsereignisse angesehene Verteilung auch auf einer inneren
Übereinstimmung der in Betracht kommenden Ereignisse beruht.

Als die am sichersten als zufällig zu bezeichnenden Ereignisse
gelten nun die Ereignisse, die in dem Begehen eines bestimmten
Beobachtungsfehlers bei sehr sorgfältig ausgeführten Beobachtungen
bestehen, \dh~sich der in der Abweichung der in der
gleichen Weise und mit der gleichen Sorgfalt bestimmten Werte
voneinander kundgeben. Für diese Fehler hat die Erfahrung mit
hinreichender Gewißheit die Geltung des sogenannten \so{Gauß}schen
Fehlergesetzes, das durch die Funktion
\[
\phi(x) = \frac{h}{\sqrt\pi}\, e^{-h^2 x^2}
\]
geliefert wird, ergeben.

Man kann es nun als die Aufgabe hinstellen, eine Erklärung
dafür zu suchen, wie dieses eigentümliche Gesetz für die Verteilung
der Fehler zustande kommt.

Der Astronom \so{Bessel} ist der erste gewesen, der diese Frage
\index{Bessel@Bessel|f}%
zu beantworten gesucht hat (Untersuchungen über die Wahrscheinlichkeit
der Beobachtungsfehler, Astron.\ Nachrichten, Bd.~15,
\DPPageSep{169}{155}
1838). Er dachte sich, daß jeder Fehler das Resultat des Zusammentreffens
einer großen Anzahl von Elementarfehlern ist, die
einzeln bestimmten Fehlerquellen entstammen. Die einfachste
Annahme ist dabei die, die Elementarfehler alle als dem absoluten
Betrag nach gleich vorauszusetzen, etwa gleich~$e$, und weiter zu
sagen, jeder einzelne Elementarfehler gehe gleich oft mit dem positiven
und dem negativen Vorzeichen in das Resultat ein. Dieses
Resultat entspricht dann einer bestimmten Vorzeichenkombination
der Elementarfehler. Man kann diesen Vorgang sehr einfach auf
das Urnenschema zurückführen, indem man eine Urne voraussetzt,
in der gleich viele schwarze und weiße Kugeln gemischt
enthalten sind. Das Ziehen einer weißen Kugel bedeutet denn
das Begehen des Elementarfehlers~$+e$, das Ziehen einer schwarzen
Kugel das Begehen des Elementarfehlers~$-e$. Wenn nun eine
große Anzahl $n = p + q$ Male eine Kugel aus der Urne gezogen
ist, so wird, wenn hierbei $p$\,mal eine weiße und $q$\,mal eine schwarze
Kugel gefunden wurde,
\[
x = (p - q)e
\]
der begangene Gesamtfehler.

Die relative Häufigkeit dieses Gesamtfehlers wird
\[
\frac{(p + q)!}{p!\, q!} \left(\frac{1}{2}\right)^p \left(\frac{1}{2}\right)^q
\]
oder wenn man
\[
p = \frac{n}{2} + u, \quad
q = \frac{n}{2} - u
\]
setzt,
\[
w_u = \frac{n!}{\left(\dfrac{n}{2} + u\right)! \left(\dfrac{n}{2} - u\right)!}
  · \left(\frac{1}{2}\right)^n.
\]
Es handelt sich nun darum, hierfür einen Näherungswert zu finden,
indem man $n$ sehr groß und $u$ als verhältnismäßig klein gegen $n$
annimmt.

Wir bilden zu dem Zweck
\[
\frac{w_u}{w_{u-1}} = \frac{\dfrac{n}{2} - u}{\dfrac{n}{2} + u},
\]
\DPPageSep{170}{156}
dividieren Zähler und Nenner dieses Bruches durch $\frac{1}{2} n$ und setzen
\[
2 \frac{u}{n} = z,
\]
dann wird
\[
\frac{w_u}{w_{u-1}} = \frac{1 - z}{1 + z}.
\]
Wir erhalten also, indem wir weiter setzen
\[
z = \frac{x}{ne},
\]
woraus
\[
x = 2ue,
\]
da $z$ ein sehr kleiner Bruch ist,
\[
\frac{w_u - w_{u-1}}{w_u} = -\frac{2z}{1 - z} = -2z = -\frac{2x}{ne},
\]
also, wenn wir berücksichtigen, daß
\[
w_u = \phi(x) \quad \text{und demnach} \quad
\frac{w_u - w_{u-1}}{w_u} = d \ln \phi(x)
\]
wird,
\[
d \ln \phi(x) = -\frac{2x}{ne},
\]
ferner $dx = 2e$, da einer Vermehrung von $u$ um $1$ eine Vermehrung
von $x$ um $2e$ entspricht, und somit schließlich
\[
\phi(x) = C e^{-h^2x^2}
\]
entsprechend dem ursprünglichen Ansatz, wenn wir noch
$h = \dfrac{1}{\sqrt{2n}e}$ machen.

Es ist aber wichtig, sich von der \so{Bessel}schen Annahme
frei zu machen, daß jede Fehlerquelle nur Fehler von bestimmtem
absoluten Betrage liefern könne, und dafür die allgemeinere Voraussetzung
einzuführen, daß jede Fehlerquelle

1. gleich große positive und negative Fehler mit gleich großer
relativer Häufigkeit ergebe und

2. nur sehr kleine Fehler, aber
\DPPageSep{171}{157}

3. innerhalb gewisser Grenzen jeden beliebigen Fehler liefern
könne\footnote
  {Vgl.\ \so{Crofton}, On the proof of the law of errors of observations,
\index{Crofton}%
  Philosophical Transactions, Vol.~159 (1869), Artikel Probability, Encyclopaedia
  Britannica, 9.~ed., Vol.~19 (1885).}.

Sogar von der Voraussetzung~1.\ können wir, wie wir sehen
werden, Abstand nehmen.

Wir nehmen an, die Aufgabe sei bereits gelöst, wenn die
Zahl der Fehlerquellen $n$ beträgt. Man habe die Fehlerfunktion
gefunden, die durch das Zusammenwirken dieser $n$ Fehlerquellen
entsteht, und man nenne diese Fehlerfunktion $\phi_n(x)$. Dann
komme noch eine Fehlerquelle hinzu, zu der die Fehlerfunktion
$\Theta_{n+1}(x)$ gehöre, und man suche die nun entstehende neue Fehlerfunktion
$\phi_{n+1}(x)$ zu bestimmen. Wir haben dann, da, wenn die
letzte Fehlerquelle den Fehler $u$ liefert, die übrigen Fehlerquellen
den Fehler $x - u$ liefern müssen, damit der Gesamtfehler $x$ werde,
\[
\phi_{n+1}(x) = \Int_{-r}^{+r} \phi_n(x - u) \Theta_{n+1}(u)\, du,
\]
wo $+r$ und $-r$ die Extremwerte sind, bis zu denen die Argumente
der Funktion~$\Theta_{n+1}(u)$ reichen.

Wir entwickeln unter dem Integralzeichen $\phi_n(x - u)$ nach
dem \so{Taylor}schen Lehrsatze, und finden
\[
\phi_{n+1} (x)
  = \Int_{-r}^{+r} \bigl[\phi_n(x) - u\phi'_n(x) + \tfrac{1}{2} u^2\phi''_n(x)\bigr]
  \Theta_{n+1}(u)\, du.
\]
Die höheren Potenzen von $u$ können wir vernachlässigen.

Es ist nun
\[
\Int_{-r}^{+r} \Theta_{n+1}(u)\, du = 1,
\]
und setzen wir ferner
\[
\Int_{-r}^{+r} u \Theta_{n+1}(u)\, du = j_{n+1}, \qquad
\Int_{-r}^{+r} u^2 \Theta_{n+1}(u)\, du = k_{n+1},
\]
so wird jetzt
\[
\phi_{n+1}(x) = \phi_n(x) - j_{n+1} \phi'_n(x) + \tfrac{1}{2} k_{n+1}\phi''_n(x).
\]
\DPPageSep{172}{158}

Wir erkennen daraus, daß es gleichgültig ist, welche Form
wir der Funktion~$\Theta_{n+1}(u)$ geben, wenn sie nur die richtigen
Werte von $j_{n+1}$ und $k_{n+1}$ liefert. Wir wollen deshalb insbesondere
für die Funktion den Ansatz machen:
\[
\Theta_{n+1}(u) = \frac{\lambda_{n+1}}{\sqrt\pi}\, e^{-\lambda_{n+1}^2 (u-u_{n+1})^2},
\]
es ergibt sich dann:
\begin{align*}
j_{n+1} &= \Int_{-r}^{+r} u \Theta_{n+1}(u)\, du = u_{n+1},\\
k_{n+1} &= \Int_{-r}^{+r} u^2 \Theta_{n+1}(u)\, du
  = \frac{1}{2\lambda_{n+1}^2} + u_{n+1}^2.
\end{align*}

Wir können nun bestätigen, daß unter dieser Voraussetzung
für die Verteilungsfunktion sich ebenfalls die Form
\[
\phi_n(x) = \frac{h_n}{\sqrt\pi}\, e^{-h_n^2(x-x_n)^2}
\]
ergibt. Wir zeigen dies, indem wir nachweisen, daß durch das
Hinzutreten einer neuen Fehlerquelle sich diese Form nicht
ändert. Da diese Form aber für \so{eine} Fehlerquelle als gültig angenommen
werden kann, gilt sie nach dem Bewiesenen dann
auch für zwei, weiter für drei, vier usw.\ Fehlerquellen und damit
allgemein.

Setzen wir also voraus, in der Formel
\[
\Theta_{n+1}(x) = \Int_{-r}^{+r} \phi_n(x - u)\Theta_{n+1}(u)\, du
\]
seien die obigen Ausdrücke für $\phi_n(x - u)$ und $\Theta_{n+1}(u)$ eingesetzt,
dann wird, wenn wir noch für die Grenzen $-r$~und~$+r$
$-\infty$~und~$+\infty$ schreiben,
\[
\phi_{n+1}(x)
  = \Int_{-\infty}^{+\infty} c e^{-h_n^2(x-u-x_n)^2}\, e^{-\lambda_{n+1}^2(u-u_{n+1})^2}\, du,
\]
\DPPageSep{173}{159}
wo $c$ eine Konstante ist. Die beiden Potenzen von $e$ vereinigen
sich zu einer einzigen, deren Exponent
\begin{align*}
&= -h_n^2(x-u-x_n)^2 - \lambda_{n+1}^2(u-u_{n+1})^2 \\
&= \begin{aligned}[t]
  -(h_n^2+\lambda_{n+1}^2)u^2 + 2
   & \bigl[h_n^2(x-x_n)+\lambda_{n+1}^2u_{n+1}\bigr]u \\
  -& \bigl[h_n^2(x-x_n)^2 + \lambda_{n+1}^2u_{n+1}^2\bigr]
\end{aligned} \\
&= -(h_n^2 + \lambda_{n+1}^2)(u - u'_n)^2
  - \frac{\lambda_{n+1}^2h_n^2}{h_n^2 + \lambda_{n+1}^2}(x - x_n - u_{n+1})^2
\end{align*}
ist, wenn
\[
u'_n = \frac{h_n^2(x - x_n) + \lambda_{n+1}^2u_{n+1}}{h_n^2 + \lambda_{n+1}^2}
\]
gesetzt wird. Hieraus folgt:
\[
\phi_{n+1}(x) = Ce^{-\tfrac{\lambda_{n+1}^2h_n^2}{h_n^2 + \lambda_{n+1}^2}(x-x_n-u_{n+1})^2},
\]
wo $C$ eine neue Konstante ist.

Setzen wir mithin
\[
\phi_{n+1}(x) = Ce^{-h_{n+1}^2(x-x_{n+1})^2},
\]
so wird
\[
\frac{1}{h_{n+1}^2} = \frac{1}{h_n^2} + \frac{1}{\lambda_{n+1}^2}, \quad
x_{n+1} = x_n + u_{n+1}.
\]
Also ist
\[
\Tag{(1)}
\frac{1}{h_n^2}
  = \frac{1}{\lambda_1^2} + \frac{1}{\lambda_2^2} + \dots
  + \frac{1}{\lambda_n^2}
\]
und
\[
\Tag{(2)}
x_n = u_1 + u_2 + \dots + u_n.
\]
Nun ist, wie wir oben (S.~158) gefunden hatten,
\[
\Tag{(3)}
u_i = \Int_{-\infty}^{+\infty} u\Theta_i(u)\, du.
\]
Also wird $u_i$ der Mittelwert, um den sich die aus der $i$ten Fehlerquelle
fließenden Fehler gruppieren, und die resultierende Fehlerfunktion
ist auf einen Mittelwert bezogen, der die Summe aus
\DPPageSep{174}{160}
den Mittelwerten aller einzelnen Fehlerquellen ist. Diesen Wert
können wir als den \so{systematischen Fehler} der Beobachtungen
ansehen.

Ferner ergibt sich:
\[
\Tag{(4)}
\frac{1}{2\lambda_i^2} = \Int_{-\infty}^{+\infty} (u - u_i)^2\Theta_i(u)\, du,
\]
also gleich dem Quadrat $\mu_i^2$ des \so{mittleren zufälligen Fehlers}
bei der $i$ten Fehlerquelle, und wir finden für den mittleren
Fehler $\mu$ bei der resultierenden Fehlerfunktion:
\[
\Tag{(5)}
\mu^2 = \mu_1^2 + \mu_2^2 + \dots + \mu_n^2.
\]

Die Resultate, die wir so für den besonderen Fall gefunden
haben, wo die zugrunde gelegte Messungsreihe aus verschiedenen
Messungen einer und derselben physikalischen Größe besteht, lassen
sich auch sofort auf den Fall übertragen, wo eine Reihe an verschiedenen
Objekten ausgeführter Beobachtungen in ihrer Verteilung
der \so{Gauß}schen Funktion folgt. Wir finden, daß eine solche
Verteilung entstehen muß, wenn die an den Objekten beobachteten
Verschiedenheiten auf zufälligen Abweichungen von einem bestimmten
Normaltypus beruhen, \dh~wenn eine große Anzahl an
sich sehr geringfügiger und voneinander unabhängiger Umstände
zusammenwirken, um die beobachtete Abweichung zu erzeugen.

In diesem Sinne könnten wir von einem objektiven Zufalle
sprechen, der Zufall würde dann in dem Zusammentreffen einer
großen Anzahl von Umständen bestehen, die untereinander in keiner
unmittelbaren kausalen Beziehung stehen, und deren Zusammentreffen
den beobachteten Erfolg herbeiführt.

Hierdurch wird der Bereich des Zufälligen aber außerordentlich
eingeschränkt, denn gerade daß eine große Menge von gegenseitig
unabhängigen Einzelumständen zusammentreffen soll, scheint
in der Wirklichkeit selten erfüllt. Wohl findet man, wenn man
ein Zufallsereignis in den Einzelheiten seines Zustandekommens
verfolgt, eine Reihe von Umständen, die zusammen das Ereignis
hervorgerufen haben, aber diese Umstände stehen nicht außer
Zusammenhang, sie bilden vielmehr die Glieder in wenigen Ketten
von kausalen Zusammenhängen. Meistens wird man sogar nur
zwei solcher Ketten feststellen können. So wird man, um auf das
\DPPageSep{175}{161}
Beispiel des von einem herabfallenden Ziegel getöteten Passanten
zurückzukommen, die zwei Ketten von Ursache und Wirkung verfolgen,
die auf der einen Seite das Vorübergehen des Menschen
gerade an dieser Stelle und auf der anderen Seite das Herabfallen
des Ziegels gerade zu dieser Zeit erklären. Damit aber wird die
Anwendung der in diesem Kapitel angestellten Analyse, wie es
scheint, in den meisten Fällen illusorisch. Es soll diese Analyse
jedoch auch gar nicht eine allgemeine genetische Erklärung der
Zufallsereignisse geben. Sie liefert nur \so{ein} Beispiel dafür, wie
die für die Zufallsereignisse typische Verteilung zustande kommen
kann. Dieses Beispiel ist deshalb von besonderer Bedeutung, weil
die gegebene Erklärung in einem sehr wichtigen Falle, nämlich
bei gleich sorgfältigen Beobachtungen einer und derselben physikalischen
Größe, tatsächlich zu stimmen scheint. Daß die typische
Verteilung auch auf ganz andere Art zustande kommen kann,
lehrt schon das Beispiel der Urnenziehungen. Es ist gerade das
Merkwürdige an der \so{Gauß}schen Verteilungsfunktion, daß sie sich
auf ganz verschiedene, anscheinend voneinander völlig unabhängige
Arten ergibt. %[** TN: Removed trailing em-dash]

Wenn wir nun zum Schluß die Ergebnisse unserer Betrachtungen
kurz zusammenfassen, so ist der Gewinn, den wir erzielt
haben, nicht darin zu suchen, daß die Auffassung des einzelnen
zufälligen Ereignisses eine Vertiefung erfahren hat. Dagegen haben
wir gesucht, den Nachweis zu führen, daß auch die zufälligen
Ereignisse nicht die Regelmäßigkeit und Ordnung des allgemeinen
Geschehens durchbrechen, daß vielmehr auf eine bestimmte Weise
bei diesen zufälligen Ereignissen ein Ausgleich stattfindet für das,
was sie als störendes Element in die Gesetzmäßigkeit des Geschehens
hineintragen.

Hierin liegt an sich nichts Neues und Überraschendes, vielmehr
etwas nahezu Selbstverständliches. Wir brauchen ja bloß
zu bedenken, daß die Vorgänge in den kleinsten Teilen der Materie
als Zufallsereignisse anzusehen sind, und daß sonach, wofern überhaupt
in dem physikalischen Geschehen eine Regelmäßigkeit zu
erkennen sein soll, diese auf einem Ausgleich der Zufälligkeiten
in den Veränderungen der kleinsten Elemente beruhen muß. Wir
verlassen uns auf diesen Ausgleich wie auf ein Naturgesetz, \zB~ist
der sogenannte zweite Hauptsatz der mechanischen Wärmetheorie,
nämlich der Satz, daß die Wärme nicht von selbst vom kälteren
\DPPageSep{176}{162}
zum wärmeren Körper strömt, nichts wie ein Ausdruck für den
Ausgleich, der in den molekularen Bewegungen stattfindet. Es ist
aber wichtig, sich klar bewußt zu sein, daß hiermit ein neues
Moment in die Naturerklärung hineingetragen wird, das von
anderer Art ist wie die eine regelmäßige kausale Verknüpfung
aussagenden Naturgesetze. Das Wesentliche an allen zufälligen
Ereignissen ist eben das, daß sie allein aus der Regelmäßigkeit
kausaler Verknüpfungen nicht zu erklären sind. Wenn daher sich
in der Gesamtheit der Zufallsereignisse einer bestimmten Gruppe
eine Regelmäßigkeit wiederfindet, so ist diese von anderer Art als
die kausalen Zusammenhänge, und die Voraussetzung einer unverbrüchlichen
Kausalität in allem Naturgeschehen mag wohl aufrecht
erhalten werden, sie reicht allein aber nicht hin, um die
Regelmäßigkeit des Weltgeschehens vollständig zu erklären. Es
gehört vielmehr die Tatsache hinzu, die wir als das Gesetz der
großen Zahlen bezeichnen und die bewirkt, daß die Unregelmäßigkeiten,
die sonst durch die zufälligen Ereignisse in die Welt hineingetragen
würden, in dem Gesamtergebnis doch wieder verschwinden.

Wenn wir diese Elimination des Zufalls als eine allgemeine
Tatsache hinstellen, so müssen wir uns bewußt sein, daß wir für
diese Tatsache keine bestimmte Erklärung geben können, daß wir
sie vielmehr nur insoweit behaupten können, wie sie uns durch
die Erfahrung bestätigt wird. Unser Verstand sträubt sich allerdings
dagegen, ein so allgemeines Prinzip nur deshalb anzunehmen,
weil hier und dort seine Richtigkeit bezeugt wird, vielmehr
drängt er dahin, auch einen inneren Grund für einen solchen
Ausgleich zu finden. Ein solcher innerer Grund läßt sich aber
nicht ermitteln. Würden wir zu ihm gelangen können, so müßte
uns eine Einsicht in den Mechanismus des Geschehens zu Gebote
stehen, wie wir sie nicht haben. Was uns gegeben ist, sind die
einzelnen Erfahrungen. Nur indem wir diese zusammenhalten,
miteinander vergleichen, Gleichartiges zusammenschließen und die
dabei sich herausstellenden regelmäßigen Zusammenhänge aufdecken,
gelangen wir dazu, das zu erreichen, was wir eine Erklärung
des Naturgeschehens nennen. Auf diesem Wege können
wir aber nicht den Ausgleich erklären, der in dem Gesetz der
großen Zahlen ausgedrückt sein soll.

Deshalb müssen wir uns damit begnügen, diesen Ausgleich,
indem wir seine Wirklichkeit von vornherein voraussetzen, in
\DPPageSep{177}{163}
seinen einzelnen Erscheinungsformen selbst zu verfolgen. Auf
diese Weise kann natürlich die Tatsache des Ausgleichs, weil wir
sie von Anfang an vorausgesetzt haben, nicht erst erklärt werden.
Wir können aber diese Tatsache uns sozusagen näher bringen,
indem wir solche Vorgänge herausgreifen, über deren inneren
Charakter wir glauben von vornherein Klarheit zu haben. Diese
Vorgänge sind die Glücksspiele, und unter den Glücksspielen
wählten wir noch insbesondere einen typischen Vorgang aus, der
in den Ziehungen aus einer Urne besteht. Alle Ergebnisse, die
aus diesen typischen Vorgängen gewonnen werden und die sich
in der Ableitung gewisser Formeln für die bei häufiger Wiederholung
des Vorganges zu erwartenden statistischen Ergebnisse
vollenden, können auf andere Vorgänge, deren inneres Zustandekommen
unserer Beobachtung verschlossen ist, nur so angewendet
werden, daß wir die statistischen Ergebnisse vergleichen. Das ist
es, was wir als die statistische Methode bezeichnet haben.

Welches Recht haben wir nun, Ereignisse, deren Verteilung
mit der aus dem Urnenschema folgenden Verteilung eine gewisse
Übereinstimmung zeigt, auch innerlich als gleichartig anzusehen?
Dadurch, daß wir überhaupt über die innere Natur
eines Vorganges urteilen, gehen wir aus dem rein phänomenologischen
Gebiet in das ontologische Gebiet über. Die innere
Natur eines Vorganges, das eigentliche Warum und Wieso liegt
außerhalb des Bereiches der bloßen Erfahrung. Was uns dazu
hinführt, sind im Grunde immer Analogieschlüsse. Auf das Bedenkliche
solcher Schlüsse braucht nicht besonders hingewiesen
zu werden. Die Analogie verführt uns nur zu leicht, aus einer
gefundenen Übereinstimmung in einzelnen Punkten eine Übereinstimmung
auch in anderen Punkten zu erschließen, ohne daß dieser
Schluß logisch zwingende Kraft hätte.

Trotzdem können wir ohne solche Analogieschlüsse nicht auskommen.
Sie sind es im wesentlichen, die uns die Dinge als begreiflich
erscheinen lassen. Das bloße Sammeln und Ordnen von
Erfahrungen würde uns unbefriedigt lassen. Wir würden das
innere Band vermissen. Dieses Band eben finden wir häufig
durch Analogieschlüsse. So beruht \zB~der Kraftbegriff, durch
den uns die physikalischen Vorgänge begreiflich erscheinen sollen,
auf einer Analogie mit physiologischen Vorgängen, nämlich dem
Gefühl der Anstrengung beim Heben einer Last, und daß uns die
\DPPageSep{178}{164}
Dinge auf diese Weise innerlich begreiflich erscheinen, liegt daran,
daß wir sie in Zusammenhang bringen mit persönlichen Empfindungen.
Wir bringen sie uns "`menschlich nahe"'.

Etwas Ähnliches können wir nun auch in der Analyse der
zufälligen Vorgänge finden. Auch hier ist es die persönliche
Stimmung dem ungewissen Ereignis gegenüber, die das Verfahren
bestimmt hat und aus der heraus man ein inneres Verstehen der
Vorgänge zu erreichen geglaubt hat. Hierhin gehört es, wenn in
der klassischen Wahrscheinlichkeitsrechnung die gleich möglichen
Fälle dadurch definiert werden, daß wir keinen Grund haben, das
Eintreten des einen eher als das Eintreten des anderen zu erwarten.
Hierhin gehört es ferner, wenn angenommen wird, daß ein Ereignis,
dessen mathematische Wahrscheinlichkeit der Einheit sehr nahe
kommt, als gewiß angesehen werden kann, weil wir in unserem
Leben fortwährend gezwungen sind, wegen der Unsicherheit aller
unserer Lebensumstände als gewiß hinzunehmen, was im Grunde
nur sehr wahrscheinlich ist. Die Analogie geht sogar tiefer, indem
wir die Unentschiedenheit eines künftigen Ereignisses mit der
Unentschiedenheit eines Menschen vergleichen, der zwischen zwei
Möglichkeiten zu wählen hat. Wenn wir von dem blinden Zufall
sprechen, so beruht dies darauf, daß die Entscheidung verglichen
wird mit der Entscheidung eines Menschen, der eine Möglichkeit
ohne Überlegung ergreift. Diese Eindeutung innerer Erlebnisse
in die äußeren Vorgänge ist dem menschlichen Geiste durchaus
natürlich, sie ist aber auch mit großen Gefahren verknüpft. Das
tritt tatsächlich in der Geschichte der Wahrscheinlichkeitsrechnung
deutlich zutage. Bei aller Großartigkeit der Entwickelung krankt
\zB~das Werk von \so{Laplace} daran, daß der Bereich des Ungewissen
\index{Laplace}%
ohne eine sichere empirische Grundlage allein aus dem
Denken heraus mit Hilfe der mathematischen Rechnung einer bestimmten
Analyse unterworfen werden soll. Rein äußerlich gibt
sich das darin zu erkennen, daß zu viel mathematische Entwickelungen
und zu wenig statistisches Material gegeben wird. Die
mathematische Ableitung ist aber nur ein formales Hilfsmittel. Aus
ihr allein läßt sich keine reale Erkenntnis schöpfen, wenn sie
nicht mit wirklicher Beobachtung gepaart wird. Es werden daher
bei \so{Laplace} eigentlich nur Methoden gegeben, ohne daß überhaupt
feststeht, wie weit diese Methoden sich auf Probleme der
Wirklichkeit überhaupt anwenden lassen. Wo solche Anwendungen
\DPPageSep{179}{165}
\index{Lipps@Lipps, G. F. (Herausgeber)}%
aufzutreten scheinen, beruhen sie nur auf unbestimmten Vermutungen
und unberechtigten Annahmen.

\so{Quételet} gebührt das große Verdienst, mit der Anwendung
\index{Quételet}%
der Wahrscheinlichkeitsrechnung auf die Wirklichkeit Ernst gemacht
zu haben\footnote
  {Vgl.\ insbesondere seine Lettres sur la théorie des probabilités
  appliquée aux sciences morales et politiques (Bruxelles 1846).}.
Aber auch er beging den Fehler, daß er zu selbstverständlich
die Übereinstimmung der Wirklichkeit mit den aus
dem einfachen Urnenschema folgenden Formeln der Wahrscheinlichkeitsrechnung
voraussetzte und sie häufig da zu sehen glaubte,
wo sie tatsächlich nicht vorhanden ist. Daher liegt ein ungeheurer
Vorteil in dem Aufkommen der eigentlich empirischen Methoden,
die sich eine unbefangene und sichere Feststellung der tatsächlichen
Verhältnisse zur Aufgabe machen und um deren Entwickelung
sich in Deutschland besonders W.~\so{Lexis} und G.~Th.~\so{Fechner}
\index{Fechner}%
\index{Lexis}%
und in England K.~\so{Pearson} verdient gemacht haben. Hier wird
\index{Pearson}%
in der Tat die mathematische Entwickelung nur ein Hilfsmittel,
um das statistische Material systematisch zu verarbeiten. Die
Verarbeitung besteht einerseits darin, daß die statistischen Ergebnisse
über solche Ereignisse, die in ihrer Verteilung eine gewisse
Gemeinsamkeit zeigen, vereinigt werden, und andererseits darin,
daß man in bestimmten Verteilungen eine einfache mathematisch
ausdrückbare Regelmäßigkeit nachzuweisen versucht.

Das Bezeichnende der Methode darf man vielleicht darin
sehen, daß gerade die Rücksichtnahme auf den ursächlichen Zusammenhang,
die sonst den Kern der Naturerklärung bildet, vollständig
in Wegfall kommt. Es ist wohl gut, nochmals hervorzuheben,
daß nach der in Rede stehenden Methode zwischen den
einzelnen Fällen keinerlei ursächlicher Zusammenhang, sondern nur
eine Gleichartigkeit der Bedingungen bei ihnen allen angenommen
wird. Die bei dem Urnenschema herauskommende Verteilung wird
ausdrücklich unter der Voraussetzung abgeleitet, daß eine Ziehung
mit der anderen außer allem kausalen Zusammenhang steht, daß es
für das Resultat einer Ziehung völlig gleichgültig ist, welche Resultate
die vorhergehenden Ziehungen ergeben haben. Die Ziehung
einer weißen Kugel bleibt in der Sprache der Wahrscheinlichkeitsrechnung
gleich wahrscheinlich, auch wenn schon zehn- oder
zwanzigmal hintereinander eine weiße Kugel gezogen worden ist.
\DPPageSep{180}{166}

Der Ausgleich zwischen den Resultaten der einzelnen Ziehungen
ist kein mechanischer, er beruht nicht auf einer Wirkung,
welche die Resultate der einen Ziehung auf das Resultat der
anderen ausüben. Er ist nur ein statistischer, \dh~wir haben uns
zu denken, daß er da zustande kommt, wo die Bedingungen des
Geschehens, soweit sie festliegen, unverändert bleiben. Wenn es
eine Ordnung des Geschehens in dem Sinne gibt, daß für das
Resultat des einen Falles es nicht gleichgültig ist, welches die
Resultate der vorhergehenden Fälle waren, so bleibt diese Ordnung
hier unberücksichtigt, sei es nun, daß sie in einer gewissen Neigung
der gleichartigen Resultate, sich räumlich oder zeitlich zusammenzuschließen
oder in einer bestimmten prädestinierten Verteilung
der verschiedenen Resultate bestehen soll. Das ganze Schwergewicht
der Betrachtung ruht darauf, daß eine Erklärung der
stattfindenden Verteilung auch möglich ist, ohne einen inneren
Zusammenhang der Einzelergebnisse vorauszusetzen.

Wenn die Beiseiteschiebung des kausalen Zusammenhanges
das Bezeichnende an den angestellten Betrachtungen sein soll, so
scheint dieses Prinzip nur bei der genetischen Erklärung des
Zufalls durchbrochen zu sein. Es ist aber leicht zu erkennen,
daß auch hier nicht das Zufallsereignis aus einer großen Menge
voneinander unabhängiger Einzelursachen kausal erklärt werden
soll, sondern daß es vielmehr als zusammengesetzt erscheint aus
einer großen Menge voneinander unabhängiger Einzelmomente.
Das Wesentliche ist auch hier wieder gerade das Fehlen des
kausalen Zusammenhanges zwischen den einzelnen Bestandteilen
des Zufallsereignisses. Es bleibt also immer das Fehlen des kausalen
Zusammenhanges das Bezeichnende für die genetische Erklärung
der Zufallsereignisse, gleichgültig, ob wir dieses Fehlen
als ein absolutes oder als ein relatives, \dh~als das Fehlen einer
engeren kausalen Verknüpfung, ansehen wollen.

Aber die genetische Erklärung des einzelnen Zufallsereignisses
war nicht das, worauf die angestellten Betrachtungen hauptsächlich
abzielten. Im Gegenteil kann man ihr Wesen darin erblicken,
daß sie von der Betrachtung des Zufalls im einzelnen
Ereignisse ablenken, daß sie die Fragestellung vielmehr auf die
Gesamtheit der Erscheinungen hinwenden.

Auch von vornherein wird man zugeben, daß das einzelne
Zufallsereignis nicht das ist, was im Grunde unsere Teilnahme
\DPPageSep{181}{167}
erweckt, daß vielmehr die wirkliche Aufgabe in der Beantwortung
der Frage liegt, wie die Zufallsereignisse in ihrer Gesamtheit auf
das Getriebe der Welt einwirken. Die Antwort ist klipp und klar
die, daß das, was im einzelnen Ereignis als zufällig und unberechenbar
erscheint, in der Totalität der Erscheinungen durch einen
gewissen Ausgleich beseitigt wird. Allerdings eine Erklärung, die
im tieferen Sinne befriedigt, für diesen Ausgleich zu finden, ist uns
nicht gelungen. Unsere Betrachtung blieb auch hier auf die Beobachtung
des Tatsächlichen und die Feststellung der darin
liegenden Regelmäßigkeiten beschränkt, genau so wie sie es da ist,
wo die mit einer durchgängigen Kausalität des Naturgeschehens
in Zusammenhang stehenden "`Naturgesetze"' den Gegenstand der
Untersuchung bilden.

Daß eine allgemeine genetische Erklärung des Zufalls nicht
geliefert ist, gibt sich auch darin zu erkennen, daß nach der
statistischen Theorie ein Ereignis als zufällig nur innerhalb einer
bestimmten Gesamtheit erscheint. So ergab sich die Verteilung
der Körpergröße unter den durch die Aushebungen in einem großen
Gebiete herausgegriffenen erwachsenen männlichen Individuen als
die typische Zufallsverteilung. Dabei können wir die Körpergröße,
die ein Mensch erreicht, doch nicht als rein zufällig hinstellen.
Im Gegenteil sind uns bestimmte Momente, \zB~die Körpergröße
der Eltern, bekannt, die einen Einfluß auf das körperliche Wachstum
ausüben. Diesen und ähnlichen Einflüssen nachzugehen, war
hier nicht unsere Aufgabe. Es scheint aber nötig, zum Schluß auf
ihr Bestehen noch nachdrücklich hinzuweisen, damit nicht der
Eindruck entsteht, als solle aus dem Vergleich mit dem Schema
der Glücksspiele, der uns für die mathematische Behandlung die
Handhabe gegeben hat, eine innere Gleichartigkeit gefolgert werden,
als solle verkannt werden, wie ungleich verwickelter in ihrer inneren
Beschaffenheit die Vorgänge in der menschlichen Gesellschaft sind,
als die wenigstens beim ersten Anblick sehr einfach scheinenden
Vorgänge der Urnenziehungen.
\EndChap
\DPPageSep{182}{168}
\PrintIndex
\iffalse
Namenverzeichnis
(Die Zahlen bedeuten die Seiten.)

Abbe 89.
Alembert@{d'Alembert|f}#Alembert 51
Aristoteles 56.

Bernoullische Theorem 66. %[** TN: "Bernoullisches Theorem" in original]
Bertillon 141.
Bessel@{Bessel|f}#Bessel 14, 154.
Blaschke 140.
Borel 66.
Bortkewitsch@{Bortkewitsch (Bortkiewicz), Lad.\ v.}#Bortkewitsch 52, 138, 147, 151. %** 151 ff.
Boylesches (Mariottesches) Gesetz 31.
Bromse@{Brömse}#Brömse 52.
Brownsche Bewegung 146.
Bruns 66, 133.

Cardano 58.
Carvallo 66.
Cournot 4.
Crofton 157.
Czuber 147, 153.

Davenport 147, 150.
Edgeworth 147.
Elster (Herausgeber) 153.

Fechner 151, 165.
Fechnersches Lagengesetz 81.
Forcher 140, 150.
Fries@{Fries, J. F.}#Fries VI.

Galilei@{Galilei|f}#Galilei 58.
Galton 150.
Gauß 93.
Gaußsche@{Gaußsche Verteilungsfunktion|uo}#Gaußsche 109.
Goethe 6.
Goldschmidt 54.
Grimsehl 52.

Helmert 89.
Hume 5.
Huygens 60.

Iterson 31.

Kant 3, 7.
King 147.
Kozak VIII.
Kries@{Kries, Joh.\ v.}#Kries 61.

Lange@{Lange, Friedr.\ Albert}#Lange 47, 57, 62. %** 62 f.
Laplace 45 f., 55, 61, 164.
Lexis 40, 135, 151, 153, 165. %** 40 f. 135 ff.
Lipps@{Lipps, G. F. (Herausgeber)}#Lipps 151, 153, 165.
Lottermoser (Übersetzer) 146.
Lourié 62.

Marbe 52.
Maxwell 43.
Mayr, v. 153.
Mill@{Mill, John Stuart|f}#Mill 1.

Pearson 33, 145, 165. %** 145 ff.
Perrin 146.
Poisson 45, 55, 111, 138, 147. %** 147 f.

Quételet 22, 148, 165.

Rhumbler 31.

Sabudski-Eberhard VIII.
Schnuse (Übersetzer) 45.
Schopenhauer 2.
Siebeck 6.
Sigwart 16, 47, 63. %** 63 f.
Spinoza 4, 6. %** 6 f.
Sterzinger 53.
Stirlingsche Formel 110.
Stumpf 63.

Trendelenburg 57.

Ueberweg 56.

Valla, Laurentius 57.
Venn 148.

Wagner, Ad. 38.
Weldon 150.
Westergaard 147.
Windelband 38, 44.
Wolf, R. 68.
Wundt, Wilh. 14, 46. %** 14 f.
\fi
%%%%%%%%%%%%%%%%%%%%%%%%% GUTENBERG LICENSE %%%%%%%%%%%%%%%%%%%%%%%%%%
\LicenseInit
\begin{PGtext}
End of the Project Gutenberg EBook of Die Analyse des Zufalls, by 
H. E. (Heinrich Emil) Timerding

*** END OF THIS PROJECT GUTENBERG EBOOK DIE ANALYSE DES ZUFALLS ***

***** This file should be named 36310-pdf.pdf or 36310-pdf.zip *****
This and all associated files of various formats will be found in:
        http://www.gutenberg.org/3/6/3/1/36310/

Produced by Andrew D. Hwang, R. Stephan, Joshua Hutchinson,
and the Online Distributed Proofreading Team at
http://www.pgdp.net. (This ebook was produced using images
provided by the Cornell University Library Historical
Mathematics Monographs collection.)


Updated editions will replace the previous one--the old editions
will be renamed.

Creating the works from public domain print editions means that no
one owns a United States copyright in these works, so the Foundation
(and you!) can copy and distribute it in the United States without
permission and without paying copyright royalties.  Special rules,
set forth in the General Terms of Use part of this license, apply to
copying and distributing Project Gutenberg-tm electronic works to
protect the PROJECT GUTENBERG-tm concept and trademark.  Project
Gutenberg is a registered trademark, and may not be used if you
charge for the eBooks, unless you receive specific permission.  If you
do not charge anything for copies of this eBook, complying with the
rules is very easy.  You may use this eBook for nearly any purpose
such as creation of derivative works, reports, performances and
research.  They may be modified and printed and given away--you may do
practically ANYTHING with public domain eBooks.  Redistribution is
subject to the trademark license, especially commercial
redistribution.



*** START: FULL LICENSE ***

THE FULL PROJECT GUTENBERG LICENSE
PLEASE READ THIS BEFORE YOU DISTRIBUTE OR USE THIS WORK

To protect the Project Gutenberg-tm mission of promoting the free
distribution of electronic works, by using or distributing this work
(or any other work associated in any way with the phrase "Project
Gutenberg"), you agree to comply with all the terms of the Full Project
Gutenberg-tm License (available with this file or online at
http://gutenberg.net/license).


Section 1.  General Terms of Use and Redistributing Project Gutenberg-tm
electronic works

1.A.  By reading or using any part of this Project Gutenberg-tm
electronic work, you indicate that you have read, understand, agree to
and accept all the terms of this license and intellectual property
(trademark/copyright) agreement.  If you do not agree to abide by all
the terms of this agreement, you must cease using and return or destroy
all copies of Project Gutenberg-tm electronic works in your possession.
If you paid a fee for obtaining a copy of or access to a Project
Gutenberg-tm electronic work and you do not agree to be bound by the
terms of this agreement, you may obtain a refund from the person or
entity to whom you paid the fee as set forth in paragraph 1.E.8.

1.B.  "Project Gutenberg" is a registered trademark.  It may only be
used on or associated in any way with an electronic work by people who
agree to be bound by the terms of this agreement.  There are a few
things that you can do with most Project Gutenberg-tm electronic works
even without complying with the full terms of this agreement.  See
paragraph 1.C below.  There are a lot of things you can do with Project
Gutenberg-tm electronic works if you follow the terms of this agreement
and help preserve free future access to Project Gutenberg-tm electronic
works.  See paragraph 1.E below.

1.C.  The Project Gutenberg Literary Archive Foundation ("the Foundation"
or PGLAF), owns a compilation copyright in the collection of Project
Gutenberg-tm electronic works.  Nearly all the individual works in the
collection are in the public domain in the United States.  If an
individual work is in the public domain in the United States and you are
located in the United States, we do not claim a right to prevent you from
copying, distributing, performing, displaying or creating derivative
works based on the work as long as all references to Project Gutenberg
are removed.  Of course, we hope that you will support the Project
Gutenberg-tm mission of promoting free access to electronic works by
freely sharing Project Gutenberg-tm works in compliance with the terms of
this agreement for keeping the Project Gutenberg-tm name associated with
the work.  You can easily comply with the terms of this agreement by
keeping this work in the same format with its attached full Project
Gutenberg-tm License when you share it without charge with others.

1.D.  The copyright laws of the place where you are located also govern
what you can do with this work.  Copyright laws in most countries are in
a constant state of change.  If you are outside the United States, check
the laws of your country in addition to the terms of this agreement
before downloading, copying, displaying, performing, distributing or
creating derivative works based on this work or any other Project
Gutenberg-tm work.  The Foundation makes no representations concerning
the copyright status of any work in any country outside the United
States.

1.E.  Unless you have removed all references to Project Gutenberg:

1.E.1.  The following sentence, with active links to, or other immediate
access to, the full Project Gutenberg-tm License must appear prominently
whenever any copy of a Project Gutenberg-tm work (any work on which the
phrase "Project Gutenberg" appears, or with which the phrase "Project
Gutenberg" is associated) is accessed, displayed, performed, viewed,
copied or distributed:

This eBook is for the use of anyone anywhere at no cost and with
almost no restrictions whatsoever.  You may copy it, give it away or
re-use it under the terms of the Project Gutenberg License included
with this eBook or online at www.gutenberg.net

1.E.2.  If an individual Project Gutenberg-tm electronic work is derived
from the public domain (does not contain a notice indicating that it is
posted with permission of the copyright holder), the work can be copied
and distributed to anyone in the United States without paying any fees
or charges.  If you are redistributing or providing access to a work
with the phrase "Project Gutenberg" associated with or appearing on the
work, you must comply either with the requirements of paragraphs 1.E.1
through 1.E.7 or obtain permission for the use of the work and the
Project Gutenberg-tm trademark as set forth in paragraphs 1.E.8 or
1.E.9.

1.E.3.  If an individual Project Gutenberg-tm electronic work is posted
with the permission of the copyright holder, your use and distribution
must comply with both paragraphs 1.E.1 through 1.E.7 and any additional
terms imposed by the copyright holder.  Additional terms will be linked
to the Project Gutenberg-tm License for all works posted with the
permission of the copyright holder found at the beginning of this work.

1.E.4.  Do not unlink or detach or remove the full Project Gutenberg-tm
License terms from this work, or any files containing a part of this
work or any other work associated with Project Gutenberg-tm.

1.E.5.  Do not copy, display, perform, distribute or redistribute this
electronic work, or any part of this electronic work, without
prominently displaying the sentence set forth in paragraph 1.E.1 with
active links or immediate access to the full terms of the Project
Gutenberg-tm License.

1.E.6.  You may convert to and distribute this work in any binary,
compressed, marked up, nonproprietary or proprietary form, including any
word processing or hypertext form.  However, if you provide access to or
distribute copies of a Project Gutenberg-tm work in a format other than
"Plain Vanilla ASCII" or other format used in the official version
posted on the official Project Gutenberg-tm web site (www.gutenberg.net),
you must, at no additional cost, fee or expense to the user, provide a
copy, a means of exporting a copy, or a means of obtaining a copy upon
request, of the work in its original "Plain Vanilla ASCII" or other
form.  Any alternate format must include the full Project Gutenberg-tm
License as specified in paragraph 1.E.1.

1.E.7.  Do not charge a fee for access to, viewing, displaying,
performing, copying or distributing any Project Gutenberg-tm works
unless you comply with paragraph 1.E.8 or 1.E.9.

1.E.8.  You may charge a reasonable fee for copies of or providing
access to or distributing Project Gutenberg-tm electronic works provided
that

- You pay a royalty fee of 20% of the gross profits you derive from
     the use of Project Gutenberg-tm works calculated using the method
     you already use to calculate your applicable taxes.  The fee is
     owed to the owner of the Project Gutenberg-tm trademark, but he
     has agreed to donate royalties under this paragraph to the
     Project Gutenberg Literary Archive Foundation.  Royalty payments
     must be paid within 60 days following each date on which you
     prepare (or are legally required to prepare) your periodic tax
     returns.  Royalty payments should be clearly marked as such and
     sent to the Project Gutenberg Literary Archive Foundation at the
     address specified in Section 4, "Information about donations to
     the Project Gutenberg Literary Archive Foundation."

- You provide a full refund of any money paid by a user who notifies
     you in writing (or by e-mail) within 30 days of receipt that s/he
     does not agree to the terms of the full Project Gutenberg-tm
     License.  You must require such a user to return or
     destroy all copies of the works possessed in a physical medium
     and discontinue all use of and all access to other copies of
     Project Gutenberg-tm works.

- You provide, in accordance with paragraph 1.F.3, a full refund of any
     money paid for a work or a replacement copy, if a defect in the
     electronic work is discovered and reported to you within 90 days
     of receipt of the work.

- You comply with all other terms of this agreement for free
     distribution of Project Gutenberg-tm works.

1.E.9.  If you wish to charge a fee or distribute a Project Gutenberg-tm
electronic work or group of works on different terms than are set
forth in this agreement, you must obtain permission in writing from
both the Project Gutenberg Literary Archive Foundation and Michael
Hart, the owner of the Project Gutenberg-tm trademark.  Contact the
Foundation as set forth in Section 3 below.

1.F.

1.F.1.  Project Gutenberg volunteers and employees expend considerable
effort to identify, do copyright research on, transcribe and proofread
public domain works in creating the Project Gutenberg-tm
collection.  Despite these efforts, Project Gutenberg-tm electronic
works, and the medium on which they may be stored, may contain
"Defects," such as, but not limited to, incomplete, inaccurate or
corrupt data, transcription errors, a copyright or other intellectual
property infringement, a defective or damaged disk or other medium, a
computer virus, or computer codes that damage or cannot be read by
your equipment.

1.F.2.  LIMITED WARRANTY, DISCLAIMER OF DAMAGES - Except for the "Right
of Replacement or Refund" described in paragraph 1.F.3, the Project
Gutenberg Literary Archive Foundation, the owner of the Project
Gutenberg-tm trademark, and any other party distributing a Project
Gutenberg-tm electronic work under this agreement, disclaim all
liability to you for damages, costs and expenses, including legal
fees.  YOU AGREE THAT YOU HAVE NO REMEDIES FOR NEGLIGENCE, STRICT
LIABILITY, BREACH OF WARRANTY OR BREACH OF CONTRACT EXCEPT THOSE
PROVIDED IN PARAGRAPH 1.F.3.  YOU AGREE THAT THE FOUNDATION, THE
TRADEMARK OWNER, AND ANY DISTRIBUTOR UNDER THIS AGREEMENT WILL NOT BE
LIABLE TO YOU FOR ACTUAL, DIRECT, INDIRECT, CONSEQUENTIAL, PUNITIVE OR
INCIDENTAL DAMAGES EVEN IF YOU GIVE NOTICE OF THE POSSIBILITY OF SUCH
DAMAGE.

1.F.3.  LIMITED RIGHT OF REPLACEMENT OR REFUND - If you discover a
defect in this electronic work within 90 days of receiving it, you can
receive a refund of the money (if any) you paid for it by sending a
written explanation to the person you received the work from.  If you
received the work on a physical medium, you must return the medium with
your written explanation.  The person or entity that provided you with
the defective work may elect to provide a replacement copy in lieu of a
refund.  If you received the work electronically, the person or entity
providing it to you may choose to give you a second opportunity to
receive the work electronically in lieu of a refund.  If the second copy
is also defective, you may demand a refund in writing without further
opportunities to fix the problem.

1.F.4.  Except for the limited right of replacement or refund set forth
in paragraph 1.F.3, this work is provided to you 'AS-IS' WITH NO OTHER
WARRANTIES OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO
WARRANTIES OF MERCHANTIBILITY OR FITNESS FOR ANY PURPOSE.

1.F.5.  Some states do not allow disclaimers of certain implied
warranties or the exclusion or limitation of certain types of damages.
If any disclaimer or limitation set forth in this agreement violates the
law of the state applicable to this agreement, the agreement shall be
interpreted to make the maximum disclaimer or limitation permitted by
the applicable state law.  The invalidity or unenforceability of any
provision of this agreement shall not void the remaining provisions.

1.F.6.  INDEMNITY - You agree to indemnify and hold the Foundation, the
trademark owner, any agent or employee of the Foundation, anyone
providing copies of Project Gutenberg-tm electronic works in accordance
with this agreement, and any volunteers associated with the production,
promotion and distribution of Project Gutenberg-tm electronic works,
harmless from all liability, costs and expenses, including legal fees,
that arise directly or indirectly from any of the following which you do
or cause to occur: (a) distribution of this or any Project Gutenberg-tm
work, (b) alteration, modification, or additions or deletions to any
Project Gutenberg-tm work, and (c) any Defect you cause.


Section  2.  Information about the Mission of Project Gutenberg-tm

Project Gutenberg-tm is synonymous with the free distribution of
electronic works in formats readable by the widest variety of computers
including obsolete, old, middle-aged and new computers.  It exists
because of the efforts of hundreds of volunteers and donations from
people in all walks of life.

Volunteers and financial support to provide volunteers with the
assistance they need are critical to reaching Project Gutenberg-tm's
goals and ensuring that the Project Gutenberg-tm collection will
remain freely available for generations to come.  In 2001, the Project
Gutenberg Literary Archive Foundation was created to provide a secure
and permanent future for Project Gutenberg-tm and future generations.
To learn more about the Project Gutenberg Literary Archive Foundation
and how your efforts and donations can help, see Sections 3 and 4
and the Foundation web page at http://www.pglaf.org.


Section 3.  Information about the Project Gutenberg Literary Archive
Foundation

The Project Gutenberg Literary Archive Foundation is a non profit
501(c)(3) educational corporation organized under the laws of the
state of Mississippi and granted tax exempt status by the Internal
Revenue Service.  The Foundation's EIN or federal tax identification
number is 64-6221541.  Its 501(c)(3) letter is posted at
http://pglaf.org/fundraising.  Contributions to the Project Gutenberg
Literary Archive Foundation are tax deductible to the full extent
permitted by U.S. federal laws and your state's laws.

The Foundation's principal office is located at 4557 Melan Dr. S.
Fairbanks, AK, 99712., but its volunteers and employees are scattered
throughout numerous locations.  Its business office is located at
809 North 1500 West, Salt Lake City, UT 84116, (801) 596-1887, email
business@pglaf.org.  Email contact links and up to date contact
information can be found at the Foundation's web site and official
page at http://pglaf.org

For additional contact information:
     Dr. Gregory B. Newby
     Chief Executive and Director
     gbnewby@pglaf.org


Section 4.  Information about Donations to the Project Gutenberg
Literary Archive Foundation

Project Gutenberg-tm depends upon and cannot survive without wide
spread public support and donations to carry out its mission of
increasing the number of public domain and licensed works that can be
freely distributed in machine readable form accessible by the widest
array of equipment including outdated equipment.  Many small donations
($1 to $5,000) are particularly important to maintaining tax exempt
status with the IRS.

The Foundation is committed to complying with the laws regulating
charities and charitable donations in all 50 states of the United
States.  Compliance requirements are not uniform and it takes a
considerable effort, much paperwork and many fees to meet and keep up
with these requirements.  We do not solicit donations in locations
where we have not received written confirmation of compliance.  To
SEND DONATIONS or determine the status of compliance for any
particular state visit http://pglaf.org

While we cannot and do not solicit contributions from states where we
have not met the solicitation requirements, we know of no prohibition
against accepting unsolicited donations from donors in such states who
approach us with offers to donate.

International donations are gratefully accepted, but we cannot make
any statements concerning tax treatment of donations received from
outside the United States.  U.S. laws alone swamp our small staff.

Please check the Project Gutenberg Web pages for current donation
methods and addresses.  Donations are accepted in a number of other
ways including including checks, online payments and credit card
donations.  To donate, please visit: http://pglaf.org/donate


Section 5.  General Information About Project Gutenberg-tm electronic
works.

Professor Michael S. Hart is the originator of the Project Gutenberg-tm
concept of a library of electronic works that could be freely shared
with anyone.  For thirty years, he produced and distributed Project
Gutenberg-tm eBooks with only a loose network of volunteer support.


Project Gutenberg-tm eBooks are often created from several printed
editions, all of which are confirmed as Public Domain in the U.S.
unless a copyright notice is included.  Thus, we do not necessarily
keep eBooks in compliance with any particular paper edition.


Most people start at our Web site which has the main PG search facility:

     http://www.gutenberg.net

This Web site includes information about Project Gutenberg-tm,
including how to make donations to the Project Gutenberg Literary
Archive Foundation, how to help produce our new eBooks, and how to
subscribe to our email newsletter to hear about new eBooks.
\end{PGtext}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %
%                                                                         %
% End of the Project Gutenberg EBook of Die Analyse des Zufalls, by       %
% H. E. (Heinrich Emil) Timerding                                         %
%                                                                         %
% *** END OF THIS PROJECT GUTENBERG EBOOK DIE ANALYSE DES ZUFALLS ***     %
%                                                                         %
% ***** This file should be named 36310-t.tex or 36310-t.zip *****        %
% This and all associated files of various formats will be found in:      %
%         http://www.gutenberg.org/3/6/3/1/36310/                         %
%                                                                         %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %

\end{document}
###
@ControlwordReplace = (
  ['\\tableofcontents', 'Inhaltverzeichnis.'],
  ['\\Vorwort', 'Vorwort.'],
  ['\\aaO', 'a. a. O.'],
  ['\\dh', 'd. h.'],
  ['\\zB', 'z. B.']
  );

@ControlwordArguments = (
  ['\\Chapter', 1, 1, '', '.  ', 1, 1, '', '.'],
  ['\\Signature', 1, 1, '', ' ', 1, 1, '', ''],
  ['\\BookMark', 1, 0, '', '', 1, 0, '', ''],
  ['\\DPPageSep', 1, 0, '', '-----', 1, 0, '', ''],
  ['\\DPtypo', 1, 0, '', '', 1, 1, '', ''],
  ['\\DPnote', 1, 0, '', ''],
  ['\\Eqref', 1, 1, '', ''],
  ['\\Fig', 1, 1, 'Fig. ', ' ']
  );
###
This is pdfTeXk, Version 3.141592-1.40.3 (Web2C 7.5.6) (format=pdflatex 2010.5.6)  5 JUN 2011 19:56
entering extended mode
 %&-line parsing enabled.
**36310-t.tex
(./36310-t.tex
LaTeX2e <2005/12/01>
Babel <v3.8h> and hyphenation patterns for english, usenglishmax, dumylang, noh
yphenation, arabic, farsi, croatian, ukrainian, russian, bulgarian, czech, slov
ak, danish, dutch, finnish, basque, french, german, ngerman, ibycus, greek, mon
ogreek, ancientgreek, hungarian, italian, latin, mongolian, norsk, icelandic, i
nterlingua, turkish, coptic, romanian, welsh, serbian, slovenian, estonian, esp
eranto, uppersorbian, indonesian, polish, portuguese, spanish, catalan, galicia
n, swedish, ukenglish, pinyin, loaded.
(/usr/share/texmf-texlive/tex/latex/base/book.cls
Document Class: book 2005/09/16 v1.4f Standard LaTeX document class
(/usr/share/texmf-texlive/tex/latex/base/leqno.clo
File: leqno.clo 1998/08/17 v1.1c Standard LaTeX option (left equation numbers)
) (/usr/share/texmf-texlive/tex/latex/base/bk12.clo
File: bk12.clo 2005/09/16 v1.4f Standard LaTeX file (size option)
)
\c@part=\count79
\c@chapter=\count80
\c@section=\count81
\c@subsection=\count82
\c@subsubsection=\count83
\c@paragraph=\count84
\c@subparagraph=\count85
\c@figure=\count86
\c@table=\count87
\abovecaptionskip=\skip41
\belowcaptionskip=\skip42
\bibindent=\dimen102
) (/usr/share/texmf-texlive/tex/latex/base/inputenc.sty
Package: inputenc 2006/05/05 v1.1b Input encoding file
\inpenc@prehook=\toks14
\inpenc@posthook=\toks15
(/usr/share/texmf-texlive/tex/latex/base/latin1.def
File: latin1.def 2006/05/05 v1.1b Input encoding file
)) (/usr/share/texmf-texlive/tex/latex/base/fontenc.sty
Package: fontenc 2005/09/27 v1.99g Standard LaTeX package
(/usr/share/texmf-texlive/tex/latex/base/t1enc.def
File: t1enc.def 2005/09/27 v1.99g Standard LaTeX file
LaTeX Font Info:    Redeclaring font encoding T1 on input line 43.
)) (/usr/share/texmf-texlive/tex/generic/babel/babel.sty
Package: babel 2005/11/23 v3.8h The Babel package
(/usr/share/texmf-texlive/tex/generic/babel/greek.ldf
Language: greek 2005/03/30 v1.3l Greek support from the babel system
(/usr/share/texmf-texlive/tex/generic/babel/babel.def
File: babel.def 2005/11/23 v3.8h Babel common definitions
\babel@savecnt=\count88
\U@D=\dimen103
) Loading the definitions for the Greek font encoding (/usr/share/texmf-texlive
/tex/generic/babel/lgrenc.def
File: lgrenc.def 2001/01/30 v2.2e Greek Encoding
)) (/usr/share/texmf-texlive/tex/generic/babel/ngermanb.ldf
Language: ngermanb 2004/02/20 v2.6m new German support from the babel system
\l@naustrian = a dialect from \language\l@ngerman 
Package babel Info: Making " an active character on input line 92.
)) (/usr/share/texmf-texlive/tex/latex/amsmath/amsmath.sty
Package: amsmath 2000/07/18 v2.13 AMS math features
\@mathmargin=\skip43
For additional information on amsmath, use the `?' option.
(/usr/share/texmf-texlive/tex/latex/amsmath/amstext.sty
Package: amstext 2000/06/29 v2.01
(/usr/share/texmf-texlive/tex/latex/amsmath/amsgen.sty
File: amsgen.sty 1999/11/30 v2.0
\@emptytoks=\toks16
\ex@=\dimen104
)) (/usr/share/texmf-texlive/tex/latex/amsmath/amsbsy.sty
Package: amsbsy 1999/11/29 v1.2d
\pmbraise@=\dimen105
) (/usr/share/texmf-texlive/tex/latex/amsmath/amsopn.sty
Package: amsopn 1999/12/14 v2.01 operator names
)
\inf@bad=\count89
LaTeX Info: Redefining \frac on input line 211.
\uproot@=\count90
\leftroot@=\count91
LaTeX Info: Redefining \overline on input line 307.
\classnum@=\count92
\DOTSCASE@=\count93
LaTeX Info: Redefining \ldots on input line 379.
LaTeX Info: Redefining \dots on input line 382.
LaTeX Info: Redefining \cdots on input line 467.
\Mathstrutbox@=\box26
\strutbox@=\box27
\big@size=\dimen106
LaTeX Font Info:    Redeclaring font encoding OML on input line 567.
LaTeX Font Info:    Redeclaring font encoding OMS on input line 568.
\macc@depth=\count94
\c@MaxMatrixCols=\count95
\dotsspace@=\muskip10
\c@parentequation=\count96
\dspbrk@lvl=\count97
\tag@help=\toks17
\row@=\count98
\column@=\count99
\maxfields@=\count100
\andhelp@=\toks18
\eqnshift@=\dimen107
\alignsep@=\dimen108
\tagshift@=\dimen109
\tagwidth@=\dimen110
\totwidth@=\dimen111
\lineht@=\dimen112
\@envbody=\toks19
\multlinegap=\skip44
\multlinetaggap=\skip45
\mathdisplay@stack=\toks20
LaTeX Info: Redefining \[ on input line 2666.
LaTeX Info: Redefining \] on input line 2667.
) (/usr/share/texmf-texlive/tex/latex/amsfonts/amssymb.sty
Package: amssymb 2002/01/22 v2.2d
(/usr/share/texmf-texlive/tex/latex/amsfonts/amsfonts.sty
Package: amsfonts 2001/10/25 v2.2f
\symAMSa=\mathgroup4
\symAMSb=\mathgroup5
LaTeX Font Info:    Overwriting math alphabet `\mathfrak' in version `bold'
(Font)                  U/euf/m/n --> U/euf/b/n on input line 132.
)) (/usr/share/texmf-texlive/tex/latex/jknapltx/mathrsfs.sty
Package: mathrsfs 1996/01/01 Math RSFS package v1.0 (jk)
\symrsfs=\mathgroup6
) (/usr/share/texmf-texlive/tex/latex/base/ifthen.sty
Package: ifthen 2001/05/26 v1.1c Standard LaTeX ifthen package (DPC)
) (/usr/share/texmf-texlive/tex/latex/base/alltt.sty
Package: alltt 1997/06/16 v2.0g defines alltt environment
) (/usr/share/texmf-texlive/tex/latex/tools/indentfirst.sty
Package: indentfirst 1995/11/23 v1.03 Indent first paragraph (DPC)
) (/usr/share/texmf-texlive/tex/latex/base/makeidx.sty
Package: makeidx 2000/03/29 v1.0m Standard LaTeX package
) (/usr/share/texmf-texlive/tex/latex/tools/multicol.sty
Package: multicol 2006/05/18 v1.6g multicolumn formatting (FMi)
\c@tracingmulticols=\count101
\mult@box=\box28
\multicol@leftmargin=\dimen113
\c@unbalance=\count102
\c@collectmore=\count103
\doublecol@number=\count104
\multicoltolerance=\count105
\multicolpretolerance=\count106
\full@width=\dimen114
\page@free=\dimen115
\premulticols=\dimen116
\postmulticols=\dimen117
\multicolsep=\skip46
\multicolbaselineskip=\skip47
\partial@page=\box29
\last@line=\box30
\mult@rightbox=\box31
\mult@grightbox=\box32
\mult@gfirstbox=\box33
\mult@firstbox=\box34
\@tempa=\box35
\@tempa=\box36
\@tempa=\box37
\@tempa=\box38
\@tempa=\box39
\@tempa=\box40
\@tempa=\box41
\@tempa=\box42
\@tempa=\box43
\@tempa=\box44
\@tempa=\box45
\@tempa=\box46
\@tempa=\box47
\@tempa=\box48
\@tempa=\box49
\@tempa=\box50
\@tempa=\box51
\c@columnbadness=\count107
\c@finalcolumnbadness=\count108
\last@try=\dimen118
\multicolovershoot=\dimen119
\multicolundershoot=\dimen120
\mult@nat@firstbox=\box52
\colbreak@box=\box53
) (/usr/share/texmf-texlive/tex/latex/tools/array.sty
Package: array 2005/08/23 v2.4b Tabular extension package (FMi)
\col@sep=\dimen121
\extrarowheight=\dimen122
\NC@list=\toks21
\extratabsurround=\skip48
\backup@length=\skip49
) (/usr/share/texmf-texlive/tex/latex/tools/longtable.sty
Package: longtable 2004/02/01 v4.11 Multi-page Table package (DPC)
\LTleft=\skip50
\LTright=\skip51
\LTpre=\skip52
\LTpost=\skip53
\LTchunksize=\count109
\LTcapwidth=\dimen123
\LT@head=\box54
\LT@firsthead=\box55
\LT@foot=\box56
\LT@lastfoot=\box57
\LT@cols=\count110
\LT@rows=\count111
\c@LT@tables=\count112
\c@LT@chunks=\count113
\LT@p@ftn=\toks22
) (/usr/share/texmf-texlive/tex/latex/multirow/multirow.sty
\bigstrutjot=\dimen124
) (/usr/share/texmf-texlive/tex/latex/soul/soul.sty
Package: soul 2003/11/17 v2.4 letterspacing/underlining (mf)
\SOUL@word=\toks23
\SOUL@lasttoken=\toks24
\SOUL@cmds=\toks25
\SOUL@buffer=\toks26
\SOUL@token=\toks27
\SOUL@spaceskip=\skip54
\SOUL@ttwidth=\dimen125
\SOUL@uldp=\dimen126
\SOUL@ulht=\dimen127
)
LaTeX Info: Redefining \so on input line 127.
(/usr/share/texmf-texlive/tex/latex/footmisc/footmisc.sty
Package: footmisc 2005/03/17 v5.3d a miscellany of footnote facilities
\FN@temptoken=\toks28
\footnotemargin=\dimen128
\c@pp@next@reset=\count114
\c@@fnserial=\count115
Package footmisc Info: Declaring symbol style bringhurst on input line 817.
Package footmisc Info: Declaring symbol style chicago on input line 818.
Package footmisc Info: Declaring symbol style wiley on input line 819.
Package footmisc Info: Declaring symbol style lamport-robust on input line 823.

Package footmisc Info: Declaring symbol style lamport* on input line 831.
Package footmisc Info: Declaring symbol style lamport*-robust on input line 840
.
) (/usr/share/texmf-texlive/tex/latex/graphics/graphicx.sty
Package: graphicx 1999/02/16 v1.0f Enhanced LaTeX Graphics (DPC,SPQR)
(/usr/share/texmf-texlive/tex/latex/graphics/keyval.sty
Package: keyval 1999/03/16 v1.13 key=value parser (DPC)
\KV@toks@=\toks29
) (/usr/share/texmf-texlive/tex/latex/graphics/graphics.sty
Package: graphics 2006/02/20 v1.0o Standard LaTeX Graphics (DPC,SPQR)
(/usr/share/texmf-texlive/tex/latex/graphics/trig.sty
Package: trig 1999/03/16 v1.09 sin cos tan (DPC)
) (/etc/texmf/tex/latex/config/graphics.cfg
File: graphics.cfg 2007/01/18 v1.5 graphics configuration of teTeX/TeXLive
)
Package graphics Info: Driver file: pdftex.def on input line 90.
(/usr/share/texmf-texlive/tex/latex/pdftex-def/pdftex.def
File: pdftex.def 2007/01/08 v0.04d Graphics/color for pdfTeX
\Gread@gobject=\count116
))
\Gin@req@height=\dimen129
\Gin@req@width=\dimen130
)

LaTeX Warning: You have requested, on input line 131, version
               `2006/02/20' of package graphicx,
               but only version
               `1999/02/16 v1.0f Enhanced LaTeX Graphics (DPC,SPQR)'
               is available.

(/usr/share/texmf-texlive/tex/latex/caption/caption.sty
Package: caption 2007/01/07 v3.0k Customising captions (AR)
(/usr/share/texmf-texlive/tex/latex/caption/caption3.sty
Package: caption3 2007/01/07 v3.0k caption3 kernel (AR)
\captionmargin=\dimen131
\captionmarginx=\dimen132
\captionwidth=\dimen133
\captionindent=\dimen134
\captionparindent=\dimen135
\captionhangindent=\dimen136
)
Package caption Info: longtable package v3.15 (or newer) detected on input line
 359.
) (/usr/share/texmf-texlive/tex/latex/tools/calc.sty
Package: calc 2005/08/06 v4.2 Infix arithmetic (KKT,FJ)
\calc@Acount=\count117
\calc@Bcount=\count118
\calc@Adimen=\dimen137
\calc@Bdimen=\dimen138
\calc@Askip=\skip55
\calc@Bskip=\skip56
LaTeX Info: Redefining \setlength on input line 75.
LaTeX Info: Redefining \addtolength on input line 76.
\calc@Ccount=\count119
\calc@Cskip=\skip57
) (/usr/share/texmf-texlive/tex/latex/fancyhdr/fancyhdr.sty
\fancy@headwidth=\skip58
\f@ncyO@elh=\skip59
\f@ncyO@erh=\skip60
\f@ncyO@olh=\skip61
\f@ncyO@orh=\skip62
\f@ncyO@elf=\skip63
\f@ncyO@erf=\skip64
\f@ncyO@olf=\skip65
\f@ncyO@orf=\skip66
) (/usr/share/texmf-texlive/tex/latex/geometry/geometry.sty
Package: geometry 2002/07/08 v3.2 Page Geometry
\Gm@cnth=\count120
\Gm@cntv=\count121
\c@Gm@tempcnt=\count122
\Gm@bindingoffset=\dimen139
\Gm@wd@mp=\dimen140
\Gm@odd@mp=\dimen141
\Gm@even@mp=\dimen142
\Gm@dimlist=\toks30
(/usr/share/texmf-texlive/tex/xelatex/xetexconfig/geometry.cfg)) (/usr/share/te
xmf-texlive/tex/latex/hyperref/hyperref.sty
Package: hyperref 2007/02/07 v6.75r Hypertext links for LaTeX
\@linkdim=\dimen143
\Hy@linkcounter=\count123
\Hy@pagecounter=\count124
(/usr/share/texmf-texlive/tex/latex/hyperref/pd1enc.def
File: pd1enc.def 2007/02/07 v6.75r Hyperref: PDFDocEncoding definition (HO)
) (/etc/texmf/tex/latex/config/hyperref.cfg
File: hyperref.cfg 2002/06/06 v1.2 hyperref configuration of TeXLive
) (/usr/share/texmf-texlive/tex/latex/oberdiek/kvoptions.sty
Package: kvoptions 2006/08/22 v2.4 Connects package keyval with LaTeX options (
HO)
)
Package hyperref Info: Option `hyperfootnotes' set `false' on input line 2238.
Package hyperref Info: Option `bookmarks' set `true' on input line 2238.
Package hyperref Info: Option `linktocpage' set `false' on input line 2238.
Package hyperref Info: Option `pdfdisplaydoctitle' set `true' on input line 223
8.
Package hyperref Info: Option `pdfpagelabels' set `true' on input line 2238.
Package hyperref Info: Option `bookmarksopen' set `true' on input line 2238.
Package hyperref Info: Option `colorlinks' set `true' on input line 2238.
Package hyperref Info: Hyper figures OFF on input line 2288.
Package hyperref Info: Link nesting OFF on input line 2293.
Package hyperref Info: Hyper index ON on input line 2296.
Package hyperref Info: Plain pages OFF on input line 2303.
Package hyperref Info: Backreferencing OFF on input line 2308.
Implicit mode ON; LaTeX internals redefined
Package hyperref Info: Bookmarks ON on input line 2444.
(/usr/share/texmf-texlive/tex/latex/ltxmisc/url.sty
\Urlmuskip=\muskip11
Package: url 2005/06/27  ver 3.2  Verb mode for urls, etc.
)
LaTeX Info: Redefining \url on input line 2599.
\Fld@menulength=\count125
\Field@Width=\dimen144
\Fld@charsize=\dimen145
\Choice@toks=\toks31
\Field@toks=\toks32
Package hyperref Info: Hyper figures OFF on input line 3102.
Package hyperref Info: Link nesting OFF on input line 3107.
Package hyperref Info: Hyper index ON on input line 3110.
Package hyperref Info: backreferencing OFF on input line 3117.
Package hyperref Info: Link coloring ON on input line 3120.
\Hy@abspage=\count126
\c@Item=\count127
)
*hyperref using driver hpdftex*
(/usr/share/texmf-texlive/tex/latex/hyperref/hpdftex.def
File: hpdftex.def 2007/02/07 v6.75r Hyperref driver for pdfTeX
\Fld@listcount=\count128
)
\TmpLen=\skip67
\c@FigNo=\count129
\@indexfile=\write3
\openout3 = `36310-t.idx'.

Writing index file 36310-t.idx
\c@ChapNo=\count130
(./36310-t.aux)
\openout1 = `36310-t.aux'.

LaTeX Font Info:    Checking defaults for OML/cmm/m/it on input line 487.
LaTeX Font Info:    ... okay on input line 487.
LaTeX Font Info:    Checking defaults for T1/cmr/m/n on input line 487.
LaTeX Font Info:    ... okay on input line 487.
LaTeX Font Info:    Checking defaults for OT1/cmr/m/n on input line 487.
LaTeX Font Info:    ... okay on input line 487.
LaTeX Font Info:    Checking defaults for OMS/cmsy/m/n on input line 487.
LaTeX Font Info:    ... okay on input line 487.
LaTeX Font Info:    Checking defaults for OMX/cmex/m/n on input line 487.
LaTeX Font Info:    ... okay on input line 487.
LaTeX Font Info:    Checking defaults for U/cmr/m/n on input line 487.
LaTeX Font Info:    ... okay on input line 487.
LaTeX Font Info:    Checking defaults for LGR/cmr/m/n on input line 487.
LaTeX Font Info:    Try loading font information for LGR+cmr on input line 487.

(/usr/share/texmf-texlive/tex/generic/babel/lgrcmr.fd
File: lgrcmr.fd 2001/01/30 v2.2e Greek Computer Modern
)
LaTeX Font Info:    ... okay on input line 487.
LaTeX Font Info:    Checking defaults for PD1/pdf/m/n on input line 487.
LaTeX Font Info:    ... okay on input line 487.
(/usr/share/texmf/tex/context/base/supp-pdf.tex
[Loading MPS to PDF converter (version 2006.09.02).]
\scratchcounter=\count131
\scratchdimen=\dimen146
\scratchbox=\box58
\nofMPsegments=\count132
\nofMParguments=\count133
\everyMPshowfont=\toks33
\MPscratchCnt=\count134
\MPscratchDim=\dimen147
\MPnumerator=\count135
\everyMPtoPDFconversion=\toks34
) (/usr/share/texmf-texlive/tex/latex/ragged2e/ragged2e.sty
Package: ragged2e 2003/03/25 v2.04 ragged2e Package (MS)
(/usr/share/texmf-texlive/tex/latex/everysel/everysel.sty
Package: everysel 1999/06/08 v1.03 EverySelectfont Package (MS)
LaTeX Info: Redefining \selectfont on input line 125.
)
\CenteringLeftskip=\skip68
\RaggedLeftLeftskip=\skip69
\RaggedRightLeftskip=\skip70
\CenteringRightskip=\skip71
\RaggedLeftRightskip=\skip72
\RaggedRightRightskip=\skip73
\CenteringParfillskip=\skip74
\RaggedLeftParfillskip=\skip75
\RaggedRightParfillskip=\skip76
\JustifyingParfillskip=\skip77
\CenteringParindent=\skip78
\RaggedLeftParindent=\skip79
\RaggedRightParindent=\skip80
\JustifyingParindent=\skip81
)
Package caption Info: hyperref package v6.74m (or newer) detected on input line
 487.
-------------------- Geometry parameters
paper: class default
landscape: --
twocolumn: --
twoside: true
asymmetric: --
h-parts: 9.03374pt, 325.215pt, 9.03375pt
v-parts: 4.15848pt, 495.49379pt, 6.23773pt
hmarginratio: 1:1
vmarginratio: 2:3
lines: --
heightrounded: --
bindingoffset: 0.0pt
truedimen: --
includehead: true
includefoot: true
includemp: --
driver: pdftex
-------------------- Page layout dimensions and switches
\paperwidth  343.28249pt
\paperheight 505.89pt
\textwidth  325.215pt
\textheight 433.62pt
\oddsidemargin  -63.23625pt
\evensidemargin -63.23624pt
\topmargin  -68.11151pt
\headheight 15.0pt
\headsep    19.8738pt
\footskip   30.0pt
\marginparwidth 98.0pt
\marginparsep   7.0pt
\columnsep  10.0pt
\skip\footins  10.8pt plus 4.0pt minus 2.0pt
\hoffset 0.0pt
\voffset 0.0pt
\mag 1000
\@twosidetrue \@mparswitchtrue 
(1in=72.27pt, 1cm=28.45pt)
-----------------------
(/usr/share/texmf-texlive/tex/latex/graphics/color.sty
Package: color 2005/11/14 v1.0j Standard LaTeX Color (DPC)
(/etc/texmf/tex/latex/config/color.cfg
File: color.cfg 2007/01/18 v1.5 color configuration of teTeX/TeXLive
)
Package color Info: Driver file: pdftex.def on input line 130.
)
Package hyperref Info: Link coloring ON on input line 487.
(/usr/share/texmf-texlive/tex/latex/hyperref/nameref.sty
Package: nameref 2006/12/27 v2.28 Cross-referencing by name of section
(/usr/share/texmf-texlive/tex/latex/oberdiek/refcount.sty
Package: refcount 2006/02/20 v3.0 Data extraction from references (HO)
)
\c@section@level=\count136
)
LaTeX Info: Redefining \ref on input line 487.
LaTeX Info: Redefining \pageref on input line 487.
(./36310-t.out) (./36310-t.out)
\@outlinefile=\write4
\openout4 = `36310-t.out'.

LaTeX Font Info:    Try loading font information for T1+cmtt on input line 497.

(/usr/share/texmf-texlive/tex/latex/base/t1cmtt.fd
File: t1cmtt.fd 1999/05/25 v2.5h Standard LaTeX font definitions
)
LaTeX Font Info:    Try loading font information for U+msa on input line 519.
(/usr/share/texmf-texlive/tex/latex/amsfonts/umsa.fd
File: umsa.fd 2002/01/19 v2.2g AMS font definitions
)
LaTeX Font Info:    Try loading font information for U+msb on input line 519.
(/usr/share/texmf-texlive/tex/latex/amsfonts/umsb.fd
File: umsb.fd 2002/01/19 v2.2g AMS font definitions
)
LaTeX Font Info:    Try loading font information for U+rsfs on input line 519.
(/usr/share/texmf-texlive/tex/latex/jknapltx/ursfs.fd
File: ursfs.fd 1998/03/24 rsfs font definition file (jk)
) [1

{/var/lib/texmf/fonts/map/pdftex/updmap/pdftex.map}] [2

] <./images/006.png, id=99, 289.08pt x 337.26pt>
File: ./images/006.png Graphic file (type png)
<use ./images/006.png> [1

 <./images/006.png (PNG copy)>] [2

] [3

] [4] [5] [6]
Underfull \hbox (badness 10000) in paragraph at lines 777--779

 []

[7] (./36310-t.toc)
\tf@toc=\write5
\openout5 = `36310-t.toc'.

[8

] [1


] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] [16] [17

] [18] [19] [20] [21] [22] [23] [24] [25] [26] [27] [28

] [29] [30] <./images/037.png, id=307, 1092.08pt x 908.39375pt>
File: ./images/037.png Graphic file (type png)
<use ./images/037.png> [31 <./images/037.png (PNG copy)>] [32] <./images/039.pn
g, id=323, 1148.29pt x 720.6925pt>
File: ./images/039.png Graphic file (type png)
<use ./images/039.png> [33] [34 <./images/039.png (PNG copy)>] [35] [36] [37] [
38] [39] [40] [41] [42] <./images/046.png, id=373, 1092.08pt x 1065.9825pt>
File: ./images/046.png Graphic file (type png)
<use ./images/046.png> [43] [44 <./images/046.png (PNG copy)>] <./images/048.pn
g, id=389, 1062.97125pt x 599.23875pt>
File: ./images/048.png Graphic file (type png)
<use ./images/048.png> [45] [46 <./images/048.png (PNG copy)>] [47

] [48] [49] [50] [51] [52] [53] [54] [55] [56] [57] [58] [59] [60] [61] [62] [6
3] [64] [65] [66

] [67] [68] [69] [70] [71] [72] [73] [74] [75] [76] [77] [78] [79] [80] [81] [8
2] [83] [84] [85] [86]
Underfull \hbox (badness 2245) in paragraph at lines 3536--3594
\T1/cmr/m/n/12 Wahr-schein-lich-keits-be-griff zu den sta-tis-ti-schen Er-geb-n
is-sen
 []


Underfull \hbox (badness 1052) in paragraph at lines 3536--3594
\T1/cmr/m/n/12 durch einen Satz ge-fun-den, der als das B e r -n o u l -l i -s 
c h e
 []

[87] [88] [89] [90] [91] [92

] [93] [94] [95] [96] [97] [98] [99] [100] [101] [102] [103] [104] [105] [106] 
<./images/094.png, id=692, 843.15pt x 372.39125pt>
File: ./images/094.png Graphic file (type png)
<use ./images/094.png> [107] [108 <./images/094.png (PNG copy)>] [109] [110] [1
11] [112] [113] [114] <./images/100.png, id=739, 635.37375pt x 575.14874pt>
File: ./images/100.png Graphic file (type png)
<use ./images/100.png> [115] [116 <./images/100.png (PNG copy)>] [117] [118]
LaTeX Font Info:    Try loading font information for U+euf on input line 4543.
(/usr/share/texmf-texlive/tex/latex/amsfonts/ueuf.fd
File: ueuf.fd 2002/01/19 v2.2g AMS font definitions
) [119] [120] [121] [122] [123

] [124] [125] [126] [127] [128] [129] [130] [131] [132] [133]

LaTeX Warning: Command \ss invalid in math mode on input line 5065.

Missing character: There is no ÿ in font cmr12!
[134] [135] [136] [137]
Overfull \hbox (2.90742pt too wide) in paragraph at lines 5220--5220
[] 
 []

[138] [139] [140] [141] <./images/120.png, id=891, 1178.4025pt x 689.57625pt>
File: ./images/120.png Graphic file (type png)
<use ./images/120.png> [142

] [143 <./images/120.png (PNG copy)>] [144] [145] [146] [147] [148] [149] [150]
[151] [152] [153] [154] [155] [156] [157] [158] [159] [160] [161] [162] [163] [
164] [165] [166]
Underfull \hbox (badness 1603) in paragraph at lines 6202--6204
[]\T1/cmr/m/n/12 Die re-la-ti-ve Häu-fig-keit des Ge-sam-ter-eig-nis-ses ent-st
eht
 []

[167] [168] [169] [170] [171] [172] [173] [174] [175] [176] [177] [178] [179] [
180

] [181] [182] [183] [184] [185] [186] [187] [188]

LaTeX Font Warning: Command \small invalid in math mode on input line 6943.

[189]

LaTeX Font Warning: Command \small invalid in math mode on input line 7026.


Overfull \hbox (0.4068pt too wide) detected at line 7043
[]
 []

[190] [191] [192] [193] <./images/159.png, id=1195, 918.43124pt x 515.9275pt>
File: ./images/159.png Graphic file (type png)
<use ./images/159.png> [194] [195 <./images/159.png (PNG copy)>] [196] [197] [1
98] <./images/163.png, id=1222, 791.95876pt x 640.3925pt>
File: ./images/163.png Graphic file (type png)
<use ./images/163.png> [199] [200] [201 <./images/163.png (PNG copy)>]

LaTeX Font Warning: Command \footnotesize invalid in math mode on input line 74
83.


Overfull \hbox (9.468pt too wide) detected at line 7520
[]
 []

<./images/165.png, id=1243, 794.97pt x 1264.725pt>
File: ./images/165.png Graphic file (type png)
<use ./images/165.png>
Overfull \hbox (2.61049pt too wide) in paragraph at lines 7481--7528
[]$[]$  $[]$ 
 []

[202] [203 <./images/165.png (PNG copy)>] [204] [205] [206

] [207

] [208] [209] [210] [211] [212] [213] [214] [215] [216] [217] [218] [219] [220]

Underfull \hbox (badness 1281) in paragraph at lines 8103--8129
\T1/cmr/m/n/12 dung []der Wahr-schein-lich-keits-rech-nung auf die Wirk-lich-ke
it
 []

[221] [222] [223] [224] [225] (./36310-t.ind [226


]) [227] [228

] [229] [230] [231] [232] [233] [234] [235] (./36310-t.aux)

 *File List*
    book.cls    2005/09/16 v1.4f Standard LaTeX document class
   leqno.clo    1998/08/17 v1.1c Standard LaTeX option (left equation numbers)
    bk12.clo    2005/09/16 v1.4f Standard LaTeX file (size option)
inputenc.sty    2006/05/05 v1.1b Input encoding file
  latin1.def    2006/05/05 v1.1b Input encoding file
 fontenc.sty
   t1enc.def    2005/09/27 v1.99g Standard LaTeX file
   babel.sty    2005/11/23 v3.8h The Babel package
   greek.ldf    2005/03/30 v1.3l Greek support from the babel system
  lgrenc.def    2001/01/30 v2.2e Greek Encoding
ngermanb.ldf    2004/02/20 v2.6m new German support from the babel system
 amsmath.sty    2000/07/18 v2.13 AMS math features
 amstext.sty    2000/06/29 v2.01
  amsgen.sty    1999/11/30 v2.0
  amsbsy.sty    1999/11/29 v1.2d
  amsopn.sty    1999/12/14 v2.01 operator names
 amssymb.sty    2002/01/22 v2.2d
amsfonts.sty    2001/10/25 v2.2f
mathrsfs.sty    1996/01/01 Math RSFS package v1.0 (jk)
  ifthen.sty    2001/05/26 v1.1c Standard LaTeX ifthen package (DPC)
   alltt.sty    1997/06/16 v2.0g defines alltt environment
indentfirst.sty    1995/11/23 v1.03 Indent first paragraph (DPC)
 makeidx.sty    2000/03/29 v1.0m Standard LaTeX package
multicol.sty    2006/05/18 v1.6g multicolumn formatting (FMi)
   array.sty    2005/08/23 v2.4b Tabular extension package (FMi)
longtable.sty    2004/02/01 v4.11 Multi-page Table package (DPC)
multirow.sty    
    soul.sty    2003/11/17 v2.4 letterspacing/underlining (mf)
footmisc.sty    2005/03/17 v5.3d a miscellany of footnote facilities
graphicx.sty    1999/02/16 v1.0f Enhanced LaTeX Graphics (DPC,SPQR)
  keyval.sty    1999/03/16 v1.13 key=value parser (DPC)
graphics.sty    2006/02/20 v1.0o Standard LaTeX Graphics (DPC,SPQR)
    trig.sty    1999/03/16 v1.09 sin cos tan (DPC)
graphics.cfg    2007/01/18 v1.5 graphics configuration of teTeX/TeXLive
  pdftex.def    2007/01/08 v0.04d Graphics/color for pdfTeX
 caption.sty    2007/01/07 v3.0k Customising captions (AR)
caption3.sty    2007/01/07 v3.0k caption3 kernel (AR)
    calc.sty    2005/08/06 v4.2 Infix arithmetic (KKT,FJ)
fancyhdr.sty    
geometry.sty    2002/07/08 v3.2 Page Geometry
geometry.cfg
hyperref.sty    2007/02/07 v6.75r Hypertext links for LaTeX
  pd1enc.def    2007/02/07 v6.75r Hyperref: PDFDocEncoding definition (HO)
hyperref.cfg    2002/06/06 v1.2 hyperref configuration of TeXLive
kvoptions.sty    2006/08/22 v2.4 Connects package keyval with LaTeX options (HO
)
     url.sty    2005/06/27  ver 3.2  Verb mode for urls, etc.
 hpdftex.def    2007/02/07 v6.75r Hyperref driver for pdfTeX
  lgrcmr.fd    2001/01/30 v2.2e Greek Computer Modern
supp-pdf.tex
ragged2e.sty    2003/03/25 v2.04 ragged2e Package (MS)
everysel.sty    1999/06/08 v1.03 EverySelectfont Package (MS)
   color.sty    2005/11/14 v1.0j Standard LaTeX Color (DPC)
   color.cfg    2007/01/18 v1.5 color configuration of teTeX/TeXLive
 nameref.sty    2006/12/27 v2.28 Cross-referencing by name of section
refcount.sty    2006/02/20 v3.0 Data extraction from references (HO)
 36310-t.out
 36310-t.out
  t1cmtt.fd    1999/05/25 v2.5h Standard LaTeX font definitions
    umsa.fd    2002/01/19 v2.2g AMS font definitions
    umsb.fd    2002/01/19 v2.2g AMS font definitions
   ursfs.fd    1998/03/24 rsfs font definition file (jk)
./images/006.png
./images/037.png
./images/039.png
./images/046.png
./images/048.png
./images/094.png
./images/100.png
    ueuf.fd    2002/01/19 v2.2g AMS font definitions
./images/120.png
./images/159.png
./images/163.png
./images/165.png
 36310-t.ind
 ***********

 ) 
Here is how much of TeX's memory you used:
 6819 strings out of 94074
 90538 string characters out of 1165154
 163914 words of memory out of 1500000
 9432 multiletter control sequences out of 10000+50000
 29942 words of font info for 83 fonts, out of 1200000 for 2000
 645 hyphenation exceptions out of 8191
 34i,18n,45p,274b,588s stack positions out of 5000i,500n,6000p,200000b,5000s
{/usr/share/texmf/fonts/enc/dvips/cm-super/cm-super-t1.enc} </home/ajhaines/.
texmf-var/fonts/pk/ljfour/public/cb/grmn1200.600pk></usr/share/texmf-texlive/fo
nts/type1/bluesky/cm/cmex10.pfb></usr/share/texmf-texlive/fonts/type1/bluesky/c
m/cmmi10.pfb></usr/share/texmf-texlive/fonts/type1/bluesky/cm/cmmi12.pfb></usr/
share/texmf-texlive/fonts/type1/bluesky/cm/cmmi6.pfb></usr/share/texmf-texlive/
fonts/type1/bluesky/cm/cmmi7.pfb></usr/share/texmf-texlive/fonts/type1/bluesky/
cm/cmmi8.pfb></usr/share/texmf-texlive/fonts/type1/bluesky/cm/cmr10.pfb></usr/s
hare/texmf-texlive/fonts/type1/bluesky/cm/cmr12.pfb></usr/share/texmf-texlive/f
onts/type1/bluesky/cm/cmr6.pfb></usr/share/texmf-texlive/fonts/type1/bluesky/cm
/cmr7.pfb></usr/share/texmf-texlive/fonts/type1/bluesky/cm/cmr8.pfb></usr/share
/texmf-texlive/fonts/type1/bluesky/cm/cmsy10.pfb></usr/share/texmf-texlive/font
s/type1/bluesky/cm/cmsy6.pfb></usr/share/texmf-texlive/fonts/type1/bluesky/cm/c
msy8.pfb></usr/share/texmf-texlive/fonts/type1/bluesky/ams/eufm10.pfb></usr/sha
re/texmf-texlive/fonts/type1/bluesky/ams/eufm7.pfb></usr/share/texmf-texlive/fo
nts/type1/public/cmex/fmex8.pfb></usr/share/texmf-texlive/fonts/type1/hoekwater
/rsfs/rsfs10.pfb></usr/share/texmf/fonts/type1/public/cm-super/sfbx1200.pfb></u
sr/share/texmf/fonts/type1/public/cm-super/sfbx1440.pfb></usr/share/texmf/fonts
/type1/public/cm-super/sfbx1728.pfb></usr/share/texmf/fonts/type1/public/cm-sup
er/sfbx2074.pfb></usr/share/texmf/fonts/type1/public/cm-super/sfbx2488.pfb></us
r/share/texmf/fonts/type1/public/cm-super/sfcc1200.pfb></usr/share/texmf/fonts/
type1/public/cm-super/sfrm0700.pfb></usr/share/texmf/fonts/type1/public/cm-supe
r/sfrm0800.pfb></usr/share/texmf/fonts/type1/public/cm-super/sfrm1000.pfb></usr
/share/texmf/fonts/type1/public/cm-super/sfrm1095.pfb></usr/share/texmf/fonts/t
ype1/public/cm-super/sfrm1200.pfb></usr/share/texmf/fonts/type1/public/cm-super
/sftt0800.pfb>
Output written on 36310-t.pdf (245 pages, 983694 bytes).
PDF statistics:
 1735 PDF objects out of 2073 (max. 8388607)
 492 named destinations out of 1000 (max. 131072)
 224 words of extra memory for PDF output out of 10000 (max. 10000000)

